{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals\n",
    "\n",
    "    -implement spectral clustering\n",
    "    -implement belief propagation\n",
    "    -implement it with power method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla Belief propagation algorithm\n",
    "\n",
    "Input: a stochastic block model (adjaceny matrix)\n",
    "\n",
    "1) for each v, v' adajecnt, randomly draw y^1_vv' from N(0,1)\n",
    "\n",
    "2) find all cycles in G of length r or less.  To do this, we may have to multiply r times, but avoid the backtracking ones.  \n",
    "\n",
    "3) for each 1<t<m and each adjacent v, v' set y^t_vv' = sum of all the y's up to that t....since we seeded it with N(0,1) we will have the value for y^1.  Howver, if (v,v') is part of a cycle of r or less, don't do this.  Instead, \n",
    "4) if your edge is part of a r cycle, then we subtract from the previous sum, the accumulated influence of the other adjacent edge in our cycle, unless the r cycle is the same lenght as the time steps, in which case we just subtract the original randomized N(0,1)\n",
    "\n",
    "5) Let Y be the matrix composed of all y_vv' summed up with edge vertices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first try implementing power method in tensorflow\n",
    "\n",
    "#feed in graphs, as in adjaceny matrices, or just nodes and connected edges?\n",
    "\n",
    "#each layer will feed in a random vector, then multiply our matrix by the random vector\n",
    "#many times.  At the end, we subtract away the orignal vector component\n",
    "\n",
    "#next layer we just randomize another vector...\n",
    "\n",
    "#how many layers.  The depth can be learned by adding identify layers, which is essentially \n",
    "#self multiplication.  \n",
    "\n",
    "#adjaceny matrix to graph laplacian \n",
    "\n",
    "#suppose for simplicity that our graph has the same dimnension\n",
    "\n",
    "#10by10 graph, so feed adjacency matrix\n",
    "dim_graph = 10\n",
    "dim_subspace = 3\n",
    "\n",
    "x = tf.placeholder(\"float\", shape = [dim_graph, dim_graph])\n",
    "y = tf.placeholder(\"float\", shape = [None, dim_graph])\n",
    "#y is our community classification answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize the k random vectors (whcih should be tuned)\n",
    "#that we are feeding to the laplacian operator\n",
    "d = {}\n",
    "for i in range(1,dim_subspace):\n",
    "    d[\"v{}\".format(i)] = tf.Variable(tf.random_normal(shape=[1, dim_graph], \n",
    "                         mean=0.0, \n",
    "                         stddev = 1.0))\n",
    "\n",
    "#may have to define another way...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#laplacian\n",
    "\n",
    "#diffusion:\n",
    "\n",
    "def DiffusionVertex(vertex, vector, graph):\n",
    "    #assume graph is in form of adjacency matrix \n",
    "    neighbour_vector = tf.slice(graph, vertex, size=dim_graph)\n",
    "    prod = tf.mul(vector, neighbour_vector)\n",
    "    diffusion = tf.reduce_sum(prod)\n",
    "    return(diffusion)\n",
    "\n",
    "def GraphLaplacian(graph, vector):\n",
    "    #takes in graph and vector on graph indices, returns new vector\n",
    "    tmp_v = tf.constant(range(dim_graph))\n",
    "    def DiffusionVertex_1(vertex):\n",
    "        return DiffusionVertex(vertex, graph, vector)\n",
    "    diffusion_vector = tf.map_fn(DiffusionVertex_1, tmp_v) \n",
    "    \n",
    "    return tf.reduce_sum(diffusion_vector)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?tf.map_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?tf.map_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
