{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import linalg_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@ops.RegisterGradient(\"gradient_no_unitary_adjustment\")\n",
    "def _test1(op, grad_e, grad_v):\n",
    "    \"\"\"Gradient for SelfAdjointEigV2 derived with Joan with no adjustment for subspace\"\"\"\n",
    "    e = op.outputs[0]\n",
    "    v = op.outputs[1]\n",
    "    #dim = v.get_shape()\n",
    "    with ops.control_dependencies([grad_e.op, grad_v.op]):\n",
    "        if grad_v is not None:  \n",
    "            E = array_ops.diag(e)\n",
    "            #v_proj = arrary.ops.slice(v, [0,0], [])\n",
    "            grad_grassman = grad_v# - math_ops.batch_matmul(math_ops.batch_matmul(v, array_ops.transpose(grad_v)), v)\n",
    "            grad_a = math_ops.batch_matmul(grad_grassman, math_ops.batch_matmul(E, array_ops.transpose(grad_v)))+math_ops.batch_matmul(grad_v, math_ops.batch_matmul(E, array_ops.transpose(grad_grassman)))\n",
    "    return grad_a\n",
    "@ops.RegisterGradient(\"grassman_with_2d\")\n",
    "def _test1(op, grad_e, grad_v):\n",
    "    \"\"\"Gradient for SelfAdjointEigV2 derived with Joan with no adjustment for subspace\"\"\"\n",
    "    e = op.outputs[0]\n",
    "    v = op.outputs[1]\n",
    "    #dim = v.get_shape()\n",
    "    with ops.control_dependencies([grad_e.op, grad_v.op]):\n",
    "        if grad_v is not None:  \n",
    "            E = array_ops.diag(e)\n",
    "            v_proj = array_ops.slice(v, [0,0], [20,2])\n",
    "            grad_grassman = grad_v - math_ops.batch_matmul(math_ops.batch_matmul(v_proj, array_ops.transpose(v_proj)), grad_v)\n",
    "            grad_a = math_ops.batch_matmul(grad_grassman, math_ops.batch_matmul(E, array_ops.transpose(grad_v)))+math_ops.batch_matmul(grad_v, math_ops.batch_matmul(E, array_ops.transpose(grad_grassman)))\n",
    "    return grad_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def balanced_stochastic_blockmodel(communities=2, groupsize=3, p_in=0.5, p_out=0.1, seed=None):\n",
    "    #gives dense adjacency matrix representaiton of randomly generated SBM with balanced community size\n",
    "\n",
    "    G = nx.planted_partition_graph(l=communities, k=groupsize, p_in=p_in, p_out =p_out, seed=seed)\n",
    "    A = nx.adjacency_matrix(G).todense()\n",
    "    \n",
    "    return A\n",
    "def target_subspace(adj, groupsize, communities, diag, dim_proj):\n",
    "    normalizer = tf.cast(2.0*groupsize*communities, dtype=tf.float64)\n",
    "    total_degree = tf.cast(tf.reduce_sum(adj), dtype=tf.float64)\n",
    "    r = tf.sqrt(total_degree/normalizer)\n",
    "    BH_op = (tf.square(r)-1)*tf.diag(tf.ones(shape=[communities*groupsize], dtype=tf.float64))-r*adj+diag \n",
    "    val, vec = tf.self_adjoint_eig(BH_op) #this is already normalized so no need to normalize\n",
    "    subspace = tf.slice(vec, [0,0], [communities*groupsize, dim_proj])\n",
    "    return r, subspace\n",
    "\n",
    "def proj_magnitude(space, vector):\n",
    "    projection_op = tf.matmul(space, tf.transpose(space))\n",
    "    projection = tf.matmul(projection_op, vector)\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(projection))) #tf.reduce_sum(tf.abs(projection))#\n",
    "\n",
    "\n",
    "def rnd_vec_normed(communities, groupsize, seed=None):\n",
    "    rnd_vec1 = tf.Variable(tf.random_normal(shape=[communities*groupsize,1], mean=0.0,stddev=1.0,\n",
    "                                                    dtype=tf.float64,\n",
    "                                                    seed=seed))\n",
    "    return normalize_vec(rnd_vec1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_svm_cluster(communities = 2, group_size = 10, seed=1, seed_r=1, p=0.8, q=0.05, name='test1', projection_dim=2, iterations=100, \n",
    "                     print_ratio=10, l_rate=0.1, mean=2.0, sd=0.4):\n",
    "    \"\"\"testing to see if the loss will decrease backproping through very simple function\"\"\"\n",
    "    B = np.asarray(balanced_stochastic_blockmodel(communities, group_size, p, q, seed)).astype(np.double)\n",
    "    B = tf.cast(B, dtype = tf.float64)\n",
    "    \n",
    "    Diag = tf.diag(tf.reduce_sum(B,0))\n",
    "    Diag = tf.cast(Diag, tf.float64)\n",
    "\n",
    "    r =  tf.Variable(tf.random_normal(shape=[1], mean=mean,\n",
    "                                 stddev=sd, dtype=tf.float64,\n",
    "                                 seed=seed_r, name=None))\n",
    "\n",
    "    \n",
    "    BH = (tf.square(r)-1)*tf.diag(tf.ones(shape=[communities*group_size], dtype=tf.float64))-tf.mul(r, B)+Diag \n",
    "    \n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        g = tf.get_default_graph()\n",
    "        \n",
    "        with g.gradient_override_map({'SelfAdjointEigV2': name}):\n",
    "            eigenval, eigenvec = tf.self_adjoint_eig(BH)\n",
    "            #we try to do svm in this subspace \n",
    "            #or we can project it down to 1 dimensions, do the clustering there via some threshold and check if it makes sense \n",
    "            #by computing the loss, if it is too big, we change the angle we project down to...\n",
    "            \n",
    "            \n",
    "            eigenvec_proj = tf.slice(eigenvec, [0,0], [communities*group_size, projection_dim])\n",
    "            \n",
    "            \n",
    "            \n",
    "            true_assignment_a = tf.concat(0, [-1*tf.ones([group_size], dtype=tf.float64),\n",
    "                                      tf.ones([group_size], dtype=tf.float64)])\n",
    "            true_assignment_b = -1*true_assignment_a\n",
    "            true_assignment_a = tf.expand_dims(true_assignment_a, 1)\n",
    "            true_assignment_b = tf.expand_dims(true_assignment_b, 1)\n",
    "\n",
    "            \n",
    "            projected_a = tf.matmul(tf.matmul(eigenvec_proj, tf.transpose(eigenvec_proj)), true_assignment_a)#tf.transpose(true_assignment_a))\n",
    "            projected_b = tf.matmul(tf.matmul(eigenvec_proj, tf.transpose(eigenvec_proj)), true_assignment_b)#tf.transpose(true_assignment_b))\n",
    "            \n",
    "            \n",
    "            \n",
    "            loss = tf.minimum(tf.reduce_sum(tf.square(tf.sub(projected_a, true_assignment_a))),\n",
    "                              tf.reduce_sum(tf.square(tf.sub(projected_b, true_assignment_b))))\n",
    "            \n",
    "            optimizer = tf.train.GradientDescentOptimizer(l_rate)\n",
    "            \n",
    "            train = optimizer.minimize(loss, var_list=[r])\n",
    "\n",
    "            eigenvec_grad = tf.gradients(eigenvec, r)\n",
    "            loss_grad = tf.gradients(loss, r)\n",
    "            \n",
    "            \n",
    "            \n",
    "            r_op, target = target_subspace(adj=B, groupsize=group_size, communities=communities, diag=Diag, dim_proj=projection_dim)  \n",
    "            \n",
    "            r_op_projection_a = tf.matmul(tf.matmul(target, tf.transpose(target)), true_assignment_a)\n",
    "            r_op_projection_b = tf.matmul(tf.matmul(target, tf.transpose(target)), true_assignment_b)\n",
    "            r_op_loss = tf.minimum(tf.reduce_sum(tf.square(tf.sub(r_op_projection_a, true_assignment_a))),\n",
    "                              tf.reduce_sum(tf.square(tf.sub(r_op_projection_b, true_assignment_b))))\n",
    "            \n",
    "            init = tf.initialize_all_variables()\n",
    "            \n",
    "            \n",
    "            sess.run(init)\n",
    "            a,b,c,d= sess.run([r, r_op, r_op_loss, tf.transpose(r_op_projection_a)])\n",
    "            a_lst = []\n",
    "            b_lst = []\n",
    "            c_lst = []\n",
    "            d_lst = []\n",
    "            \n",
    "            a_lst.append(a)\n",
    "            b_lst.append(b)\n",
    "            c_lst.append(c)\n",
    "            d_lst.append(d)\n",
    "            \n",
    "            print \"initial r: {}. r_op = sqrt(average degree) : {} . Loss associated with r_op: {}. r_op assignments {}.\".format(a, b, c, d)\n",
    "            for i in range(iterations):   \n",
    "                try: sess.run(train)\n",
    "                except: \n",
    "                    pass\n",
    "                \n",
    "                if i%print_ratio==0:  \n",
    "                    #print i\n",
    "                    try:\n",
    "                        a,b,c,d = sess.run([r, loss, tf.gradients(loss, r), tf.transpose(projected_a)]) \n",
    "                        a_lst.append(a)\n",
    "                        b_lst.append(b)\n",
    "                        c_lst.append(c)\n",
    "                        d_lst.append(d)\n",
    "                    except:\n",
    "                        a,b,c,d = 0, 0, 0, 0 \n",
    "                        a_lst.append(a)\n",
    "                        b_lst.append(b)\n",
    "                        c_lst.append(c)\n",
    "                        d_lst.append(d)\n",
    "                    #print \"current r: {}, current loss: {}, gradient of loss/r is {} and current assignments (up to sign) {}.\".format(a,b,c,d)  \n",
    "\n",
    "    d = {\"r_value\": a_lst, \"loss\": b_lst, \"gradient_loss_r\": c_lst, \"projection\": d_lst}\n",
    "    d = pd.DataFrame(d)\n",
    "    d.to_csv(\"/Users/xiangli/Desktop/clusternet/plot_data/r{}rate{}p{}q{}iterations{}step{}.csv\".format(mean, l_rate, p, q, iterations, print_ratio))\n",
    "    return  d\n",
    "                \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "r_list = [i for i in range(-6, 7, 2)]\n",
    "p_q_pairs = [(0.4, 0.05), (0.4,0.2), (0.4, 0.3)]\n",
    "l_rate_lst = [10**(-i)/3 for i in range(2, 6, 1)]\n",
    "\n",
    "\n",
    "l_rate_dic = {i: l_rate_lst[i] for i in range(len(l_rate_lst))}\n",
    "r_list_dic = {i: r_list[i] for i in range(len(r_list))}\n",
    "pq_pairs_dict = {i: p_q_pairs[i] for i in range(len(p_q_pairs))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.33333333333e-05 -6 (0.25, 0.05)\n",
      "3.33333333333e-05 -6 (0.25, 0.1)\n",
      "3.33333333333e-05 -6 (0.25, 0.15)\n",
      "3.33333333333e-05 -6 (0.4, 0.05)\n",
      "3.33333333333e-05 -6 (0.4, 0.2)\n",
      "3.33333333333e-05 -6 (0.4, 0.3)\n",
      "3.33333333333e-05 -6 (0.9, 0.05)\n",
      "3.33333333333e-05 -6 (0.9, 0.45)\n",
      "3.33333333333e-05 -6 (0.9, 0.7)\n",
      "3.33333333333e-05 -4 (0.25, 0.05)\n",
      "3.33333333333e-05 -4 (0.25, 0.1)\n",
      "3.33333333333e-05 -4 (0.25, 0.15)\n",
      "3.33333333333e-05 -4 (0.4, 0.05)\n",
      "3.33333333333e-05 -4 (0.4, 0.2)\n",
      "3.33333333333e-05 -4 (0.4, 0.3)\n",
      "3.33333333333e-05 -4 (0.9, 0.05)\n",
      "3.33333333333e-05 -4 (0.9, 0.45)\n",
      "3.33333333333e-05 -4 (0.9, 0.7)\n",
      "3.33333333333e-05 -2 (0.25, 0.05)\n",
      "3.33333333333e-05 -2 (0.25, 0.1)\n",
      "3.33333333333e-05 -2 (0.25, 0.15)\n",
      "3.33333333333e-05 -2 (0.4, 0.05)\n",
      "3.33333333333e-05 -2 (0.4, 0.2)\n",
      "3.33333333333e-05 -2 (0.4, 0.3)\n",
      "3.33333333333e-05 -2 (0.9, 0.05)\n",
      "3.33333333333e-05 -2 (0.9, 0.45)\n",
      "3.33333333333e-05 -2 (0.9, 0.7)\n",
      "3.33333333333e-05 0 (0.25, 0.05)\n",
      "3.33333333333e-05 0 (0.25, 0.1)\n",
      "3.33333333333e-05 0 (0.25, 0.15)\n",
      "3.33333333333e-05 0 (0.4, 0.05)\n",
      "3.33333333333e-05 0 (0.4, 0.2)\n",
      "3.33333333333e-05 0 (0.4, 0.3)\n",
      "3.33333333333e-05 0 (0.9, 0.05)\n",
      "3.33333333333e-05 0 (0.9, 0.45)\n",
      "3.33333333333e-05 0 (0.9, 0.7)\n",
      "3.33333333333e-05 2 (0.25, 0.05)\n",
      "3.33333333333e-05 2 (0.25, 0.1)\n",
      "3.33333333333e-05 2 (0.25, 0.15)\n",
      "3.33333333333e-05 2 (0.4, 0.05)\n",
      "3.33333333333e-05 2 (0.4, 0.2)\n",
      "3.33333333333e-05 2 (0.4, 0.3)\n",
      "3.33333333333e-05 2 (0.9, 0.05)\n",
      "3.33333333333e-05 2 (0.9, 0.45)\n",
      "3.33333333333e-05 2 (0.9, 0.7)\n",
      "3.33333333333e-05 4 (0.25, 0.05)\n",
      "3.33333333333e-05 4 (0.25, 0.1)\n",
      "3.33333333333e-05 4 (0.25, 0.15)\n",
      "3.33333333333e-05 4 (0.4, 0.05)\n",
      "3.33333333333e-05 4 (0.4, 0.2)\n",
      "3.33333333333e-05 4 (0.4, 0.3)\n",
      "3.33333333333e-05 4 (0.9, 0.05)\n",
      "3.33333333333e-05 4 (0.9, 0.45)\n",
      "3.33333333333e-05 4 (0.9, 0.7)\n",
      "3.33333333333e-05 6 (0.25, 0.05)\n",
      "3.33333333333e-05 6 (0.25, 0.1)\n",
      "3.33333333333e-05 6 (0.25, 0.15)\n",
      "3.33333333333e-05 6 (0.4, 0.05)\n",
      "3.33333333333e-05 6 (0.4, 0.2)\n",
      "3.33333333333e-05 6 (0.4, 0.3)\n",
      "3.33333333333e-05 6 (0.9, 0.05)\n",
      "3.33333333333e-05 6 (0.9, 0.45)\n",
      "3.33333333333e-05 6 (0.9, 0.7)\n",
      "3.33333333333e-06 -6 (0.25, 0.05)\n",
      "3.33333333333e-06 -6 (0.25, 0.1)\n",
      "3.33333333333e-06 -6 (0.25, 0.15)\n",
      "3.33333333333e-06 -6 (0.4, 0.05)\n",
      "3.33333333333e-06 -6 (0.4, 0.2)\n",
      "3.33333333333e-06 -6 (0.4, 0.3)\n",
      "3.33333333333e-06 -6 (0.9, 0.05)\n",
      "3.33333333333e-06 -6 (0.9, 0.45)\n",
      "3.33333333333e-06 -6 (0.9, 0.7)\n",
      "3.33333333333e-06 -4 (0.25, 0.05)\n",
      "3.33333333333e-06 -4 (0.25, 0.1)\n",
      "3.33333333333e-06 -4 (0.25, 0.15)\n",
      "3.33333333333e-06 -4 (0.4, 0.05)\n",
      "3.33333333333e-06 -4 (0.4, 0.2)\n",
      "3.33333333333e-06 -4 (0.4, 0.3)\n",
      "3.33333333333e-06 -4 (0.9, 0.05)\n",
      "3.33333333333e-06 -4 (0.9, 0.45)\n",
      "3.33333333333e-06 -4 (0.9, 0.7)\n",
      "3.33333333333e-06 -2 (0.25, 0.05)\n",
      "3.33333333333e-06 -2 (0.25, 0.1)\n",
      "3.33333333333e-06 -2 (0.25, 0.15)\n",
      "3.33333333333e-06 -2 (0.4, 0.05)\n",
      "3.33333333333e-06 -2 (0.4, 0.2)\n",
      "3.33333333333e-06 -2 (0.4, 0.3)\n",
      "3.33333333333e-06 -2 (0.9, 0.05)\n",
      "3.33333333333e-06 -2 (0.9, 0.45)\n",
      "3.33333333333e-06 -2 (0.9, 0.7)\n",
      "3.33333333333e-06 0 (0.25, 0.05)\n",
      "3.33333333333e-06 0 (0.25, 0.1)\n",
      "3.33333333333e-06 0 (0.25, 0.15)\n",
      "3.33333333333e-06 0 (0.4, 0.05)\n",
      "3.33333333333e-06 0 (0.4, 0.2)\n",
      "3.33333333333e-06 0 (0.4, 0.3)\n",
      "3.33333333333e-06 0 (0.9, 0.05)\n",
      "3.33333333333e-06 0 (0.9, 0.45)\n",
      "3.33333333333e-06 0 (0.9, 0.7)\n",
      "3.33333333333e-06 2 (0.25, 0.05)\n",
      "3.33333333333e-06 2 (0.25, 0.1)\n",
      "3.33333333333e-06 2 (0.25, 0.15)\n",
      "3.33333333333e-06 2 (0.4, 0.05)\n",
      "3.33333333333e-06 2 (0.4, 0.2)\n",
      "3.33333333333e-06 2 (0.4, 0.3)\n",
      "3.33333333333e-06 2 (0.9, 0.05)\n",
      "3.33333333333e-06 2 (0.9, 0.45)\n",
      "3.33333333333e-06 2 (0.9, 0.7)\n",
      "3.33333333333e-06 4 (0.25, 0.05)\n",
      "3.33333333333e-06 4 (0.25, 0.1)\n",
      "3.33333333333e-06 4 (0.25, 0.15)\n",
      "3.33333333333e-06 4 (0.4, 0.05)\n",
      "3.33333333333e-06 4 (0.4, 0.2)\n",
      "3.33333333333e-06 4 (0.4, 0.3)\n",
      "3.33333333333e-06 4 (0.9, 0.05)\n",
      "3.33333333333e-06 4 (0.9, 0.45)\n",
      "3.33333333333e-06 4 (0.9, 0.7)\n",
      "3.33333333333e-06 6 (0.25, 0.05)\n",
      "3.33333333333e-06 6 (0.25, 0.1)\n",
      "3.33333333333e-06 6 (0.25, 0.15)\n",
      "3.33333333333e-06 6 (0.4, 0.05)\n",
      "3.33333333333e-06 6 (0.4, 0.2)\n",
      "3.33333333333e-06 6 (0.4, 0.3)\n",
      "3.33333333333e-06 6 (0.9, 0.05)\n",
      "3.33333333333e-06 6 (0.9, 0.45)\n",
      "3.33333333333e-06 6 (0.9, 0.7)\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(l_rate_lst)):\n",
    "    for k in range(len(r_list)):\n",
    "        for j in range(len(p_q_pairs)):\n",
    "            print l_rate_lst[l], r_list[k], p_q_pairs[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
