{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import  networkx as nx\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non backtacking matrix is similiar to message passing algorithms used to find clusters.  This works much better in the sparse case (especially since adjacency matrices in that case are very not full rank, so finding their eigenvectors...)\n",
    "\n",
    "Definition:\n",
    "\n",
    "Let M be the number of edges, then the matrix B, our non backtracking matrix will be a 2M by 2M matrix such that B_(ei-ej) = 1 if ei and ej are adjacent and are not just one edge, and 0 otherwise (i.e the diagonal should be zero). \n",
    "\n",
    "\n",
    "An interesting point is that the Bethe Hessian matrix should have similar performance, however is defined from the laplacian, with a regularizing r...that can be learned.  https://papers.nips.cc/paper/5520-spectral-clustering-of-graphs-with-the-bethe-hessian.pdf\n",
    "\n",
    "the Bethe Hessian Matrix is the deformed Laplacian is is simply:\n",
    "H(r): = (r^2 -1)1 - rA +D\n",
    "\n",
    "\n",
    "for the stochastic block model, optimal r's have been show to equal root(c) where c is the average degree of the graph.\n",
    "\n",
    "\n",
    "Compute eigenvectors associated with negative eigenvalues of both H(r_c) and H(-r_c)\n",
    "\n",
    "supposedly, the negative eigenvalues of H(r_c) reveal the assortative aspects, whereas H(-r_c) reviews the disassortative ones.\n",
    "\n",
    "Tests:\n",
    "\n",
    "Give a large dataset of stochastic block models with the same average degree, will it learn the correct r_c?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ÃŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def balanced_stochastic_blockmodel(communities=2, groupsize=3, p_in=1.0, p_out=0.0):\n",
    "    #gives dense adjacency matrix representaiton of randomly generated SBM with balanced community size\n",
    "\n",
    "    G = nx.planted_partition_graph(l=communities, k=groupsize, p_in=p_in, p_out =p_out)\n",
    "    A = nx.adjacency_matrix(G).todense()\n",
    "    \n",
    "    return A\n",
    "\n",
    "\n",
    "communities = 2 #number of communities, chance to \n",
    "group_size = 4 #number of nodes in each communitites (balanced so far)\n",
    "dim_graph = communities*group_size\n",
    "A = balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.15, p_out=0.01)\n",
    "print A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a dataset\n",
    "block_model = [balanced_stochastic_blockmodel() for i in range(9)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gather_cols(params, indices, name=None):\n",
    "    \"\"\"Gather columns of a 2D tensor.\n",
    "\n",
    "    Args:\n",
    "        params: A 2D tensor.\n",
    "        indices: A 1D tensor. Must be one of the following types: ``int32``, ``int64``.\n",
    "        name: A name for the operation (optional).\n",
    "\n",
    "    Returns:\n",
    "        A 2D Tensor. Has the same type as ``params``.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name, \"gather_cols\", [params, indices]) as scope:\n",
    "        # Check input\n",
    "        params = tf.convert_to_tensor(params, name=\"params\")\n",
    "        indices = tf.convert_to_tensor(indices, name=\"indices\")\n",
    "        try:\n",
    "            params.get_shape().assert_has_rank(2)\n",
    "        except ValueError:\n",
    "            raise ValueError('\\'params\\' must be 2D.')\n",
    "        try:\n",
    "            indices.get_shape().assert_has_rank(1)\n",
    "        except ValueError:\n",
    "            raise ValueError('\\'params\\' must be 1D.')\n",
    "\n",
    "        # Define op\n",
    "        p_shape = tf.shape(params)\n",
    "        p_flat = tf.reshape(params, [-1])\n",
    "        i_flat = tf.reshape(tf.reshape(tf.range(0, p_shape[0]) * p_shape[1],\n",
    "                                       [-1, 1]) + indices, [-1])\n",
    "        return tf.reshape(tf.gather(p_flat, i_flat),\n",
    "                          [p_shape[0], -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE IMPLEMENTATION\n",
    "## Not working so far....probably becasue of non-differentiable....\n",
    "\n",
    "This function we just test on the A above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.41298231] 0.375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Adj = tf.cast(A, tf.float32)\n",
    "Diag = tf.diag(tf.reduce_sum(Adj,0)) #just the diagonal matrix of degrees of Adj\n",
    "\n",
    "\n",
    "\n",
    "r =  tf.Variable(tf.random_normal(shape=[1], mean=0.0,\n",
    "                                 stddev=1.0, dtype=tf.float32,\n",
    "                                 seed=None, name=None))\n",
    "\n",
    "Bethe_Hesse_neg = (tf.square(r)-1)*tf.diag(tf.ones(shape=[dim_graph]))-tf.mul(r, Adj)+Diag \n",
    "\n",
    "eigenval, eigenvec = tf.self_adjoint_eig(Bethe_Hesse_neg)\n",
    "\n",
    "zeros = tf.zeros(shape=[1, dim_graph])\n",
    "\n",
    "\n",
    "eigenval_neg_bool = tf.less(eigenval, zeros)\n",
    "eigenval_neg_bool = tf.stop_gradient(eigenval_neg_bool)\n",
    "\n",
    "eigenval_neg_index = tf.squeeze(gather_cols(tf.where(eigenval_neg_bool), [1]))\n",
    "eigenval_neg_index = tf.cast(eigenval_neg_index, dtype = tf.int32)\n",
    "eigenval_neg_index = tf.stop_gradient(eigenval_neg_index)\n",
    "\n",
    "\n",
    "#num_centers = tf.shape(eigenval_neg_index) #arghh!  cannot get it to work as entry, using 2 for now\n",
    "#num_centers = tf.squeeze(num_centers)\n",
    "#num_centers = tf.shape(num_centers)\n",
    "\n",
    "\n",
    "\n",
    "eigenvec_neg = gather_cols(eigenvec, eigenval_neg_index)\n",
    "\n",
    "#cannot make this into an integer (right now using 2, ideally I want to use shape)\n",
    "#have random initialization errors when I make the bottom a shuffle\n",
    "#need fix for when it has no negative eigenvalues\n",
    "\n",
    "centroides_neg = tf.slice(eigenvec_neg,[0,0],[2,-1])\n",
    "\n",
    "\n",
    "\n",
    "expanded_Y = tf.expand_dims(eigenvec_neg, 0)\n",
    "\n",
    "expanded_centroides = tf.expand_dims(centroides_neg, 1)\n",
    "\n",
    "\n",
    "#be careful to make sure below is compatible with num_centers\n",
    "\n",
    "assignments_neg = tf.argmin(tf.reduce_sum(tf.square(tf.sub(expanded_Y, expanded_centroides)), 2), 0) #these are the clustering assignments based on current centroides\n",
    "assignments_neg = tf.stop_gradient(assignments_neg)\n",
    "\n",
    "\n",
    "centroides_neg = tf.concat(0, [tf.reduce_mean(tf.gather(eigenvec_neg, tf.reshape(tf.where( tf.equal(assignments_neg, c)),[1,-1])),reduction_indices=[1]) for c in xrange(2)])\n",
    "centroides_neg = tf.stop_gradient(centroides_neg)\n",
    "\n",
    "expanded_centroides = tf.expand_dims(centroides_neg, 1)\n",
    "\n",
    "assignments_neg = tf.argmin(tf.reduce_sum(tf.square(tf.sub(expanded_Y, expanded_centroides)), 2), 0) #these are the clustering assignments based on current centroides\n",
    "assignments_neg = tf.stop_gradient(assignments_neg)\n",
    "\n",
    "\n",
    "\n",
    "def cluster_error(assignment, group_size=group_size, communities=communities, dim_graph=dim_graph):\n",
    "    \"\"\"Takes in assignments and compares to the balanced two cluster\n",
    "    model of the random graph above\"\"\"\n",
    "    dim_graph = communities*group_size\n",
    "    true_assignment_a = tf.concat(0, [tf.zeros([group_size], dtype=tf.float32),\n",
    "                                      tf.ones([group_size], dtype=tf.float32)])\n",
    "    true_assignment_b = tf.concat(0, [tf.ones([group_size], dtype=tf.float32),\n",
    "                                      tf.zeros([group_size], dtype=tf.float32)])         \n",
    "    assignment = tf.cast(assignment, dtype = tf.float32)\n",
    "    loss = tf.minimum(tf.reduce_sum(tf.square(tf.sub(true_assignment_a, assignment))),\n",
    "                      tf.reduce_sum(tf.square(tf.sub(true_assignment_b, assignment))))\n",
    "    error = tf.div(loss, dim_graph)\n",
    "    \n",
    "    return loss, error\n",
    "\n",
    "\n",
    "loss_neg, error_neg = cluster_error(assignments_neg, group_size, communities, dim_graph)\n",
    "\n",
    "#optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "#train = optimizer.minimize(loss_neg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "init = tf.initialize_variables([r])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "#    sess.run(train)\n",
    "    sess.run([eigenval_neg_index, eigenval, eigenvec, eigenval_neg_bool])\n",
    "    a, r, b, c, d =  sess.run([r, eigenvec_neg, centroides_neg, assignments_neg, error_neg])\n",
    "    print a, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where the problems begin.  We cannot back prop through tf.less, tf.argmin....so we are working to fix this by  using functions that approximate them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ((None, <tensorflow.python.ops.variables.Variable object at 0x104648390>), (None, <tensorflow.python.ops.variables.Variable object at 0x11378a1d0>), (None, <tensorflow.python.ops.variables.Variable object at 0x11391af90>), (None, <tensorflow.python.ops.variables.Variable object at 0x1138c6850>), (None, <tensorflow.python.ops.variables.Variable object at 0x113ab8e10>), (None, <tensorflow.python.ops.variables.Variable object at 0x113a7eb90>), (None, <tensorflow.python.ops.variables.Variable object at 0x113cc6d90>), (None, <tensorflow.python.ops.variables.Variable object at 0x11413c3d0>), (None, <tensorflow.python.ops.variables.Variable object at 0x10441f050>), (None, <tensorflow.python.ops.variables.Variable object at 0x114127d10>))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b2a6a0e7b6a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/training/optimizer.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    196\u001b[0m         grad_loss=grad_loss)\n\u001b[1;32m    197\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n\u001b[0;32m--> 198\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m   def compute_gradients(self, loss, var_list=None,\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/training/optimizer.pyc\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, global_step, name)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\"No gradients provided for any variable: %s\" %\n\u001b[0;32m--> 298\u001b[0;31m                        (grads_and_vars,))\n\u001b[0m\u001b[1;32m    299\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_slots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: ((None, <tensorflow.python.ops.variables.Variable object at 0x104648390>), (None, <tensorflow.python.ops.variables.Variable object at 0x11378a1d0>), (None, <tensorflow.python.ops.variables.Variable object at 0x11391af90>), (None, <tensorflow.python.ops.variables.Variable object at 0x1138c6850>), (None, <tensorflow.python.ops.variables.Variable object at 0x113ab8e10>), (None, <tensorflow.python.ops.variables.Variable object at 0x113a7eb90>), (None, <tensorflow.python.ops.variables.Variable object at 0x113cc6d90>), (None, <tensorflow.python.ops.variables.Variable object at 0x11413c3d0>), (None, <tensorflow.python.ops.variables.Variable object at 0x10441f050>), (None, <tensorflow.python.ops.variables.Variable object at 0x114127d10>))"
     ]
    }
   ],
   "source": [
    "dim_graph = 3\n",
    "\n",
    "\n",
    "Adj = tf.Variable(tf.random_normal(shape=[dim_graph, dim_graph], mean=0.0,\n",
    "                                 stddev=1.0, dtype=tf.float32,\n",
    "                                 seed=1, name=None))\n",
    "r =  tf.Variable(tf.random_normal(shape=[1], mean=0.0,\n",
    "                                 stddev=1.0, dtype=tf.float32,\n",
    "                                 seed=None, name=None))\n",
    "Bethe_Hesse_neg = r*Adj\n",
    "\n",
    "eigenval, eigenvec = tf.self_adjoint_eig(Bethe_Hesse_neg)\n",
    "\n",
    "eigenvec_neg = eigenvec # Bethe_Hesse_neg\n",
    "\n",
    "\n",
    "zeros = tf.zeros(shape=[1, dim_graph])\n",
    "\n",
    "\n",
    "eigenval_neg_bool = tf.less(eigenval, zeros)\n",
    "eigenval_neg_bool = tf.stop_gradient(eigenval_neg_bool)\n",
    "\n",
    "eigenval_neg_index = tf.squeeze(gather_cols(tf.where(eigenval_neg_bool), [1]))\n",
    "eigenval_neg_index = tf.cast(eigenval_neg_index, dtype = tf.int32)\n",
    "eigenval_neg_index = tf.stop_gradient(eigenval_neg_index)\n",
    "\n",
    "\n",
    "#num_centers = tf.shape(eigenval_neg_index) #arghh!  cannot get it to work as entry, using 2 for now\n",
    "#num_centers = tf.squeeze(num_centers)\n",
    "#num_centers = tf.shape(num_centers)\n",
    "\n",
    "\n",
    "\n",
    "eigenvec_neg = gather_cols(eigenvec, eigenval_neg_index)\n",
    "\n",
    "assignments_neg = tf.reduce_sum(eigenvec_neg, 1)#assignments_neg = tf.reduce_sum(Bethe_Hesse_neg, 1)\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(assignments_neg))#tf.sub(assignments_neg, zeros)))\n",
    "\n",
    "error = tf.div(loss, dim_graph)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "var_grad = tf.gradients(loss, [r])\n",
    "\n",
    "init = tf.initialize_variables([r, Adj])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(train)\n",
    "    bh, a, b, c, r =  sess.run([eigenval, Bethe_Hesse_neg, error, loss, r])\n",
    "    print bh, a, c, r\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zeros = tf.zeros(shape = [dim_graph], dtype = tf.float32)\n",
    "\n",
    "centroides_neg = tf.slice(eigenvec_neg,[0,0],[2,-1])\n",
    "\n",
    "\n",
    "\n",
    "expanded_Y = tf.expand_dims(eigenvec_neg, 0)\n",
    "\n",
    "expanded_centroides = tf.expand_dims(centroides_neg, 1)\n",
    "\n",
    "\n",
    "#be careful to make sure below is compatible with num_centers\n",
    "\n",
    "assignments_neg = tf.argmax(tf.reduce_sum(tf.square(tf.sub(expanded_Y, expanded_centroides)), 2), 0) #these are the clustering assignments based on current centroides\n",
    "assignments_neg = tf.stop_gradient(assignments_neg)\n",
    "\n",
    "assignments_neg = tf.cast(assignments_neg, dtype = tf.float32)\n",
    "\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        batch = A\n",
    "        sess.run(init)\n",
    "        if i%2 == 0:\n",
    "            train_accuracy = sess.run(loss, feed_dict={ Adj:A})\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        sess.run(train_step,feed_dict={x: batch})\n",
    "\n",
    "    print(\"test accuracy %g\"% sess.run(loss, feed_dict={ \n",
    "       Adj: A}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "communities = 2 #number of communities, chance to \n",
    "group_size = 2 #number of nodes in each communitites (balanced so far)\n",
    "dim_graph = communities*group_size\n",
    "A = balanced_stochastic_blockmodel(communities=communities, \n",
    "                                   groupsize=group_size, p_in=0.25, p_out=0.01)\n",
    "print A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible shapes for broadcasting: (3, 3) and (8, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ea37c92e411e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mBethe_Hesse_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim_graph\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mDiag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_neg_eigenvectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   2301\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2302\u001b[0m   \"\"\"\n\u001b[0;32m-> 2303\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sub\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2304\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    701\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    702\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                            op_def=op_def)\n\u001b[0m\u001b[1;32m    704\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2334\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2336\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2337\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1723\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[1;32m   1724\u001b[0m                          % op.type)\n\u001b[0;32m-> 1725\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1726\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36m_BroadcastShape\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1817\u001b[0m   return [common_shapes.broadcast_shape(\n\u001b[1;32m   1818\u001b[0m       \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m       op.inputs[1].get_shape())]\n\u001b[0m\u001b[1;32m   1820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mbroadcast_shape\u001b[0;34m(shape_x, shape_y)\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m       raise ValueError(\"Incompatible shapes for broadcasting: %s and %s\"\n\u001b[0;32m--> 588\u001b[0;31m                        % (shape_x, shape_y))\n\u001b[0m\u001b[1;32m    589\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: (3, 3) and (8, 8)"
     ]
    }
   ],
   "source": [
    "Adj = tf.cast(A, tf.float32)\n",
    "Diag = tf.diag(tf.reduce_sum(Adj,0)) #just the diagonal matrix of degrees of Adj\n",
    "\n",
    "\n",
    "\n",
    "r =  tf.Variable(tf.random_normal(shape=[1], mean=0.0,\n",
    "                                 stddev=1.0, dtype=tf.float32,\n",
    "                                 seed=None, name=None))\n",
    "#tf.constant(1, dtype=tf.float32)#\n",
    "\n",
    "\n",
    "Bethe_Hesse_neg = (tf.square(r)-1)*tf.diag(tf.ones(shape=[dim_graph]))-tf.mul(r, Adj)+Diag \n",
    "\n",
    "def get_neg_eigenvectors(A, dim_graph=dim_graph, group_size=group_size):\n",
    "    \"\"\"gets neg eigenvalues of matrix, \n",
    "    this may not be a differentiable opeartor\n",
    "    so let's set it to take the last n/2 eigenvalues as usual\n",
    "    \"\"\"\n",
    "    dim_graph = communities*group_size\n",
    "    eigenval, eigenvec = tf.self_adjoint_eig(A)\n",
    "    return eigenval, tf.slice(eigenvec, [0, 0], [dim_graph, group_size])\n",
    "\n",
    "\n",
    "def cluster_error(assignment, group_size=group_size, communities=communities, dim_graph=dim_graph):\n",
    "    \"\"\"Takes in assignments and compares to the balanced two cluster\n",
    "    model of the random graph above\"\"\"\n",
    "    dim_graph = communities*group_size\n",
    "    true_assignment_a = tf.concat(0, [tf.zeros([group_size], dtype=tf.float32),\n",
    "                                      tf.ones([group_size], dtype=tf.float32)])\n",
    "    true_assignment_b = tf.concat(0, [tf.ones([group_size], dtype=tf.float32),\n",
    "                                      tf.zeros([group_size], dtype=tf.float32)])         \n",
    "    assignment = tf.cast(assignment, dtype = tf.float32)\n",
    "    loss = tf.minimum(tf.reduce_sum(tf.square(tf.sub(true_assignment_a, assignment))),\n",
    "                      tf.reduce_sum(tf.square(tf.sub(true_assignment_b, assignment))))\n",
    "    error = tf.div(loss, dim_graph)\n",
    "    \n",
    "    return loss, error\n",
    "\n",
    "\n",
    "\n",
    "Y = get_neg_eigenvectors(Bethe_Hesse_neg, dim_graph, group_size)[1]\n",
    "centroides_neg = tf.Variable(tf.slice(tf.random_shuffle(Y),[0,0],[communities,-1]))\n",
    "expanded_Y = tf.expand_dims(Y, 0)\n",
    "expanded_centroides = tf.expand_dims(centroides_neg, 1)\n",
    "assignments_neg = tf.argmin(tf.reduce_sum(tf.square(tf.sub(expanded_Y, expanded_centroides)), 2), 0) #these are the clustering assignments based on current centroides\n",
    "means_neg = tf.concat(0, [tf.reduce_mean(tf.gather(Y, tf.reshape(tf.where( tf.equal(assignments_neg, c)),[1,-1])),\n",
    "                                         reduction_indices=[1]) for c in xrange(communities)])\n",
    "    \n",
    "    \n",
    "update_centroides_neg = tf.assign(centroides_neg, means_neg)\n",
    "loss_neg, error_neg = cluster_error(assignments_neg, group_size, communities, dim_graph)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss_neg)\n",
    "\n",
    "\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(train)\n",
    "    for steps in xrange(1):\n",
    "        sess.run([update_centroides_neg, centroides_neg, assignments_neg])\n",
    "        a, b, c, d = sess.run([centroides_neg, error_neg, assignments_neg, loss_neg])\n",
    "        print 'Using the Besse Hessian Matrix, the assignment of clusters for each node is {}, with error rate of {}'.format(c, b)\n",
    "        print 'loss is {}'.format(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tfnighly]",
   "language": "python",
   "name": "conda-env-tfnighly-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
