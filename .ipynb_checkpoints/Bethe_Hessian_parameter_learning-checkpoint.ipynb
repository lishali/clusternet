{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import  networkx as nx\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non backtacking matrix is similiar to message passing algorithms used to find clusters.  This works much better in the sparse case (especially since adjacency matrices in that case are very not full rank, so finding their eigenvectors...)\n",
    "\n",
    "Definition:\n",
    "\n",
    "Let M be the number of edges, then the matrix B, our non backtracking matrix will be a 2M by 2M matrix such that B_(ei-ej) = 1 if ei and ej are adjacent and are not just one edge, and 0 otherwise (i.e the diagonal should be zero). \n",
    "\n",
    "\n",
    "An interesting point is that the Bethe Hessian matrix should have similar performance, however is defined from the laplacian, with a regularizing r...that can be learned.  https://papers.nips.cc/paper/5520-spectral-clustering-of-graphs-with-the-bethe-hessian.pdf\n",
    "\n",
    "the Bethe Hessian Matrix is the deformed Laplacian is is simply:\n",
    "H(r): = (r^2 -1)1 - rA +D\n",
    "\n",
    "\n",
    "for the stochastic block model, optimal r's have been show to equal root(c) where c is the average degree of the graph.\n",
    "\n",
    "\n",
    "Compute eigenvectors associated with negative eigenvalues of both H(r_c) and H(-r_c)\n",
    "\n",
    "supposedly, the negative eigenvalues of H(r_c) reveal the assortative aspects, whereas H(-r_c) reviews the disassortative ones.\n",
    "\n",
    "Tests:\n",
    "\n",
    "Give a large dataset of stochastic block models with the same average degree, will it learn the correct r_c?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 1 ..., 1 0 1]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 1 0 ..., 0 1 0]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'laplacian' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-f6097960bd00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0massignment_laplacian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans_laplacian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroides_laplacian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_means_spectral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlaplacian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommunities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mupdate_centroides_laplacian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroides_laplacian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans_laplacian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mloss_laplacian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_laplacian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massignment_laplacian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'laplacian' is not defined"
     ]
    }
   ],
   "source": [
    "communities = 2 #number of communities, chance to \n",
    "group_size = 20 #number of nodes in each communitites (balanced so far)\n",
    "dim_graph = communities*group_size\n",
    "A = balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.29, p_out=0.1)\n",
    "\n",
    "print A\n",
    "\n",
    "Adj = tf.cast(A, tf.float32)\n",
    "Diag = tf.diag(tf.reduce_sum(Adj,0)) #just the diagonal matrix of degrees of Adj\n",
    "r = tf.Variable(tf.random_normal(shape=[1], mean=0.0,\n",
    "                                 stddev=10.0, dtype=tf.float32,\n",
    "                                 seed=None, name=None))\n",
    "Bethe_Hesse = (tf.square(r)-1)*tf.diag(tf.ones(shape=[dim_graph]))-tf.mul(r, Adj)+Diag \n",
    "\n",
    "\n",
    "assignment_laplacian, means_laplacian, centroides_laplacian = k_means_spectral(laplacian, communities, group_size)\n",
    "update_centroides_laplacian = tf.assign(centroides_laplacian, means_laplacian)\n",
    "loss_laplacian, error_laplacian = cluster_error(assignment_laplacian, group_size)\n",
    "\n",
    "assignment_adj, means_adj, centroides_adj = k_means_spectral(Adj, communities, group_size)\n",
    "update_centroides_adj = tf.assign(centroides_adj, means_adj)\n",
    "loss_adj, error_adj = cluster_error(assignment_adj, group_size)\n",
    "\n",
    "\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print sess.run(Bethe_Hesse)\n",
    "    \n",
    "    \n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) #, feed_dict = {x: A})\n",
    "    for step in xrange(10):\n",
    "        sess.run([update_centroides_adj, update_centroides_laplacian, assignment_adj, assignment_laplacian])\n",
    "    a, b, c, d = sess.run([assignment_laplacian, assignment_adj, error_adj, error_laplacian])\n",
    "    print 'Using the Laplacian, the assignment of clusters for each node is {}, with error rate of {}.'.format(a, d)\n",
    "    print 'Using the adjacency matrix, the assignment of clusters for each node is {}, with error rate of {}'.format(b, c)\n",
    "    print \"Note that a random guess of a balanced partition will on average overlap with the correct clustering by 50%,but we are taking the min of two binomial's--since we wanted it to be invariant under labellings, so randomly we will do a little better than 50% error, min of two binomial 1/2.  But for bigger and bigger vectors this will approach 1/2. \"\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ÃŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "communities = 2 #number of communities, chance to \n",
    "group_size = 3 \n",
    "def get_eigenvectors(A, communities=communities, group_size=group_size):\n",
    "    \"\"\"gets first k eigenvalues of matrix\"\"\"\n",
    "    dim_graph = communities*group_size\n",
    "    eigenval, eigenvec = tf.self_adjoint_eig(A)\n",
    "    return tf.slice(eigenvec, [0, dim_graph-communities], [dim_graph, communities])\n",
    "\n",
    "def k_means_spectral(A, communities=communities, group_size=group_size):\n",
    "    \"\"\"takes in matrix, does k means on first k eignvectors \n",
    "    Y where rows are the data points\"\"\"    \n",
    "\n",
    "    Y = get_eigenvectors(A, communities, group_size)\n",
    "    centroides = tf.Variable(tf.slice(tf.random_shuffle(Y),[0,0],[communities,-1]))\n",
    "    expanded_Y = tf.expand_dims(Y, 0)\n",
    "    expanded_centroides = tf.expand_dims(centroides, 1)\n",
    "    assignments = tf.argmin(tf.reduce_sum(tf.square(tf.sub(expanded_Y, expanded_centroides)), 2), 0) #these are the clustering assignments based on current centroides\n",
    "    means = tf.concat(0, [tf.reduce_mean(tf.gather(Y, tf.reshape(tf.where( tf.equal(assignments, c)),[1,-1])),\n",
    "                                     reduction_indices=[1]) for c in xrange(communities)])\n",
    "    \n",
    "    return assignments, means, centroides\n",
    "\n",
    "def cluster_error(assignment, group_size=group_size, communities=communities):\n",
    "    \"\"\"Takes in assignments and compares to the balanced two cluster\n",
    "    model of the random graph above\"\"\"\n",
    "    dim_graph = communities*group_size\n",
    "    true_assignment_a = tf.concat(0, [tf.zeros([group_size], dtype=tf.float32),\n",
    "                                      tf.ones([group_size], dtype=tf.float32)])\n",
    "    true_assignment_b = tf.concat(0, [tf.ones([group_size], dtype=tf.float32),\n",
    "                                      tf.zeros([group_size], dtype=tf.float32)])         \n",
    "    assignment = tf.cast(assignment, dtype = tf.float32)\n",
    "    loss = tf.minimum(tf.reduce_sum(tf.square(tf.sub(true_assignment_a, assignment))),\n",
    "                      tf.reduce_sum(tf.square(tf.sub(true_assignment_b, assignment))))\n",
    "    error = tf.div(loss, dim_graph)\n",
    "    \n",
    "    return loss, error\n",
    "\n",
    "\n",
    "## the following functions allows us to verify that permuted adjacency matrices shoudl have no effect on the network\n",
    "#of course, which no power method, this is just true by construction but good to have anyways \n",
    "\n",
    "def joint_permutation(A):\n",
    "    #takes adjacency matrix and relabels, gives out permutated adjacency matrix of same relationship\n",
    "    random_shuffle = np.random.permutation(len(A))\n",
    "\n",
    "    A_shuffle = A[random_shuffle]\n",
    "    A_shuffle = np.transpose(A_shuffle)\n",
    "    A_shuffle = A_shuffle[random_shuffle]\n",
    "\n",
    "    return A_shuffle, random_shuffle\n",
    "\n",
    "def balanced_stochastic_blockmodel(communities=2, groupsize=3, p_in=1.0, p_out=0.0):\n",
    "    #gives dense adjacency matrix representaiton of randomly generated SBM with balanced community size\n",
    "\n",
    "    G = nx.planted_partition_graph(l=communities, k=groupsize, p_in=p_in, p_out =p_out)\n",
    "    A = nx.adjacency_matrix(G).todense()\n",
    "    \n",
    "    return A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value Variable\n\t [[Node: Variable/read = Identity[T=DT_FLOAT, _class=[\"loc:@Variable\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable)]]\nCaused by op u'Variable/read', defined at:\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 498, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-185-8000aa7c3336>\", line 10, in <module>\n    seed=None, name=None))\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 215, in __init__\n    dtype=dtype)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 327, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1106, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2334, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1253, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-185-8000aa7c3336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, feed_dict = {x: A})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_centroides_adj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massignment_adj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_adj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable\n\t [[Node: Variable/read = Identity[T=DT_FLOAT, _class=[\"loc:@Variable\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable)]]\nCaused by op u'Variable/read', defined at:\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 498, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-185-8000aa7c3336>\", line 10, in <module>\n    seed=None, name=None))\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 215, in __init__\n    dtype=dtype)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 327, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1106, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2334, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1253, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "communities = 2 #number of communities, chance to \n",
    "group_size = 4 #number of nodes in each communitites (balanced so far)\n",
    "dim_graph = communities*group_size\n",
    "A = balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.15, p_out=0.01)\n",
    "\n",
    "Adj = tf.cast(A, tf.float32)\n",
    "Diag = tf.diag(tf.reduce_sum(Adj,0)) #just the diagonal matrix of degrees of Adj\n",
    "r = tf.Variable(tf.random_normal(shape=[1], mean=0.0,\n",
    "                                 stddev=1.0, dtype=tf.float32,\n",
    "                                 seed=None, name=None))\n",
    "\n",
    "\n",
    "Bethe_Hesse_neg = (tf.square(r)-1)*tf.diag(tf.ones(shape=[dim_graph]))-tf.mul(r, Adj)+Diag \n",
    "\n",
    "def get_neg_eigenvectors(A, dim_graph=dim_graph):\n",
    "    \"\"\"gets neg eigenvalues of matrix, \n",
    "    this may not be a differentiable opeartor\n",
    "    so let's set it to take the last k eigenvalues as usual\n",
    "    \"\"\"\n",
    "    dim_graph = communities*group_size\n",
    "    eigenval, eigenvec = tf.self_adjoint_eig(A)\n",
    "    return eigenval, tf.slice(eigenvec, [0, 0], [dim_graph, group_size])\n",
    "\n",
    "def k_means_spectral(A, dim_graph=dim_graph, communities=communities):\n",
    "    \"\"\"takes in matrix, does k means on first k eignvectors \n",
    "    Y where rows are the data points\"\"\"    \n",
    "\n",
    "    Y = get_neg_eigenvectors(A, dim_graph)[1]\n",
    "    centroides = tf.Variable(tf.slice(tf.random_shuffle(Y),[0,0],[communities,-1]))\n",
    "    expanded_Y = tf.expand_dims(Y, 0)\n",
    "    expanded_centroides = tf.expand_dims(centroides, 1)\n",
    "    assignments = tf.argmin(tf.reduce_sum(tf.square(tf.sub(expanded_Y, expanded_centroides)), 2), 0) #these are the clustering assignments based on current centroides\n",
    "    means = tf.concat(0, [tf.reduce_mean(tf.gather(Y, tf.reshape(tf.where( tf.equal(assignments, c)),[1,-1])),\n",
    "                                     reduction_indices=[1]) for c in xrange(communities)])\n",
    "    \n",
    "    return assignments, means, centroides\n",
    "\n",
    "\n",
    "def cluster_error(assignment, group_size=group_size, communities=communities):\n",
    "    \"\"\"Takes in assignments and compares to the balanced two cluster\n",
    "    model of the random graph above\"\"\"\n",
    "    dim_graph = communities*group_size\n",
    "    true_assignment_a = tf.concat(0, [tf.zeros([group_size], dtype=tf.float32),\n",
    "                                      tf.ones([group_size], dtype=tf.float32)])\n",
    "    true_assignment_b = tf.concat(0, [tf.ones([group_size], dtype=tf.float32),\n",
    "                                      tf.zeros([group_size], dtype=tf.float32)])         \n",
    "    assignment = tf.cast(assignment, dtype = tf.float32)\n",
    "    loss = tf.minimum(tf.reduce_sum(tf.square(tf.sub(true_assignment_a, assignment))),\n",
    "                      tf.reduce_sum(tf.square(tf.sub(true_assignment_b, assignment))))\n",
    "    error = tf.div(loss, dim_graph)\n",
    "    \n",
    "    return error\n",
    "\n",
    "\n",
    "assignment_adj, means_adj, centroides_adj = k_means_spectral(Bethe_Hesse_neg, communities, group_size)\n",
    "update_centroides_adj = tf.assign(centroides_adj, means_adj)\n",
    "error_adj = cluster_error(assignment_adj, group_size, communities)\n",
    "\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) #, feed_dict = {x: A})\n",
    "    for step in xrange(10):\n",
    "        sess.run([update_centroides_adj, assignment_adj, error_adj])\n",
    "        a, b = sess.run([assignment_adj, error_adj])\n",
    "        print 'Using the Besse Hessian Matrix, the assignment of clusters for each node is {}, with error rate of {}'.format(a, b)\n",
    "  \n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print sess.run([Y, centroides, assignments, means, tmp])\n",
    "\n",
    "    \n",
    "\n",
    "init = tf.initialize_all_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tfnighly]",
   "language": "python",
   "name": "conda-env-tfnighly-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
