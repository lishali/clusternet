{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import  networkx as nx\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non backtacking matrix is similiar to message passing algorithms used to find clusters.  This works much better in the sparse case (especially since adjacency matrices in that case are very not full rank, so finding their eigenvectors...)\n",
    "\n",
    "Definition:\n",
    "\n",
    "Let M be the number of edges, then the matrix B, our non backtracking matrix will be a 2M by 2M matrix such that B_(ei-ej) = 1 if ei and ej are adjacent and are not just one edge, and 0 otherwise (i.e the diagonal should be zero). \n",
    "\n",
    "\n",
    "An interesting point is that the Bethe Hessian matrix should have similar performance, however is defined from the laplacian, with a regularizing r...that can be learned.  https://papers.nips.cc/paper/5520-spectral-clustering-of-graphs-with-the-bethe-hessian.pdf\n",
    "\n",
    "the Bethe Hessian Matrix is the deformed Laplacian is is simply:\n",
    "H(r): = (r^2 -1)1 - rA +D\n",
    "\n",
    "\n",
    "for the stochastic block model, optimal r's have been show to equal root(c) where c is the average degree of the graph.\n",
    "\n",
    "\n",
    "Compute eigenvectors associated with negative eigenvalues of both H(r_c) and H(-r_c)\n",
    "\n",
    "supposedly, the negative eigenvalues of H(r_c) reveal the assortative aspects, whereas H(-r_c) reviews the disassortative ones.\n",
    "\n",
    "Tests:\n",
    "\n",
    "Give a large dataset of stochastic block models with the same average degree, will it learn the correct r_c?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ÃŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def balanced_stochastic_blockmodel(communities=2, groupsize=3, p_in=1.0, p_out=0.0):\n",
    "    #gives dense adjacency matrix representaiton of randomly generated SBM with balanced community size\n",
    "\n",
    "    G = nx.planted_partition_graph(l=communities, k=groupsize, p_in=p_in, p_out =p_out)\n",
    "    A = nx.adjacency_matrix(G).todense()\n",
    "    \n",
    "    return A\n",
    "\n",
    "\n",
    "communities = 2 #number of communities, chance to \n",
    "group_size = 4 #number of nodes in each communitites (balanced so far)\n",
    "dim_graph = communities*group_size\n",
    "A = balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.15, p_out=0.01)\n",
    "print A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ((None, <tensorflow.python.ops.variables.Variable object at 0x116317b50>), (None, <tensorflow.python.ops.variables.Variable object at 0x114ab2b50>), (None, <tensorflow.python.ops.variables.Variable object at 0x1159d5bd0>), (None, <tensorflow.python.ops.variables.Variable object at 0x11517b310>), (None, <tensorflow.python.ops.variables.Variable object at 0x115115b50>), (None, <tensorflow.python.ops.variables.Variable object at 0x114014f90>))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-8a9da0518d9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/training/optimizer.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    196\u001b[0m         grad_loss=grad_loss)\n\u001b[1;32m    197\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n\u001b[0;32m--> 198\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m   def compute_gradients(self, loss, var_list=None,\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/training/optimizer.pyc\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, global_step, name)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\"No gradients provided for any variable: %s\" %\n\u001b[0;32m--> 298\u001b[0;31m                        (grads_and_vars,))\n\u001b[0m\u001b[1;32m    299\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_slots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: ((None, <tensorflow.python.ops.variables.Variable object at 0x116317b50>), (None, <tensorflow.python.ops.variables.Variable object at 0x114ab2b50>), (None, <tensorflow.python.ops.variables.Variable object at 0x1159d5bd0>), (None, <tensorflow.python.ops.variables.Variable object at 0x11517b310>), (None, <tensorflow.python.ops.variables.Variable object at 0x115115b50>), (None, <tensorflow.python.ops.variables.Variable object at 0x114014f90>))"
     ]
    }
   ],
   "source": [
    "Adj = tf.cast(A, tf.float32)\n",
    "Diag = tf.diag(tf.reduce_sum(Adj,0)) #just the diagonal matrix of degrees of Adj\n",
    "\n",
    "\n",
    "\n",
    "r =  tf.Variable(tf.random_normal(shape=[1], mean=0.0,\n",
    "                                 stddev=1.0, dtype=tf.float32,\n",
    "                                 seed=None, name=None))\n",
    "#tf.constant(1, dtype=tf.float32)#\n",
    "\n",
    "\n",
    "Bethe_Hesse_neg = (tf.square(r)-1)*tf.diag(tf.ones(shape=[dim_graph]))-tf.mul(r, Adj)+Diag \n",
    "\n",
    "def get_neg_eigenvectors(A, dim_graph=dim_graph, group_size=group_size):\n",
    "    \"\"\"gets neg eigenvalues of matrix, \n",
    "    this may not be a differentiable opeartor\n",
    "    so let's set it to take the last n/2 eigenvalues as usual\n",
    "    \"\"\"\n",
    "    dim_graph = communities*group_size\n",
    "    eigenval, eigenvec = tf.self_adjoint_eig(A)\n",
    "    return eigenval, tf.slice(eigenvec, [0, 0], [dim_graph, group_size])\n",
    "\n",
    "\n",
    "def cluster_error(assignment, group_size=group_size, communities=communities, dim_graph=dim_graph):\n",
    "    \"\"\"Takes in assignments and compares to the balanced two cluster\n",
    "    model of the random graph above\"\"\"\n",
    "    dim_graph = communities*group_size\n",
    "    true_assignment_a = tf.concat(0, [tf.zeros([group_size], dtype=tf.float32),\n",
    "                                      tf.ones([group_size], dtype=tf.float32)])\n",
    "    true_assignment_b = tf.concat(0, [tf.ones([group_size], dtype=tf.float32),\n",
    "                                      tf.zeros([group_size], dtype=tf.float32)])         \n",
    "    assignment = tf.cast(assignment, dtype = tf.float32)\n",
    "    loss = tf.minimum(tf.reduce_sum(tf.square(tf.sub(true_assignment_a, assignment))),\n",
    "                      tf.reduce_sum(tf.square(tf.sub(true_assignment_b, assignment))))\n",
    "    error = tf.div(loss, dim_graph)\n",
    "    \n",
    "    return loss, error\n",
    "\n",
    "\n",
    "\n",
    "Y = get_neg_eigenvectors(Bethe_Hesse_neg, dim_graph, group_size)[1]\n",
    "centroides_neg = tf.Variable(tf.slice(tf.random_shuffle(Y),[0,0],[communities,-1]))\n",
    "expanded_Y = tf.expand_dims(Y, 0)\n",
    "expanded_centroides = tf.expand_dims(centroides_neg, 1)\n",
    "assignments_neg = tf.argmin(tf.reduce_sum(tf.square(tf.sub(expanded_Y, expanded_centroides)), 2), 0) #these are the clustering assignments based on current centroides\n",
    "means_neg = tf.concat(0, [tf.reduce_mean(tf.gather(Y, tf.reshape(tf.where( tf.equal(assignments_neg, c)),[1,-1])),\n",
    "                                         reduction_indices=[1]) for c in xrange(communities)])\n",
    "    \n",
    "    \n",
    "update_centroides_neg = tf.assign(centroides_neg, means_neg)\n",
    "loss_neg, error_neg = cluster_error(assignments_neg, group_size, communities, dim_graph)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss_neg)\n",
    "\n",
    "\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(train)\n",
    "    for steps in xrange(1):\n",
    "        sess.run([update_centroides_neg, centroides_neg, assignments_neg])\n",
    "        a, b, c, d = sess.run([centroides_neg, error_neg, assignments_neg, loss_neg])\n",
    "        print 'Using the Besse Hessian Matrix, the assignment of clusters for each node is {}, with error rate of {}'.format(c, b)\n",
    "        print 'loss is {}'.format(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gather_cols(params, indices, name=None):\n",
    "    \"\"\"Gather columns of a 2D tensor.\n",
    "\n",
    "    Args:\n",
    "        params: A 2D tensor.\n",
    "        indices: A 1D tensor. Must be one of the following types: ``int32``, ``int64``.\n",
    "        name: A name for the operation (optional).\n",
    "\n",
    "    Returns:\n",
    "        A 2D Tensor. Has the same type as ``params``.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name, \"gather_cols\", [params, indices]) as scope:\n",
    "        # Check input\n",
    "        params = tf.convert_to_tensor(params, name=\"params\")\n",
    "        indices = tf.convert_to_tensor(indices, name=\"indices\")\n",
    "        try:\n",
    "            params.get_shape().assert_has_rank(2)\n",
    "        except ValueError:\n",
    "            raise ValueError('\\'params\\' must be 2D.')\n",
    "        try:\n",
    "            indices.get_shape().assert_has_rank(1)\n",
    "        except ValueError:\n",
    "            raise ValueError('\\'params\\' must be 1D.')\n",
    "\n",
    "        # Define op\n",
    "        p_shape = tf.shape(params)\n",
    "        p_flat = tf.reshape(params, [-1])\n",
    "        i_flat = tf.reshape(tf.reshape(tf.range(0, p_shape[0]) * p_shape[1],\n",
    "                                       [-1, 1]) + indices, [-1])\n",
    "        return tf.reshape(tf.gather(p_flat, i_flat),\n",
    "                          [p_shape[0], -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "communities = 2 #number of communities, chance to \n",
    "group_size = 2 #number of nodes in each communitites (balanced so far)\n",
    "dim_graph = communities*group_size\n",
    "A = balanced_stochastic_blockmodel(communities=communities, \n",
    "                                   groupsize=group_size, p_in=0.25, p_out=0.01)\n",
    "print A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2] [[ 0.          0.          0.70710677]\n",
      " [ 0.          0.          0.70710677]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 0.          1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Adj = tf.cast(A, tf.float32)\n",
    "Diag = tf.diag(tf.reduce_sum(Adj,0)) #just the diagonal matrix of degrees of Adj\n",
    "\n",
    "\n",
    "\n",
    "r =  tf.Variable(tf.random_normal(shape=[1], mean=0.0,\n",
    "                                 stddev=1.0, dtype=tf.float32,\n",
    "                                 seed=None, name=None))\n",
    "\n",
    "Bethe_Hesse_neg = (tf.square(r)-1)*tf.diag(tf.ones(shape=[dim_graph]))-tf.mul(r, Adj)+Diag \n",
    "\n",
    "eigenval, eigenvec = tf.self_adjoint_eig(Bethe_Hesse_neg)\n",
    "\n",
    "zeros = tf.zeros(shape=[1, dim_graph])\n",
    "\n",
    "eigenval_neg_bool = tf.less(eigenval, zeros)\n",
    "\n",
    "eigenval_neg_index = tf.squeeze(gather_cols(tf.where(eigenval_neg_bool), [1]))\n",
    "eigenval_neg_index = tf.cast(eigenval_neg_index, dtype = tf.int32)\n",
    "\n",
    "eigenvec_neg = gather_cols(eigenvec, eigenval_neg_index)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run([eigenval_neg_index, eigenval, eigenvec, eigenval_neg_bool])\n",
    "    a, b, c, d, e= sess.run([eigenval_neg_index, eigenval, eigenvec, eigenvec_neg, eigenval_neg_bool])\n",
    "    print a, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?tf.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tfnighly]",
   "language": "python",
   "name": "conda-env-tfnighly-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
