{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import  networkx as nx\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non backtacking matrix is similiar to message passing algorithms used to find clusters.  This works much better in the sparse case (especially since adjacency matrices in that case are very not full rank, so finding their eigenvectors...)\n",
    "\n",
    "Definition:\n",
    "\n",
    "Let M be the number of edges, then the matrix B, our non backtracking matrix will be a 2M by 2M matrix such that B_(ei-ej) = 1 if ei and ej are adjacent and are not just one edge, and 0 otherwise (i.e the diagonal should be zero). \n",
    "\n",
    "\n",
    "An interesting point is that the Bethe Hessian matrix should have similar performance, however is defined from the laplacian, with a regularizing r...that can be learned.  https://papers.nips.cc/paper/5520-spectral-clustering-of-graphs-with-the-bethe-hessian.pdf\n",
    "\n",
    "the Bethe Hessian Matrix is the deformed Laplacian is is simply:\n",
    "H(r): = (r^2 -1)1 - rA +D\n",
    "\n",
    "\n",
    "for the stochastic block model, optimal r's have been show to equal root(c) where c is the average degree of the graph.\n",
    "\n",
    "\n",
    "Compute eigenvectors associated with negative eigenvalues of both H(r_c) and H(-r_c)\n",
    "\n",
    "supposedly, the negative eigenvalues of H(r_c) reveal the assortative aspects, whereas H(-r_c) reviews the disassortative ones.\n",
    "\n",
    "Tests:\n",
    "\n",
    "Give a large dataset of stochastic block models with the same average degree, will it learn the correct r_c?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ÃŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def balanced_stochastic_blockmodel(communities=2, groupsize=3, p_in=1.0, p_out=0.0):\n",
    "    #gives dense adjacency matrix representaiton of randomly generated SBM with balanced community size\n",
    "\n",
    "    G = nx.planted_partition_graph(l=communities, k=groupsize, p_in=p_in, p_out =p_out)\n",
    "    A = nx.adjacency_matrix(G).todense()\n",
    "    \n",
    "    return A\n",
    "\n",
    "\n",
    "communities = 2 #number of communities, chance to \n",
    "group_size = 4 #number of nodes in each communitites (balanced so far)\n",
    "dim_graph = communities*group_size\n",
    "A = balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.15, p_out=0.01)\n",
    "print A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a dataset\n",
    "block_model = [balanced_stochastic_blockmodel() for i in range(9)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gather_cols(params, indices, name=None):\n",
    "    \"\"\"Gather columns of a 2D tensor.\n",
    "\n",
    "    Args:\n",
    "        params: A 2D tensor.\n",
    "        indices: A 1D tensor. Must be one of the following types: ``int32``, ``int64``.\n",
    "        name: A name for the operation (optional).\n",
    "\n",
    "    Returns:\n",
    "        A 2D Tensor. Has the same type as ``params``.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name, \"gather_cols\", [params, indices]) as scope:\n",
    "        # Check input\n",
    "        params = tf.convert_to_tensor(params, name=\"params\")\n",
    "        indices = tf.convert_to_tensor(indices, name=\"indices\")\n",
    "        try:\n",
    "            params.get_shape().assert_has_rank(2)\n",
    "        except ValueError:\n",
    "            raise ValueError('\\'params\\' must be 2D.')\n",
    "        try:\n",
    "            indices.get_shape().assert_has_rank(1)\n",
    "        except ValueError:\n",
    "            raise ValueError('\\'params\\' must be 1D.')\n",
    "\n",
    "        # Define op\n",
    "        p_shape = tf.shape(params)\n",
    "        p_flat = tf.reshape(params, [-1])\n",
    "        i_flat = tf.reshape(tf.reshape(tf.range(0, p_shape[0]) * p_shape[1],\n",
    "                                       [-1, 1]) + indices, [-1])\n",
    "        return tf.reshape(tf.gather(p_flat, i_flat),\n",
    "                          [p_shape[0], -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE IMPLEMENTATION\n",
    "## Not working so far....probably becasue of non-differentiable....\n",
    "\n",
    "This function we just test on the A above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.44863907] 0.375\n"
     ]
    }
   ],
   "source": [
    "communities = 2 #number of communities, chance to \n",
    "group_size = 4 #number of nodes in each communitites (balanced so far)\n",
    "dim_graph = communities*group_size\n",
    "A = balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.15, p_out=0.01)\n",
    "\n",
    "Adj = tf.cast(A, tf.float32)\n",
    "Diag = tf.diag(tf.reduce_sum(Adj,0)) #just the diagonal matrix of degrees of Adj\n",
    "\n",
    "\n",
    "\n",
    "r =  tf.Variable(tf.random_normal(shape=[1], mean=0.0,\n",
    "                                 stddev=1.0, dtype=tf.float32,\n",
    "                                 seed=None, name=None))\n",
    "\n",
    "Bethe_Hesse_neg = (tf.square(r)-1)*tf.diag(tf.ones(shape=[dim_graph]))-tf.mul(r, Adj)+Diag \n",
    "\n",
    "eigenval, eigenvec = tf.self_adjoint_eig(Bethe_Hesse_neg)\n",
    "\n",
    "zeros = tf.zeros(shape=[1, dim_graph])\n",
    "\n",
    "\n",
    "eigenval_neg_bool = tf.less(eigenval, zeros)\n",
    "eigenval_neg_bool = tf.stop_gradient(eigenval_neg_bool)\n",
    "\n",
    "eigenval_neg_index = tf.squeeze(gather_cols(tf.where(eigenval_neg_bool), [1]))\n",
    "eigenval_neg_index = tf.cast(eigenval_neg_index, dtype = tf.int32)\n",
    "eigenval_neg_index = tf.stop_gradient(eigenval_neg_index)\n",
    "\n",
    "\n",
    "#num_centers = tf.shape(eigenval_neg_index) #arghh!  cannot get it to work as entry, using 2 for now\n",
    "#num_centers = tf.squeeze(num_centers)\n",
    "#num_centers = tf.shape(num_centers)\n",
    "\n",
    "\n",
    "\n",
    "eigenvec_neg = gather_cols(eigenvec, eigenval_neg_index)\n",
    "\n",
    "#cannot make this into an integer (right now using 2, ideally I want to use shape)\n",
    "#have random initialization errors when I make the bottom a shuffle\n",
    "#need fix for when it has no negative eigenvalues\n",
    "\n",
    "centroides_neg = tf.slice(eigenvec_neg,[0,0],[2,-1])\n",
    "\n",
    "\n",
    "\n",
    "expanded_Y = tf.expand_dims(eigenvec_neg, 0)\n",
    "\n",
    "expanded_centroides = tf.expand_dims(centroides_neg, 1)\n",
    "\n",
    "\n",
    "#be careful to make sure below is compatible with num_centers\n",
    "\n",
    "assignments_neg = tf.argmin(tf.reduce_sum(tf.square(tf.sub(expanded_Y, expanded_centroides)), 2), 0) #these are the clustering assignments based on current centroides\n",
    "assignments_neg = tf.stop_gradient(assignments_neg)\n",
    "\n",
    "\n",
    "centroides_neg = tf.concat(0, [tf.reduce_mean(tf.gather(eigenvec_neg, tf.reshape(tf.where( tf.equal(assignments_neg, c)),[1,-1])),reduction_indices=[1]) for c in xrange(2)])\n",
    "centroides_neg = tf.stop_gradient(centroides_neg)\n",
    "\n",
    "expanded_centroides = tf.expand_dims(centroides_neg, 1)\n",
    "\n",
    "assignments_neg = tf.argmin(tf.reduce_sum(tf.square(tf.sub(expanded_Y, expanded_centroides)), 2), 0) #these are the clustering assignments based on current centroides\n",
    "assignments_neg = tf.stop_gradient(assignments_neg)\n",
    "\n",
    "\n",
    "\n",
    "def cluster_error(assignment, group_size=group_size, communities=communities, dim_graph=dim_graph):\n",
    "    \"\"\"Takes in assignments and compares to the balanced two cluster\n",
    "    model of the random graph above\"\"\"\n",
    "    dim_graph = communities*group_size\n",
    "    true_assignment_a = tf.concat(0, [tf.zeros([group_size], dtype=tf.float32),\n",
    "                                      tf.ones([group_size], dtype=tf.float32)])\n",
    "    true_assignment_b = tf.concat(0, [tf.ones([group_size], dtype=tf.float32),\n",
    "                                      tf.zeros([group_size], dtype=tf.float32)])         \n",
    "    assignment = tf.cast(assignment, dtype = tf.float32)\n",
    "    loss = tf.minimum(tf.reduce_sum(tf.square(tf.sub(true_assignment_a, assignment))),\n",
    "                      tf.reduce_sum(tf.square(tf.sub(true_assignment_b, assignment))))\n",
    "    error = tf.div(loss, dim_graph)\n",
    "    \n",
    "    return loss, error\n",
    "\n",
    "\n",
    "loss_neg, error_neg = cluster_error(assignments_neg, group_size, communities, dim_graph)\n",
    "\n",
    "#optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "#train = optimizer.minimize(loss_neg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "init = tf.initialize_variables([r])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "#    sess.run(train)\n",
    "    sess.run([eigenval_neg_index, eigenval, eigenvec, eigenval_neg_bool])\n",
    "    a, r, b, c, d =  sess.run([r, eigenvec_neg, centroides_neg, assignments_neg, error_neg])\n",
    "    print a, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where the problems begin.  We cannot back prop through tf.less, tf.argmin....so we are working to fix this by  using functions that approximate them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.  0.] [-0.53288943]\n"
     ]
    }
   ],
   "source": [
    "dim_graph = 6\n",
    "communities = 3\n",
    "\n",
    "communities = 3 #number of communities, chance to \n",
    "group_size = 2 #number of nodes in each communitites (balanced so far)\n",
    "A = balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.15, p_out=0.01)\n",
    "\n",
    "Adj = tf.cast(A, dtype = tf.float32)\n",
    "\n",
    "Diag = tf.diag(tf.reduce_sum(Adj,0))\n",
    "\n",
    "r =  tf.Variable(tf.random_normal(shape=[1], mean=0.0,\n",
    "                                 stddev=1.0, dtype=tf.float32,\n",
    "                                 seed=None, name=None))\n",
    "\n",
    "Bethe_Hesse_neg = (tf.square(r)-1)*tf.diag(tf.ones(shape=[dim_graph]))-tf.mul(r, Adj)+Diag \n",
    "\n",
    "\n",
    "eigenval, eigenvec = tf.self_adjoint_eig(Bethe_Hesse_neg)\n",
    "\n",
    "#k = tf.Variable(tf.random_uniform([1], minval=0, maxval=dim_graph, dtype=tf.float32, seed=None, name=None))\n",
    "#k = tf.floor(k)\n",
    "#dear god it is impossible to convert a tensor to an integer!!!! hard code for now...\n",
    "\n",
    "k = communities \n",
    "\n",
    "\n",
    "true_assignment_a = tf.concat(0, [tf.zeros([3], dtype=tf.float32),\n",
    "                                      tf.ones([3], dtype=tf.float32)])\n",
    "true_assignment_b = tf.concat(0, [tf.ones([3], dtype=tf.float32),\n",
    "                                      tf.zeros([3], dtype=tf.float32)])\n",
    "\n",
    "\n",
    "\n",
    "eigenvec_neg = tf.argmax(tf.nn.softmax(tf.slice(Bethe_Hesse_neg, [0,0], [dim_graph, 2])), 1) #this is where we are supposed to take the eigenspace that corresponds to negative eigenvalues, however let's just learn this...\n",
    "eigenvec_neg = tf.cast(eigenvec_neg, dtype = tf.float32)\n",
    "loss = tf.minimum(tf.reduce_sum(tf.square(tf.sub(eigenvec_neg, true_assignment_a))), \n",
    "              tf.reduce_sum(tf.square(tf.sub(eigenvec_neg, true_assignment_b))))\n",
    "#tf.reduce_sum(tf.square(tf.sub(c, true_assignment_a)))\n",
    "    \n",
    "    #tf.reduce_sum(tf.square(eigenvec_neg))\n",
    "#error = tf.div(loss, dim_graph)\n",
    "\n",
    "\n",
    "#optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "#train = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "#var_grad = tf.gradients(loss, [r])\n",
    "\n",
    "init = tf.initialize_variables([r])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "#   sess.run(train)\n",
    "    a, c =  sess.run([eigenvec_neg, r])\n",
    "    print a, c \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tensorflow.python.framework.ops.Operation object at 0x11381e150> cannot be interpreted as a Tensor. (Operation name: \"init\"\nop: \"NoOp\"\ninput: \"^Variable/Assign\"\n is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9b70d7995bcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0mAdj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m     \u001b[0mfetch_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \"\"\"\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 225\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    226\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument <tensorflow.python.framework.ops.Operation object at 0x11381e150> cannot be interpreted as a Tensor. (Operation name: \"init\"\nop: \"NoOp\"\ninput: \"^Variable/Assign\"\n is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "Adj = tf.Variable(tf.random_normal(shape=[dim_graph, dim_graph], mean=0.0,\n",
    "                                 stddev=3.0, dtype=tf.float32,\n",
    "                                 seed=1, name=None))\n",
    "\n",
    "\n",
    "centroides_neg = tf.slice(eigenvec_neg,[0,0],[2,-1])\n",
    "\n",
    "\n",
    "expanded_Y = tf.expand_dims(eigenvec_neg, 0)\n",
    "expanded_centroides = tf.expand_dims(centroides_neg, 1)\n",
    "\n",
    "\n",
    "diff_centers = tf.transpose(tf.reduce_sum(tf.square(tf.sub(expanded_Y, expanded_centroides)), 2))\n",
    "\n",
    "\n",
    "diff_centers_softmax = diff_centers #tf.nn.softmax(diff_centers) \n",
    "\n",
    "\n",
    "#assignments_neg = tf.slice(diff_centers_softmax, [0,0], [6, 1])#tf.argmax(diff_centers_softmax, 1)\n",
    "assignments_neg = diff_centers_softmax #tf.cast(assignments_neg, dtype = tf.float64)\n",
    "\n",
    "\n",
    "true_assignment_a = tf.concat(0, [tf.zeros([3], dtype=tf.float64),\n",
    "                                      tf.ones([3], dtype=tf.float64)])\n",
    "true_assignment_b = tf.concat(0, [tf.ones([3], dtype=tf.float64),\n",
    "                                      tf.zeros([3], dtype=tf.float64)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        batch = A\n",
    "        sess.run(init)\n",
    "        if i%2 == 0:\n",
    "            train_accuracy = sess.run(loss, feed_dict={ Adj:A})\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        sess.run(train_step,feed_dict={x: batch})\n",
    "\n",
    "    print(\"test accuracy %g\"% sess.run(loss, feed_dict={ \n",
    "       Adj: A}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "communities = 2 #number of communities, chance to \n",
    "group_size = 2 #number of nodes in each communitites (balanced so far)\n",
    "dim_graph = communities*group_size\n",
    "A = balanced_stochastic_blockmodel(communities=communities, \n",
    "                                   groupsize=group_size, p_in=0.25, p_out=0.01)\n",
    "print A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible shapes for broadcasting: (3, 3) and (8, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ea37c92e411e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mBethe_Hesse_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim_graph\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mDiag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_neg_eigenvectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   2301\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2302\u001b[0m   \"\"\"\n\u001b[0;32m-> 2303\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sub\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2304\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    701\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    702\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                            op_def=op_def)\n\u001b[0m\u001b[1;32m    704\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2334\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2336\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2337\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1723\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[1;32m   1724\u001b[0m                          % op.type)\n\u001b[0;32m-> 1725\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1726\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36m_BroadcastShape\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1817\u001b[0m   return [common_shapes.broadcast_shape(\n\u001b[1;32m   1818\u001b[0m       \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m       op.inputs[1].get_shape())]\n\u001b[0m\u001b[1;32m   1820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mbroadcast_shape\u001b[0;34m(shape_x, shape_y)\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m       raise ValueError(\"Incompatible shapes for broadcasting: %s and %s\"\n\u001b[0;32m--> 588\u001b[0;31m                        % (shape_x, shape_y))\n\u001b[0m\u001b[1;32m    589\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: (3, 3) and (8, 8)"
     ]
    }
   ],
   "source": [
    "Adj = tf.cast(A, tf.float32)\n",
    "Diag = tf.diag(tf.reduce_sum(Adj,0)) #just the diagonal matrix of degrees of Adj\n",
    "\n",
    "\n",
    "\n",
    "r =  tf.Variable(tf.random_normal(shape=[1], mean=0.0,\n",
    "                                 stddev=1.0, dtype=tf.float32,\n",
    "                                 seed=None, name=None))\n",
    "#tf.constant(1, dtype=tf.float32)#\n",
    "\n",
    "\n",
    "Bethe_Hesse_neg = (tf.square(r)-1)*tf.diag(tf.ones(shape=[dim_graph]))-tf.mul(r, Adj)+Diag \n",
    "\n",
    "def get_neg_eigenvectors(A, dim_graph=dim_graph, group_size=group_size):\n",
    "    \"\"\"gets neg eigenvalues of matrix, \n",
    "    this may not be a differentiable opeartor\n",
    "    so let's set it to take the last n/2 eigenvalues as usual\n",
    "    \"\"\"\n",
    "    dim_graph = communities*group_size\n",
    "    eigenval, eigenvec = tf.self_adjoint_eig(A)\n",
    "    return eigenval, tf.slice(eigenvec, [0, 0], [dim_graph, group_size])\n",
    "\n",
    "\n",
    "def cluster_error(assignment, group_size=group_size, communities=communities, dim_graph=dim_graph):\n",
    "    \"\"\"Takes in assignments and compares to the balanced two cluster\n",
    "    model of the random graph above\"\"\"\n",
    "    dim_graph = communities*group_size\n",
    "    true_assignment_a = tf.concat(0, [tf.zeros([group_size], dtype=tf.float32),\n",
    "                                      tf.ones([group_size], dtype=tf.float32)])\n",
    "    true_assignment_b = tf.concat(0, [tf.ones([group_size], dtype=tf.float32),\n",
    "                                      tf.zeros([group_size], dtype=tf.float32)])         \n",
    "    assignment = tf.cast(assignment, dtype = tf.float32)\n",
    "    loss = tf.minimum(tf.reduce_sum(tf.square(tf.sub(true_assignment_a, assignment))),\n",
    "                      tf.reduce_sum(tf.square(tf.sub(true_assignment_b, assignment))))\n",
    "    error = tf.div(loss, dim_graph)\n",
    "    \n",
    "    return loss, error\n",
    "\n",
    "\n",
    "\n",
    "Y = get_neg_eigenvectors(Bethe_Hesse_neg, dim_graph, group_size)[1]\n",
    "centroides_neg = tf.Variable(tf.slice(tf.random_shuffle(Y),[0,0],[communities,-1]))\n",
    "expanded_Y = tf.expand_dims(Y, 0)\n",
    "expanded_centroides = tf.expand_dims(centroides_neg, 1)\n",
    "assignments_neg = tf.argmin(tf.reduce_sum(tf.square(tf.sub(expanded_Y, expanded_centroides)), 2), 0) #these are the clustering assignments based on current centroides\n",
    "means_neg = tf.concat(0, [tf.reduce_mean(tf.gather(Y, tf.reshape(tf.where( tf.equal(assignments_neg, c)),[1,-1])),\n",
    "                                         reduction_indices=[1]) for c in xrange(communities)])\n",
    "    \n",
    "    \n",
    "update_centroides_neg = tf.assign(centroides_neg, means_neg)\n",
    "loss_neg, error_neg = cluster_error(assignments_neg, group_size, communities, dim_graph)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss_neg)\n",
    "\n",
    "\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(train)\n",
    "    for steps in xrange(1):\n",
    "        sess.run([update_centroides_neg, centroides_neg, assignments_neg])\n",
    "        a, b, c, d = sess.run([centroides_neg, error_neg, assignments_neg, loss_neg])\n",
    "        print 'Using the Besse Hessian Matrix, the assignment of clusters for each node is {}, with error rate of {}'.format(c, b)\n",
    "        print 'loss is {}'.format(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tfnighly]",
   "language": "python",
   "name": "conda-env-tfnighly-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
