{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we try to implement powermethod with kmeans: here\n",
    "http://jmlr.org/proceedings/papers/v37/boutsidis15.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import  networkx as nx\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals: \n",
    "\n",
    "So far we have not implemented non linearities.  We have also not included much of a learning component.  \n",
    "The only hope was to change parameters of how to add laplacian together, but so far it is working....\n",
    "\n",
    "If we feed it communities, depending on how the communities are structured (more strong in degree, more strong out degree) it will change whether we want to just optimize on adjacency matrix, versus optimizing on the laplacian...that is one possible way it can learn\n",
    "\n",
    "\n",
    "It does not need to learn throug kmeans\n",
    "\n",
    "\n",
    "Finally, we can include belief propagation level.  \n",
    "\n",
    "##let's try to make a version where it can decide to take take a vote between the adjaency matrix version versus the laplacian matrix version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to apply to our tf implementation of spectral clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_eigenvectors(A, communities=communities):\n",
    "    \"\"\"gets first k eigenvalues of matrix\"\"\"\n",
    "    eigenval, eigenvec = tf.self_adjoint_eig(A)\n",
    "    return tf.slice(eigenvec, [0, dim_graph-communities], [dim_graph, communities])\n",
    "\n",
    "def k_means_spectral(A, communities=communities):\n",
    "    \"\"\"takes in matrix, does k means on first k eignvectors \n",
    "    Y where rows are the data points\"\"\"    \n",
    "\n",
    "    Y = get_eigenvectors(A)\n",
    "    centroides = tf.Variable(tf.slice(tf.random_shuffle(Y),[0,0],[communities,-1]))\n",
    "    expanded_Y = tf.expand_dims(Y, 0)\n",
    "    expanded_centroides = tf.expand_dims(centroides, 1)\n",
    "    assignments = tf.argmin(tf.reduce_sum(tf.square(tf.sub(expanded_Y, expanded_centroides)), 2), 0) #these are the clustering assignments based on current centroides\n",
    "    means = tf.concat(0, [tf.reduce_mean(tf.gather(Y, tf.reshape(tf.where( tf.equal(assignments, c)),[1,-1])),\n",
    "                                     reduction_indices=[1]) for c in xrange(communities)])\n",
    "    \n",
    "    return assignments, means, centroides\n",
    "\n",
    "def cluster_error(assignment, group_size=group_size):\n",
    "    \"\"\"Takes in assignments and compares to the balanced two cluster\n",
    "    model of the random graph above\"\"\"\n",
    "    \n",
    "    true_assignment_a = tf.concat(0, [tf.zeros([group_size], dtype=tf.float32),\n",
    "                                      tf.ones([group_size], dtype=tf.float32)])\n",
    "    true_assignment_b = tf.concat(0, [tf.ones([group_size], dtype=tf.float32),\n",
    "                                      tf.zeros([group_size], dtype=tf.float32)])         \n",
    "    assignment = tf.cast(assignment, dtype = tf.float32)\n",
    "    loss = tf.minimum(tf.reduce_sum(tf.square(tf.sub(true_assignment_a, assignment))),\n",
    "                      tf.reduce_sum(tf.square(tf.sub(true_assignment_b, assignment))))\n",
    "    error = tf.div(loss, dim_graph)\n",
    "    \n",
    "    return loss, error\n",
    "\n",
    "\n",
    "## the following functions allows us to verify that permuted adjacency matrices shoudl have no effect on the network\n",
    "#of course, which no power method, this is just true by construction but good to have anyways \n",
    "\n",
    "def joint_permutation(A):\n",
    "    #takes adjacency matrix and relabels, gives out permutated adjacency matrix of same relationship\n",
    "    random_shuffle = np.random.permutation(len(A))\n",
    "\n",
    "    A_shuffle = A[random_shuffle]\n",
    "    A_shuffle = np.transpose(A_shuffle)\n",
    "    A_shuffle = A_shuffle[random_shuffle]\n",
    "\n",
    "    return A_shuffle, random_shuffle\n",
    "\n",
    "def balanced_stochastic_blockmodel(communities=2, groupsize=3, p_in=1.0, p_out=0.0):\n",
    "    #gives dense adjacency matrix representaiton of randomly generated SBM with balanced community size\n",
    "\n",
    "    G = nx.planted_partition_graph(l=communities, k=groupsize, p_in=p_in, p_out =p_out)\n",
    "    A = nx.adjacency_matrix(G).todense()\n",
    "    \n",
    "    return A\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Spectral Clustering.  \n",
    "So far we are using balanced networks to test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 0]\n",
      " [1 0 1 0 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [0 0 0 0 1 1]\n",
      " [0 0 0 1 0 1]\n",
      " [0 0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "communities = 2 #number of communities, chance to \n",
    "group_size = 3 #number of nodes in each communitites (balanced so far)\n",
    "A = balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.9, p_out=0.0)\n",
    "print A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the Laplacian, the assignment of clusters for each node is [0 0 0 1 1 1], with error rate of 0.0.\n",
      "Using the adjacency matrix, the assignment of clusters for each node is [0 0 0 0 0 0], with error rate of 0.5\n"
     ]
    }
   ],
   "source": [
    "dim_graph = communities*group_size\n",
    "\n",
    "x = A #tf.placeholder(tf.float32, shape=[dim_graph, dim_graph])\n",
    "\n",
    "Adj = tf.cast(x, tf.float32)\n",
    "laplacian = tf.matmul(tf.diag(tf.inv(tf.reduce_sum(Adj,0))),x_tensor)\n",
    "\n",
    "assignment_laplacian, means_laplacian, centroides_laplacian = k_means_spectral(laplacian)\n",
    "update_centroides_laplacian = tf.assign(centroides_laplacian, means_laplacian)\n",
    "loss_laplacian, error_laplacian = cluster_error(assignment_laplacian)\n",
    "\n",
    "assignment_adj, means_adj, centroides_adj = k_means_spectral(Adj)\n",
    "update_centroides_adj = tf.assign(centroides_adj, means_adj)\n",
    "loss_adj, error_adj = cluster_error(assignment_adj)\n",
    "\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in xrange(10):\n",
    "        sess.run([update_centroides_adj, update_centroides_laplacian, assignment_adj, assignment_laplacian])\n",
    "    a, b, c, d = sess.run([assignment_laplacian, assignment_adj, error_adj, error_laplacian])\n",
    "    print 'Using the Laplacian, the assignment of clusters for each node is {}, with error rate of {}.'.format(a, d)\n",
    "    print 'Using the adjacency matrix, the assignment of clusters for each node is {}, with error rate of {}'.format(b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting to create learnable parameter to choose between using Laplacian and Adjacency matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 1, 0, 1],\n",
       "        [0, 0, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities = 2\n",
    "group_size = 3\n",
    "A = balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.9, p_out=0.0)\n",
    "x = A\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got <function if_true at 0x117a7fb18>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-aa0d7cc08e5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#tf.less(a, b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0massignment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36mselect\u001b[0;34m(condition, t, e, name)\u001b[0m\n\u001b[1;32m   1933\u001b[0m   \"\"\"\n\u001b[1;32m   1934\u001b[0m   result = _op_def_lib.apply_op(\"Select\", condition=condition, t=t, e=e,\n\u001b[0;32m-> 1935\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m   1936\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    452\u001b[0m             values = ops.convert_to_tensor(\n\u001b[1;32m    453\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m                 as_ref=input_arg.is_ref)\n\u001b[0m\u001b[1;32m    455\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# What type does convert_to_tensor think it has?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconversion_func\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfuncs_at_priority\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m           \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    178\u001b[0m                                          as_ref=False):\n\u001b[1;32m    179\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 163\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n\u001b[0m\u001b[1;32m    164\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.pyc\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape)\u001b[0m\n\u001b[1;32m    420\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnumpy_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0mproto_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FlattenToStrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/util/compat.pyc\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text)\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 45\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got <function if_true at 0x117a7fb18>"
     ]
    }
   ],
   "source": [
    "dim_graph = communities*group_size\n",
    "\n",
    "x = A #tf.placeholder(tf.float32, shape=[dim_graph, dim_graph])\n",
    "\n",
    "x_tensor = tf.cast(x, tf.float32)\n",
    "\n",
    "\n",
    "def get_eigenvectors(A, communities=communities):\n",
    "    \"\"\"gets first k eigenvalues of matrix\"\"\"\n",
    "    eigenval, eigenvec = tf.self_adjoint_eig(A)\n",
    "    return tf.slice(eigenvec, [0, dim_graph-communities], [dim_graph, communities])\n",
    "\n",
    "def k_means_spectral(A, communities=communities):\n",
    "    \"\"\"takes in matrix, does k means on first k eignvectors \n",
    "    Y where rows are the data points\"\"\"    \n",
    "\n",
    "    Y = get_eigenvectors(A)\n",
    "    centroides = tf.Variable(tf.slice(tf.random_shuffle(Y),[0,0],[communities,-1]))\n",
    "    expanded_Y = tf.expand_dims(Y, 0)\n",
    "    expanded_centroides = tf.expand_dims(centroides, 1)\n",
    "    assignments = tf.argmin(tf.reduce_sum(tf.square(tf.sub(expanded_Y, expanded_centroides)), 2), 0) #these are the clustering assignments based on current centroides\n",
    "    means = tf.concat(0, [tf.reduce_mean(tf.gather(Y, tf.reshape(tf.where( tf.equal(assignments, c)),[1,-1])),\n",
    "                                     reduction_indices=[1]) for c in xrange(communities)])\n",
    "    \n",
    "    return assignments, means\n",
    "\n",
    "def cluster_error(assignment, group_size=group_size):\n",
    "    \"\"\"Takes in assignments and compares to the balanced two cluster\n",
    "    model of the random graph above\"\"\"\n",
    "    \n",
    "    true_assignment_a = tf.concat(0, [tf.zeros([group_size], dtype=tf.float32),\n",
    "                                      tf.ones([group_size], dtype=tf.float32)])\n",
    "    true_assignment_b = tf.concat(0, [tf.ones([group_size], dtype=tf.float32),\n",
    "                                      tf.zeros([group_size], dtype=tf.float32)])         \n",
    "    assignment = tf.cast(assignment, dtype = tf.float32)\n",
    "    loss = tf.minimum(tf.reduce_sum(tf.square(tf.sub(true_assignment_a, assignment))),\n",
    "                      tf.reduce_sum(tf.square(tf.sub(true_assignment_b, assignment))))\n",
    "    error = tf.div(loss, dim_graph)\n",
    "    \n",
    "    return loss, error\n",
    "\n",
    "    \n",
    "#Laplcian define\n",
    "laplacian = tf.matmul(tf.diag(tf.inv(tf.reduce_sum(x_tensor,0))),x_tensor)\n",
    "\n",
    "#Adjacnecy Branch\n",
    "\n",
    "a = tf.Variable(tf.random_uniform([1], -1, 1))\n",
    "b = tf.zeros(1)\n",
    "#will make a negative if it wants us to use the laplacian, really cruderight now, need more ideas needed\n",
    "\n",
    "def if_true():\n",
    "    a = tf.constant(3)#a, b = k_means_spectral(laplacian)\n",
    "    return a\n",
    "def if_false():\n",
    "    a = tf.constant(2) #a, b = k_means_spectral(x_tensor)\n",
    "    return a \n",
    "\n",
    "pred = tf.less(a, b)\n",
    "\n",
    "r = tf.cond(pred, if_true, if_false)\n",
    "\n",
    "assignment, means = r\n",
    "update_centroides = tf.assign(centroides, means)\n",
    "loss, error = cluster_error(assignment)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in xrange(10):\n",
    "        sess.run([a, update_centroides, assignments])\n",
    "    print sess.run([assignments, error])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Less_19:0' shape=(0,) dtype=bool>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.Variable(tf.random_uniform([0], -1, 1))\n",
    "a = tf.zeros(1)\n",
    "c = tf.less(b, 0)\n",
    "tf.shape(c)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#eigenspace_power = tf.matmul(laplacian, tf.transpose(laplacian)) #x will be symmetric, so so will L, can be made more effcient here\n",
    "#eigenspace_power = tf.matmul(eigenspace_power, eigenspace_power)\n",
    "#here we used p = 2 iterations, we can also try to learn this.  \n",
    "#the paper reference above used p = some function of the eigenvalues...\n",
    "#but this may be learned\n",
    "\n",
    "#S = tf.Variable(tf.random_normal(shape=[dim_graph,k],mean = 0.0,stddev = 1.0))\n",
    "#B = tf.matmul(eigenspace_power, S)\n",
    "#now we extract the singular vectors of B (left) to get our eigenspace approximation\n",
    "#Y_hat = tf.svd(B, full_matrices=True) #we want to use tf.svd, however it does not work in the newest version and building from source does not give me all that I want...\n",
    "\n",
    "\n",
    "#the laplacian is symmetric, we wish to get the 2 largest eigenvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
