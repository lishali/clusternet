{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import  networkx as nx\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals: \n",
    "\n",
    "So far we have not implemented non linearities.  We have also not included much of a learning component.  \n",
    "The only hope was to change parameters of how to add laplacian together, but so far it is working....\n",
    "\n",
    "If we feed it communities, depending on how the communities are structured (more strong in degree, more strong out degree) it will change whether we want to just optimize on adjacency matrix, versus optimizing on the laplacian...that is one possible way it can learn\n",
    "\n",
    "\n",
    "It does not need to learn throug kmeans\n",
    "\n",
    "\n",
    "Finally, we can include belief propagation level.  \n",
    "\n",
    "let's try to make a version where it can decide to take take a vote between the adjaency matrix version versus the laplacian matrix version\n",
    "\n",
    "\n",
    "maybe try to implement powermethod with kmeans: here\n",
    "http://jmlr.org/proceedings/papers/v37/boutsidis15.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to apply to our tf implementation of spectral clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "communities = 2 #number of communities, chance to \n",
    "group_size = 3 \n",
    "def get_eigenvectors(A, communities=communities, group_size=group_size):\n",
    "    \"\"\"gets first k eigenvalues of matrix\"\"\"\n",
    "    dim_graph = communities*group_size\n",
    "    eigenval, eigenvec = tf.self_adjoint_eig(A)\n",
    "    return tf.slice(eigenvec, [0, dim_graph-communities], [dim_graph, communities])\n",
    "\n",
    "def k_means_spectral(A, communities=communities, group_size=group_size):\n",
    "    \"\"\"takes in matrix, does k means on first k eignvectors \n",
    "    Y where rows are the data points\"\"\"    \n",
    "\n",
    "    Y = get_eigenvectors(A, communities, group_size)\n",
    "    centroides = tf.Variable(tf.slice(tf.random_shuffle(Y),[0,0],[communities,-1]))\n",
    "    expanded_Y = tf.expand_dims(Y, 0)\n",
    "    expanded_centroides = tf.expand_dims(centroides, 1)\n",
    "    assignments = tf.argmin(tf.reduce_sum(tf.square(tf.sub(expanded_Y, expanded_centroides)), 2), 0) #these are the clustering assignments based on current centroides\n",
    "    means = tf.concat(0, [tf.reduce_mean(tf.gather(Y, tf.reshape(tf.where( tf.equal(assignments, c)),[1,-1])),\n",
    "                                     reduction_indices=[1]) for c in xrange(communities)])\n",
    "    \n",
    "    return assignments, means, centroides\n",
    "\n",
    "def cluster_error(assignment, group_size=group_size, communities=communities):\n",
    "    \"\"\"Takes in assignments and compares to the balanced two cluster\n",
    "    model of the random graph above\"\"\"\n",
    "    dim_graph = communities*group_size\n",
    "    true_assignment_a = tf.concat(0, [tf.zeros([group_size], dtype=tf.float32),\n",
    "                                      tf.ones([group_size], dtype=tf.float32)])\n",
    "    true_assignment_b = tf.concat(0, [tf.ones([group_size], dtype=tf.float32),\n",
    "                                      tf.zeros([group_size], dtype=tf.float32)])         \n",
    "    assignment = tf.cast(assignment, dtype = tf.float32)\n",
    "    loss = tf.minimum(tf.reduce_sum(tf.square(tf.sub(true_assignment_a, assignment))),\n",
    "                      tf.reduce_sum(tf.square(tf.sub(true_assignment_b, assignment))))\n",
    "    error = tf.div(loss, dim_graph)\n",
    "    \n",
    "    return loss, error\n",
    "\n",
    "\n",
    "## the following functions allows us to verify that permuted adjacency matrices shoudl have no effect on the network\n",
    "#of course, which no power method, this is just true by construction but good to have anyways \n",
    "\n",
    "def joint_permutation(A):\n",
    "    #takes adjacency matrix and relabels, gives out permutated adjacency matrix of same relationship\n",
    "    random_shuffle = np.random.permutation(len(A))\n",
    "\n",
    "    A_shuffle = A[random_shuffle]\n",
    "    A_shuffle = np.transpose(A_shuffle)\n",
    "    A_shuffle = A_shuffle[random_shuffle]\n",
    "\n",
    "    return A_shuffle, random_shuffle\n",
    "\n",
    "def balanced_stochastic_blockmodel(communities=2, groupsize=3, p_in=1.0, p_out=0.0):\n",
    "    #gives dense adjacency matrix representaiton of randomly generated SBM with balanced community size\n",
    "\n",
    "    G = nx.planted_partition_graph(l=communities, k=groupsize, p_in=p_in, p_out =p_out)\n",
    "    A = nx.adjacency_matrix(G).todense()\n",
    "    \n",
    "    return A\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Spectral Clustering.  \n",
    "So far we are using balanced networks to test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "communities = 2 #number of communities, chance to \n",
    "group_size = 20 #number of nodes in each communitites (balanced so far)\n",
    "A = balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.29, p_out=0.0)\n",
    "print A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the Laplacian, the assignment of clusters for each node is [0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1], with error rate of 0.449999988079.\n",
      "Using the adjacency matrix, the assignment of clusters for each node is [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0], with error rate of 0.0\n",
      "Note that a random guess of a balanced partition will on average overlap with the correct clustering by 50%,but we are taking the min of two binomial's--since we wanted it to be invariant under labellings, so randomly we will do a little better than 50% error, min of two binomial 1/2.  But for bigger and bigger vectors this will approach 1/2. \n"
     ]
    }
   ],
   "source": [
    "communities = 2 #number of communities, chance to \n",
    "group_size = 20 #number of nodes in each communitites (balanced so far)\n",
    "A = balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.3, p_out=0.0)\n",
    "\n",
    "dim_graph = communities*group_size\n",
    "\n",
    "x = A#tf.placeholder(tf.int32, shape = None) #A\n",
    "\n",
    "\n",
    "Adj = tf.cast(x, tf.float32)\n",
    "laplacian = tf.matmul(tf.diag(tf.inv(tf.reduce_sum(Adj,0))), Adj)\n",
    "\n",
    "assignment_laplacian, means_laplacian, centroides_laplacian = k_means_spectral(laplacian, communities, group_size)\n",
    "update_centroides_laplacian = tf.assign(centroides_laplacian, means_laplacian)\n",
    "loss_laplacian, error_laplacian = cluster_error(assignment_laplacian, group_size)\n",
    "\n",
    "assignment_adj, means_adj, centroides_adj = k_means_spectral(Adj, communities, group_size)\n",
    "update_centroides_adj = tf.assign(centroides_adj, means_adj)\n",
    "loss_adj, error_adj = cluster_error(assignment_adj, group_size)\n",
    "\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) #, feed_dict = {x: A})\n",
    "    for step in xrange(10):\n",
    "        sess.run([update_centroides_adj, update_centroides_laplacian, assignment_adj, assignment_laplacian])\n",
    "    a, b, c, d = sess.run([assignment_laplacian, assignment_adj, error_adj, error_laplacian])\n",
    "    print 'Using the Laplacian, the assignment of clusters for each node is {}, with error rate of {}.'.format(a, d)\n",
    "    print 'Using the adjacency matrix, the assignment of clusters for each node is {}, with error rate of {}'.format(b, c)\n",
    "    print \"Note that a random guess of a balanced partition will on average overlap with the correct clustering by 50%,but we are taking the min of two binomial's--since we wanted it to be invariant under labellings, so randomly we will do a little better than 50% error, min of two binomial 1/2.  But for bigger and bigger vectors this will approach 1/2. \"\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "#really interesting, this does not work well with very sparse graphs...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting to create learnable parameter to choose between using Laplacian and Adjacency matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 1, 0, 0, 0],\n",
       "        [1, 0, 1, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hey = tf.placeholder(tf.int64, shape = None)# A\n",
    "Adj = tf.cast(hey, tf.float32)\n",
    "a= get_eigenvectors(Adj, communities, group_size)#a, b, c = k_means_spectral(Adj, communities, group_size)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init, feed_dict={hey: A})\n",
    "    print sess.run(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(16, dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = tf.placeholder(tf.int32, shape= None) #A\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print sess.run([dim_graph], feed_dict = {communities : 2, group_size : 8, dim_graph: 16})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.slice(eigenvec, [0, dim_graph-communities], [dim_graph, communities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (1,) and () are not compatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-06839f392c2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mless\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0massignment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, fn1, fn2, name)\u001b[0m\n\u001b[1;32m   1506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pred must not be a Python bool\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m     \u001b[0mp_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1509\u001b[0m     \u001b[0mpivot_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"switch_t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m     \u001b[0mpivot_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"switch_f\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc\u001b[0m in \u001b[0;36mswitch\u001b[0;34m(data, pred, dtype, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_control_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexedSlices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/gen_control_flow_ops.pyc\u001b[0m in \u001b[0;36m_switch\u001b[0;34m(data, pred, name)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0moutput_true\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIf\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mforwarded\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthis\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m   \"\"\"\n\u001b[0;32m--> 366\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Switch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_SwitchOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    701\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    702\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                            op_def=op_def)\n\u001b[0m\u001b[1;32m    704\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2334\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2336\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2337\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1723\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[1;32m   1724\u001b[0m                          % op.type)\n\u001b[0;32m-> 1725\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1726\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.pyc\u001b[0m in \u001b[0;36m_SwitchShape\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_SwitchShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2709\u001b[0m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2710\u001b[0;31m   \u001b[0munused_pred_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2711\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/envs/tfnighly/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    577\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         raise ValueError(\"Shapes %s and %s are not compatible\" %\n\u001b[0;32m--> 579\u001b[0;31m                          (self, other))\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (1,) and () are not compatible"
     ]
    }
   ],
   "source": [
    "dim_graph = communities*group_size\n",
    "\n",
    "x = A #tf.placeholder(tf.float32, shape=[dim_graph, dim_graph])\n",
    "\n",
    "x_tensor = tf.cast(x, tf.float32)\n",
    "    \n",
    "#Laplcian define\n",
    "laplacian = tf.matmul(tf.diag(tf.inv(tf.reduce_sum(x_tensor,0))),x_tensor)\n",
    "\n",
    "#Adjacnecy Branch\n",
    "\n",
    "a = tf.Variable(tf.random_uniform([1], -1, 1))\n",
    "b = tf.zeros(1)\n",
    "#will make a negative if it wants us to use the laplacian, really cruderight now, need more ideas needed\n",
    "\n",
    "def if_true():\n",
    "    a = tf.constant(3)#a, b = k_means_spectral(laplacian)\n",
    "    return a\n",
    "def if_false():\n",
    "    a = tf.constant(2) #a, b = k_means_spectral(x_tensor)\n",
    "    return a \n",
    "\n",
    "pred = tf.less(a, b)\n",
    "\n",
    "r = tf.cond(pred, if_true, if_false)\n",
    "\n",
    "assignment, means = r\n",
    "update_centroides = tf.assign(centroides, means)\n",
    "loss, error = cluster_error(assignment)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in xrange(10):\n",
    "        sess.run([a, update_centroides, assignments])\n",
    "    print sess.run([assignments, error])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Less_1:0' shape=(0,) dtype=bool>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.Variable(tf.random_uniform([0], -1, 1))\n",
    "a = tf.zeros(1)\n",
    "c = tf.less(b, 0)\n",
    "tf.shape(c)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#eigenspace_power = tf.matmul(laplacian, tf.transpose(laplacian)) #x will be symmetric, so so will L, can be made more effcient here\n",
    "#eigenspace_power = tf.matmul(eigenspace_power, eigenspace_power)\n",
    "#here we used p = 2 iterations, we can also try to learn this.  \n",
    "#the paper reference above used p = some function of the eigenvalues...\n",
    "#but this may be learned\n",
    "\n",
    "#S = tf.Variable(tf.random_normal(shape=[dim_graph,k],mean = 0.0,stddev = 1.0))\n",
    "#B = tf.matmul(eigenspace_power, S)\n",
    "#now we extract the singular vectors of B (left) to get our eigenspace approximation\n",
    "#Y_hat = tf.svd(B, full_matrices=True) #we want to use tf.svd, however it does not work in the newest version and building from source does not give me all that I want...\n",
    "\n",
    "\n",
    "#the laplacian is symmetric, we wish to get the 2 largest eigenvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
