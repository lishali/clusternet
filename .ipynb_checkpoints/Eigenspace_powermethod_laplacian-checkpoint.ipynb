{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we try to implement powermethod with kmeans: here\n",
    "http://jmlr.org/proceedings/papers/v37/boutsidis15.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import  networkx as nx\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1219004   0.12978126]\n",
      " [ 0.03260613  0.26531591]]\n",
      "[-0.61014277 -0.79229149]\n"
     ]
    }
   ],
   "source": [
    "def euclidean_norm(tensor): #need to have this for tf to work\n",
    "    square_tensor = tf.square(tensor)\n",
    "    norm_squared = tf.reduce_sum(square_tensor)\n",
    "    euclidean_norm = tf.sqrt(norm_squared)\n",
    "    return euclidean_norm\n",
    "\n",
    "x = np.random.rand(2,2)\n",
    "eigenValues,eigenVectors = np.linalg.eig(x)\n",
    "y = eigenVectors[:, eigenValues.argmax()]\n",
    "\n",
    "print x\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.48034069  0.1725045 ]\n",
      " [ 0.47344008  0.84283829]] [[ 0.48034069  0.17250449]\n",
      " [ 0.47344006  0.84283828]]\n"
     ]
    }
   ],
   "source": [
    "#get diagonal matrix from adjacency matrix\n",
    "x = np.random.rand(2,2)\n",
    "\n",
    "    \n",
    "x_tensor = tf.cast(x, tf.float32)\n",
    "\n",
    "degree_m_inverse = tf.diag(tf.inv(tf.reduce_sum(x_tensor,0))) #takes the degree of each vertex and makes diagonal matrix out of it\n",
    "\n",
    "laplacian = tf.matmul(degree_m_inverse, x_tensor)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    a, b = sess.run([laplacian, degree_m_inverse])\n",
    "\n",
    "#double check we do the same thing in np.\n",
    "\n",
    "degree_m = np.diag(np.reciprocal(np.ndarray.sum(np.array(x, dtype = np.float32), 0)))\n",
    "laplacian_np = np.dot(degree_m, x)\n",
    "\n",
    "print a, laplacian_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?nx.planted_partition_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities = 3\n",
    "G = nx.planted_partition_graph(l=communities, k = 4, p_in = 1., p_out = 0.0)\n",
    "A = nx.adjacency_matrix(G).todense()\n",
    "#A = A.todense()\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0. ,  0.5,  0. ],\n",
      "       [ 0. ,  0. ,  0.5],\n",
      "       [ 0.5,  0. ,  0. ]], dtype=float32), array([[ 0. ,  0.5,  0. ],\n",
      "       [ 0. ,  0. ,  0.5],\n",
      "       [ 0.5,  0. ,  0. ]], dtype=float32), array([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2])]\n"
     ]
    }
   ],
   "source": [
    "x=A\n",
    "dim_graph = len(x)\n",
    "k = communities #let's start with 2, but we can make it more complicated\n",
    "\n",
    "x_tensor = tf.cast(x, tf.float32)\n",
    " #takes the degree of each vertex and makes diagonal matrix out of it\n",
    "laplacian = tf.matmul(tf.diag(tf.inv(tf.reduce_sum(x_tensor,0))),\n",
    "                      x_tensor)\n",
    "#the laplacian is symmetric, we wish to get the 2 largest eigenvalues\n",
    "\n",
    "eigenval, eigenvec = tf.self_adjoint_eig(laplacian) #seems to be sorted for me\n",
    "Y = tf.slice(eigenvec, [0, dim_graph-k], [dim_graph, k]) #pick the top k eigenvectors\n",
    "\n",
    "\n",
    "#now we do K-means clustering on the rows of Y, which are the top k eignvectors of the laplacian above, or the bottom k of the normalized laplacian\n",
    "\n",
    "#find k random centroides\n",
    "\n",
    "centroides = tf.Variable(tf.slice(tf.random_shuffle(Y),[0,0],[k,-1]))\n",
    "\n",
    "expanded_Y = tf.expand_dims(Y, 0)\n",
    "expanded_centroides = tf.expand_dims(centroides, 1)\n",
    "\n",
    "diff = tf.sub(expanded_Y, expanded_centroides) #will get difference between eacnh centroide and all of thw points\n",
    "\n",
    "sqr = tf.square(diff) #sqr diff\n",
    "\n",
    "distances = tf.reduce_sum(sqr, 2)\n",
    "assignments = tf.argmin(distances, 0) #these are the clustering assignments based on current centroides\n",
    "\n",
    "means = tf.concat(0, \n",
    "                  [tf.reduce_mean(\n",
    "            tf.gather(\n",
    "                Y, tf.reshape(\n",
    "                    tf.where( \n",
    "                        tf.equal(assignments, c)),[1,-1])),\n",
    "            reduction_indices=[1]) for c in xrange(k)])\n",
    "\n",
    "#these new means, calculated by group, will be the new centroides\n",
    "update_centroides = tf.assign(centroides, means)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in xrange(100):\n",
    "        _, centroid_values, assigment_values = sess.run([centroides, update_centroides, assignments])\n",
    "    print sess.run([centroides, update_centroides, assignments])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(3,3)\n",
    "\n",
    "dim_graph = len(x)\n",
    "k = 2 #let's start with 2, but we can make it more complicated\n",
    "\n",
    "x_tensor = tf.cast(x, tf.float32)\n",
    " #takes the degree of each vertex and makes diagonal matrix out of it\n",
    "laplacian = tf.matmul(tf.diag(tf.inv(tf.reduce_sum(x_tensor,0))),\n",
    "                      x_tensor)\n",
    "\n",
    "#eigenspace_power = tf.matmul(laplacian, tf.transpose(laplacian)) #x will be symmetric, so so will L, can be made more effcient here\n",
    "#eigenspace_power = tf.matmul(eigenspace_power, eigenspace_power)\n",
    "#here we used p = 2 iterations, we can also try to learn this.  \n",
    "#the paper reference above used p = some function of the eigenvalues...\n",
    "#but this may be learned\n",
    "\n",
    "#S = tf.Variable(tf.random_normal(shape=[dim_graph,k],mean = 0.0,stddev = 1.0))\n",
    "#B = tf.matmul(eigenspace_power, S)\n",
    "#now we extract the singular vectors of B (left) to get our eigenspace approximation\n",
    "#Y_hat = tf.svd(B, full_matrices=True) #we want to use tf.svd, however it does not work in the newest version and building from source does not give me all that I want...\n",
    "\n",
    "\n",
    "#the laplacian is symmetric, we wish to get the 2 largest eigenvalues\n",
    "\n",
    "eigenval, eigenvec = tf.self_adjoint_eig(laplacian) #seems to be sorted for me\n",
    "Y = tf.slice(eigenvec, [0, dim_graph-k], [dim_graph, k]) #pick the top k eigenvectors\n",
    "\n",
    "\n",
    "#now we do K-means clustering on the rows of Y, which are the top k eignvectors of the laplacian above, or the bottom k of the normalized laplacian\n",
    "\n",
    "#find k random centroides\n",
    "\n",
    "centroides = tf.Variable(tf.slice(tf.random_shuffle(Y),[0,0],[k,-1]))\n",
    "\n",
    "expanded_Y = tf.expand_dims(Y, 0)\n",
    "expanded_centroides = tf.expand_dim(centroides, 1)\n",
    "\n",
    "diff = tf.sub(expanded_Y, expanded_centroides) #will get difference between eacnh centroide and all of thw points\n",
    "\n",
    "sqr = tf.square(diff) #sqr diff\n",
    "\n",
    "distances = tf.reduce_sum(sqr, 2)\n",
    "assignments = tf.argmin(distances, 0) #these are the clustering assignments based on current centroides\n",
    "\n",
    "means = tf.concat(0, \n",
    "                  [tf.reduce_mean(\n",
    "            tf.gather(\n",
    "                Y, tf.reshape(\n",
    "                    tf.where( \n",
    "                        tf.equal(assignments, c)),[1,-1])),\n",
    "            reduction_indices=[1]) for c in xrange(k)])\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "#these new means, calculated by group, will be the new centroides\n",
    "\n",
    "update_centroides = tf.assign(centroides, means)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in xrange(100):\n",
    "        _, centroid_values, assigment_values = sess.run([centroides, update_centroides, assignments])\n",
    "    \n",
    "print sess.run([update_centroides, centroides, assignments])\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
