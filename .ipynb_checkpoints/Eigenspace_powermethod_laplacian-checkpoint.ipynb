{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we try to implement powermethod with kmeans: here\n",
    "http://jmlr.org/proceedings/papers/v37/boutsidis15.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.77548423e-01   9.00150689e-01   5.73328145e-01   9.70417722e-01\n",
      "    6.75187106e-02   2.69927249e-02]\n",
      " [  4.81387072e-01   7.85013014e-01   4.37255678e-01   7.00551887e-01\n",
      "    2.82237134e-01   5.91758733e-01]\n",
      " [  1.44719378e-02   8.80120182e-01   7.75156136e-01   1.14887930e-05\n",
      "    6.01145737e-02   7.16156525e-01]\n",
      " [  3.27851642e-01   1.99112508e-01   8.45961559e-01   7.78023327e-01\n",
      "    1.01739702e-01   7.19809963e-01]\n",
      " [  3.24799278e-01   6.84552804e-01   1.58479409e-01   2.97494076e-01\n",
      "    9.67790054e-01   6.01365567e-01]\n",
      " [  7.21219360e-01   6.49677447e-01   4.93659582e-02   8.14609653e-01\n",
      "    8.82628731e-01   8.37970056e-01]]\n",
      "[ 0.40835687+0.j  0.41635474+0.j  0.31481462+0.j  0.36823266+0.j\n",
      "  0.39595448+0.j  0.51808292+0.j]\n"
     ]
    }
   ],
   "source": [
    "def euclidean_norm(tensor): #need to have this for tf to work\n",
    "    square_tensor = tf.square(tensor)\n",
    "    norm_squared = tf.reduce_sum(square_tensor)\n",
    "    euclidean_norm = tf.sqrt(norm_squared)\n",
    "    return euclidean_norm\n",
    "\n",
    "x = np.random.rand(6,6)\n",
    "eigenValues,eigenVectors = np.linalg.eig(x)\n",
    "y = eigenVectors[:, eigenValues.argmax()]\n",
    "\n",
    "print x\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08669717  0.3041949   0.39782742  0.08660683  0.312745    0.00333091]\n",
      " [ 0.02113973  0.06947854  0.12225462  0.13509353  0.01587746  0.16934253]\n",
      " [ 0.05644882  0.24605824  0.01773158  0.14604199  0.13960373  0.1396171 ]\n",
      " [ 0.14403594  0.36620224  0.18330204  0.27556527  0.10848746  0.21258424]\n",
      " [ 0.31938058  0.33307314  0.12925398  0.04901455  0.23823662  0.13879231]\n",
      " [ 0.14387381  0.35887092  0.32157561  0.14536391  0.29164752  0.19129111]] [[ 0.08669717  0.30419487  0.3978274   0.08660682  0.31274498  0.00333091]\n",
      " [ 0.02113973  0.06947854  0.12225462  0.13509353  0.01587746  0.16934253]\n",
      " [ 0.05644883  0.24605825  0.01773158  0.146042    0.13960374  0.13961711]\n",
      " [ 0.14403592  0.3662022   0.18330203  0.27556523  0.10848744  0.21258424]\n",
      " [ 0.31938058  0.33307316  0.12925399  0.04901455  0.23823662  0.13879231]\n",
      " [ 0.14387382  0.35887095  0.32157561  0.14536392  0.29164755  0.19129112]]\n"
     ]
    }
   ],
   "source": [
    "#get diagonal matrix from adjacency matrix\n",
    "x = np.random.rand(6,6)\n",
    "\n",
    "    \n",
    "x_tensor = tf.cast(x, tf.float32)\n",
    "\n",
    "degree_m_inverse = tf.diag(tf.inv(tf.reduce_sum(x_tensor,0))) #takes the degree of each vertex and makes diagonal matrix out of it\n",
    "\n",
    "laplacian = tf.matmul(degree_m_inverse, x_tensor)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    a, b = sess.run([laplacian, degree_m_inverse])\n",
    "\n",
    "#double check we do the same thing in np.\n",
    "\n",
    "degree_m = np.diag(np.reciprocal(np.ndarray.sum(x, 0)))\n",
    "laplacian_np = np.dot(degree_m, x)\n",
    "\n",
    "print a, laplacian_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  4.73598945e+04,   5.21473633e-03], dtype=float32), array([[ 0.26957893, -0.00535233, -0.64693505, -0.48660555, -0.26561663,\n",
      "        -0.44881675],\n",
      "       [ 0.22891937,  0.46884421,  0.55450636, -0.62466532,  0.15345313,\n",
      "        -0.08092672],\n",
      "       [ 0.53995997, -0.67343241,  0.41838583,  0.03821847, -0.20490901,\n",
      "        -0.19088461],\n",
      "       [ 0.57218558,  0.53451258, -0.04639177,  0.58455217, -0.04615809,\n",
      "        -0.20227689],\n",
      "       [ 0.23352411, -0.2023313 , -0.21093667, -0.0159529 ,  0.9235608 ,\n",
      "        -0.08255456],\n",
      "       [ 0.44881675, -0.00189212, -0.22870202, -0.17202295, -0.09389979,\n",
      "         0.84133601]], dtype=float32), array([[-0.36504978,  0.93098789],\n",
      "       [ 0.93098789,  0.36504978]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(6,6)\n",
    "\n",
    "dim_graph = len(x)\n",
    "k = 2 #let's start with 2, but we can make it more complicated\n",
    "\n",
    "x_tensor = tf.cast(x, tf.float32)\n",
    " #takes the degree of each vertex and makes diagonal matrix out of it\n",
    "laplacian = tf.matmul(tf.diag(tf.inv(tf.reduce_sum(x_tensor,0))),\n",
    "                      x_tensor)\n",
    "\n",
    "eigenspace_power = tf.matmul(laplacian, tf.transpose(laplacian)) #x will be symmetric, so so will L, can be made more effcient here\n",
    "eigenspace_power = tf.matmul(eigenspace_power, eigenspace_power)\n",
    "eigenspace_power = tf.matmul(eigenspace_power, eigenspace_power)\n",
    "eigenspace_power = tf.matmul(eigenspace_power, eigenspace_power)\n",
    "eigenspace_power = tf.matmul(eigenspace_power, eigenspace_power)\n",
    "eigenspace_power = tf.matmul(eigenspace_power, eigenspace_power)\n",
    "#here we used p = 2 iterations, we can also try to learn this.  \n",
    "#the paper reference above used p = some function of the eigenvalues...\n",
    "#but this may be learned\n",
    "\n",
    "eigenspace_power = tf.matmul(eigenspace_power, laplacian)\n",
    "\n",
    "S = tf.Variable(tf.random_normal(shape=[dim_graph,k], \n",
    "                                 mean = 0.0,\n",
    "                                 stddev = 1.0))\n",
    "\n",
    "\n",
    "B = tf.matmul(eigenspace_power, S)\n",
    "\n",
    "#now we extract the singular vectors of B (left) to get our eigenspace approximation\n",
    "\n",
    "Y_hat = tf.svd(B, full_matrices=True) #we want to use tf.svd, however it does not work in the newest version and building from source does not give me all that I want...\n",
    "#Y_hat = len(Y_hat)\n",
    "\n",
    "#now we do K-means clustering on the rows of Y, which are the top k eignvectors of the laplacian above, or the bottom k of the normalized laplacian\n",
    "\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    a, c = sess.run([S, Y_hat])\n",
    "    \n",
    "print c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?tf.svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.10.0rc0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf .__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
