{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral Clustering using Adjacency Matrix and Laplacian:\n",
    "Adjacency:  optimizes on in group closeness\n",
    "Laplacian: Average cut\n",
    "A variant of the Laplacian: Normalized Cut\n",
    "\n",
    "In general, Laplacian has better behaved/more stable convergenence properties of eigenvectors (makes sense when we are dealing with random graphs).  \n",
    "\n",
    "TODO\n",
    "make function for laplacian\n",
    "make function for adjaceny matrix\n",
    "make function for non backtracking matrix\n",
    "\n",
    "make sampling method for blockmodel\n",
    "\n",
    "make function for power method\n",
    "\n",
    "make function for power method for subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#assume graphs are dictionaries of vertices with entries that are the incident vertices for now, we can change this later.  \n",
    "\n",
    "\n",
    "#compute laplacian\n",
    "    #f-Mf\n",
    "\n",
    "        #averaging function\n",
    "        \n",
    "simple_graph = {\n",
    "    0: [2,3],\n",
    "    1: [2, 3],\n",
    "    2: [3], \n",
    "    3: [0, 1]\n",
    "}\n",
    "\n",
    "simple_graph[1]\n",
    "\n",
    "vector = np.array([1,1,1,1])\n",
    "\n",
    "lst = [vector[i] for i in simple_graph[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AverageOperatorVertex(vertex, vector, graph):\n",
    "    lst = [vector[i] for i in graph[vertex]]\n",
    "    answer = np.sum(lst)\n",
    "    return(answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AverageOperatorVertex(vertex = 2, vector = np.array([1,2,3,4]), graph = simple_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def GraphLaplacian(graph, vector):\n",
    "    #takes in graph and vector on graph indices, returns new vector\n",
    "    new_vector = np.empty(len(vector),)\n",
    "    for i in graph:\n",
    "        #this step can be parallelized\n",
    "        new_vector[i] = vector[i]*len(graph[i])-AverageOperatorVertex(vertex=i, vector = vector, graph = graph)\n",
    "    return new_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2. -1. -0. -0. -0. -0. -0. -0. -0. -1.]\n",
      " [-1.  3. -1. -0. -0. -0. -1. -0. -0. -0.]\n",
      " [-0. -1.  3. -0. -0. -1. -1. -0. -0. -0.]\n",
      " [-0. -0. -0.  1. -0. -0. -1. -0. -0. -0.]\n",
      " [-0. -0. -0. -0.  0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -1. -0. -0.  2. -1. -0. -0. -0.]\n",
      " [-0. -1. -1. -1. -0. -1.  5. -1. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -1.  2. -1. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0. -1.  1. -0.]\n",
      " [-1. -0. -0. -0. -0. -0. -0. -0. -0.  1.]]\n",
      "[ 2. -3.  2. -1.  0. -2.  4. -2.  1. -1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2., -3.,  2., -1.,  0., -2.,  4., -2.,  1., -1.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er_graph_10 = nx.erdos_renyi_graph(10, 0.2, seed=1)\n",
    "nx.to_dict_of_lists(er_graph_10)\n",
    "print sp.sparse.csgraph.laplacian(nx.to_numpy_matrix(er_graph_10))\n",
    "print np.dot(sp.sparse.csgraph.laplacian(nx.to_numpy_matrix(er_graph_10)), [1,0,1,0,1,0,1,0,1,0])\n",
    "\n",
    "GraphLaplacian(nx.to_dict_of_lists(er_graph_10), [1,0,1,0,1,0,1,0,1,0])\n",
    "\n",
    "#yes!  They did the same thing!!!! So correct function confirmed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this is problematic for the spectral algorithm\n",
    "#as the unnormalized laplacian requires extraction of k smallest eigenvector, so far\n",
    "#we are extracting the k largest eigenvectors\n",
    "\n",
    "\n",
    "#first try at implementing net\n",
    "\n",
    "#nonlinearity?\n",
    "#fixed number of layers for iterations\n",
    "#fixed subspace dimension for number of eigenvectors\n",
    "\n",
    "\n",
    "def LaplacianEigenvalueExtract(Graph, layers=10, subspace_dim=1, vector=None):\n",
    "    #takes in graph, computes Laplacian, then does powermethod\n",
    "    #we end up with a list of k eigenvectors to do k-means on\n",
    "    #we assume Graph given as a dictionary\n",
    "    \n",
    "    if vector==None:\n",
    "        vector = np.random.normal(0,1,len(Graph)) #we initalize with function with random components as default\n",
    "    \n",
    "    eigenvectors = [vector]*subspace_dim #initialize list of eigvectors we want to return\n",
    "    \n",
    "    new_vector = vector \n",
    "    lmbda_lst = np.zeros(subspace_dim)#ghetto hack for operator tail recursion\n",
    "    for i in range(subspace_dim): #This is done for the number of eigenvectors we want to find.\n",
    "        #so this cannot be done in parallel.  \n",
    "\n",
    "        for j in range(layers): #This is iterated for the power we want to bring the operator, \n",
    "            #so this cannot be done in parallel:\n",
    "            tmp_vector = GraphLaplacian(graph=Graph, vector=new_vector)\n",
    "            for k in range(subspace_dim):\n",
    "                tmp_vector = tmp_vector-lmbda_lst[k]*new_vector \n",
    "                \n",
    "                #this will only amount to something if our list contains eigenvalues\n",
    "            new_vector = tmp_vector/np.linalg.norm(tmp_vector)\n",
    "\n",
    "           \n",
    "        eigenvectors[i] = new_vector #this will already be normalized by the last iteration of j\n",
    "        lmbda_lst[i] = np.dot(GraphLaplacian(graph=Graph, vector = eigenvectors[i]), eigenvectors[i]) #since it is normalized,\n",
    "        #the scaling factor will be lamba\n",
    "        print lmbda_lst[i]\n",
    "\n",
    "        new_vector = np.random.normal(0,1,len(Graph))\n",
    "        #now we are onto finding the second eigenvector\n",
    "        #we should randomize the next vector\n",
    "    \n",
    "\n",
    "        \n",
    "    return eigenvectors\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lishali/.virtualenvs/stitchfix/lib/python2.7/site-packages/ipykernel/__main__.py:18: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.11033387308\n",
      "-5.46121248253e-17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([-0.06668608,  0.2610528 ,  0.14353418,  0.17392395,  0.        ,\n",
       "         0.18131746, -0.88880947,  0.22704687, -0.04442897,  0.01304926]),\n",
       " array([ 0.32793486,  0.32793486,  0.32793486,  0.32793486,  0.17924438,\n",
       "         0.32793486,  0.32793486,  0.32793486,  0.32793486,  0.32793486])]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(2)\n",
    "\n",
    "LaplacianEigenvalueExtract(Graph = nx.to_dict_of_lists(er_graph_10), layers =100000, subspace_dim=2, \n",
    "                          vector = np.random.normal(0,1,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ -2.26725847e-16,   2.26725847e-16,   2.99157099e-01,\n",
       "          5.50092286e-01,   1.05880186e+00,   2.00000000e+00,\n",
       "          2.47466903e+00,   3.10172249e+00,   4.40522337e+00,\n",
       "          6.11033387e+00]),\n",
       " array([[  3.31608274e-01,  -3.38683298e-02,  -4.34881048e-01,\n",
       "          -1.61958943e-01,  -1.15691988e-02,   5.00000000e-01,\n",
       "          -9.59407281e-02,   5.71772005e-01,   2.87798428e-01,\n",
       "          -6.66860830e-02],\n",
       "        [  3.31608274e-01,  -3.38683298e-02,  -1.19152888e-01,\n",
       "           1.25157067e-01,  -2.07637763e-01,   5.00000000e-01,\n",
       "          -1.95190675e-02,  -3.57884834e-01,  -6.07702749e-01,\n",
       "           2.61052804e-01],\n",
       "        [  3.31608274e-01,  -3.38683298e-02,   1.63185651e-02,\n",
       "           2.65781018e-01,  -3.45128199e-01,   2.22044605e-16,\n",
       "          -7.49681661e-02,  -4.53440598e-01,   6.83402450e-01,\n",
       "           1.43534176e-01],\n",
       "        [  3.31608274e-01,  -3.38683298e-02,   1.38046986e-01,\n",
       "           4.50761749e-01,   7.88557356e-01,  -4.44089210e-16,\n",
       "          -1.08943038e-01,   3.89806325e-02,   3.44302746e-02,\n",
       "           1.73923954e-01],\n",
       "        [ -1.01604989e-01,  -9.94824822e-01,  -5.55111512e-17,\n",
       "           1.11022302e-16,  -6.59194921e-17,  -1.38777878e-17,\n",
       "           5.55111512e-17,   5.55111512e-17,   0.00000000e+00,\n",
       "           0.00000000e+00],\n",
       "        [  3.31608274e-01,  -3.38683298e-02,   6.64775185e-02,\n",
       "           3.23180711e-01,  -4.15955816e-01,  -5.00000000e-01,\n",
       "          -1.80518955e-01,   4.85936410e-01,  -2.35387566e-01,\n",
       "           1.81317460e-01],\n",
       "        [  3.31608274e-01,  -3.38683298e-02,   9.67492504e-02,\n",
       "           2.02801188e-01,  -4.63686401e-02,  -4.90348503e-16,\n",
       "           1.60654923e-01,  -8.19264719e-02,  -1.17242775e-01,\n",
       "          -8.88809473e-01],\n",
       "        [  3.31608274e-01,  -3.38683298e-02,   3.53112845e-01,\n",
       "          -2.62433973e-01,  -2.58357636e-03,  -5.55111512e-17,\n",
       "           7.89656080e-01,   1.30889210e-01,   5.55243275e-02,\n",
       "           2.27046871e-01],\n",
       "        [  3.31608274e-01,  -3.38683298e-02,   5.03840225e-01,\n",
       "          -5.83306230e-01,   4.39369828e-02,   1.69131352e-16,\n",
       "          -5.35480209e-01,  -6.22771134e-02,  -1.63056345e-02,\n",
       "          -4.44289700e-02],\n",
       "        [  3.31608274e-01,  -3.38683298e-02,  -6.20511455e-01,\n",
       "          -3.59982588e-01,   1.96748854e-01,  -5.00000000e-01,\n",
       "           6.50591598e-02,  -2.72049240e-01,  -8.45167547e-02,\n",
       "           1.30492615e-02]]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does seem to be very close....\n",
    "\n",
    "\n",
    "#omg that worked, this is just coded insanely terribly, read the last eigenvector \n",
    "np.linalg.eigh(sp.sparse.csgraph.laplacian(nx.to_numpy_matrix(er_graph_10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#first try at implementing net for adjacnecy matrices\n",
    "\n",
    "def AdjacencyEigenvalueExtract(Graph, layers=10, subspace_dim=1, vector=None):\n",
    "    #takes in graph, computes Laplacian, then does powermethod\n",
    "    #we end up with a list of k eigenvectors to do k-means on\n",
    "    #we assume Graph given as a dictionary\n",
    "        \n",
    "        \n",
    "    if vector==None:\n",
    "        vector = np.random.normal(0,1,len(Graph)) #we initalize with function with random components as default\n",
    "    \n",
    "    eigenvectors = [vector]*subspace_dim #initialize list of eigvectors we want to return\n",
    "         \n",
    "    new_matrix = Graph\n",
    "    \n",
    "    for i in range(subspace_dim): #This is done for the number of eigenvectors we want to find.\n",
    "        #so this cannot be done in parallel.  \n",
    "\n",
    "        for j in range(layers): #This is iterated for the power we want to bring the operator, \n",
    "            #so this cannot be done in parallel:\n",
    "            tmp_vector = np.dot(new_matrix, vector) #this should be done in parallel since each component does not reference the other\n",
    "\n",
    "            new_vector = tmp_vector/np.linalg.norm(tmp_vector)\n",
    "            new_vector = np.array(new_vector)\n",
    "            new_vector = new_vector.reshape(10)\n",
    "            \n",
    "        eigenvectors[i] = new_vector #this will already be normalized by the last iteration of j\n",
    "\n",
    "        lmbda = np.dot(np.dot(eigenvectors[i], new_matrix), eigenvectors[i]) #eigenvector is already normalized\n",
    "        new_matrix = new_matrix - lmbda[0,0]*np.identity(len(Graph))\n",
    "        print lmbda[0,0]\n",
    "        \n",
    "\n",
    "        vector = np.random.normal(0,1,len(Graph))\n",
    "        #now we are onto finding the second eigenvector\n",
    "        #we should randomize the next vector\n",
    "    \n",
    "\n",
    "        \n",
    "    return eigenvectors\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.28426513445\n",
      "2.24403824477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([-0.19762488,  0.1211857 , -0.31234077, -0.40388971,  0.        ,\n",
       "         0.2583267 ,  0.65327   , -0.40094508,  0.11187399, -0.137141  ]),\n",
       " array([ 0.50050544,  0.27483225,  0.03338326, -0.17304786,  0.25809951,\n",
       "        -0.09393759, -0.4619708 , -0.38369783,  0.11111886,  0.44099146])]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#er_graph_10 = nx.erdos_renyi_graph(10, 0.2, seed=1)\n",
    "\n",
    "AdjacencyEigenvalueExtract(Graph = nx.to_numpy_matrix(er_graph_10),\n",
    "                           layers = 100000, \n",
    "    subspace_dim=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ -2.16045879e+00,  -1.59820643e+00,  -1.00000000e+00,\n",
       "         -7.54713673e-01,  -2.47509086e-18,   1.06992180e-16,\n",
       "          3.02324782e-01,   1.00000000e+00,   1.31474495e+00,\n",
       "          2.89630916e+00]),\n",
       " matrix([[ -2.54774785e-01,   4.22714525e-01,  -5.00000000e-01,\n",
       "            5.10966382e-02,   9.81277765e-18,  -2.60778306e-17,\n",
       "            3.69437993e-02,   2.88675135e-01,   6.26003278e-01,\n",
       "            1.64963909e-01],\n",
       "         [  4.32504183e-01,  -4.11092000e-01,  -3.33066907e-16,\n",
       "            2.91400108e-02,   5.50611531e-01,   1.73667140e-01,\n",
       "           -1.11030018e-01,   1.66533454e-16,   3.46894175e-01,\n",
       "            4.20829885e-01],\n",
       "         [ -5.81230860e-02,   5.40608665e-01,   5.00000000e-01,\n",
       "            2.15643334e-01,  -2.51277390e-17,   1.47073421e-16,\n",
       "           -3.18484306e-01,  -2.88675135e-01,   2.06165114e-02,\n",
       "            4.71880603e-01],\n",
       "         [  2.87674819e-01,   1.91660669e-01,  -2.22044605e-16,\n",
       "            3.82572023e-01,   1.84358899e-16,  -4.62838375e-16,\n",
       "            8.20221811e-01,   2.77555756e-17,  -1.44927293e-01,\n",
       "            2.00948486e-01],\n",
       "         [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           -6.93889390e-17,  -3.00800310e-01,   9.53687146e-01,\n",
       "            3.33066907e-16,   1.11022302e-16,  -5.55111512e-17,\n",
       "            1.38777878e-17],\n",
       "         [  3.14577941e-01,  -1.46598930e-01,  -5.00000000e-01,\n",
       "            9.68433532e-02,  -5.50611531e-01,  -1.73667140e-01,\n",
       "           -2.33229061e-01,  -2.88675135e-01,  -1.29246296e-01,\n",
       "            3.63873290e-01],\n",
       "         [ -6.21509592e-01,  -3.06313313e-01,   4.01185686e-16,\n",
       "           -2.88732337e-01,   5.50218363e-18,  -9.49177598e-17,\n",
       "            2.47973381e-01,  -2.26103084e-17,  -1.90542425e-01,\n",
       "            5.82008940e-01],\n",
       "         [  3.66112003e-01,   3.14973501e-01,   5.50834023e-17,\n",
       "           -5.06288478e-01,   1.31641787e-17,   4.01910703e-17,\n",
       "           -8.25099283e-02,   5.77350269e-01,  -3.43851790e-01,\n",
       "            2.28145560e-01],\n",
       "         [ -1.69460304e-01,  -1.97079361e-01,  -8.80802249e-17,\n",
       "            6.70835174e-01,  -3.22538109e-17,   9.28832265e-17,\n",
       "           -2.72918177e-01,   5.77350269e-01,  -2.61534977e-01,\n",
       "            7.87711349e-02],\n",
       "         [  1.17926242e-01,  -2.64493070e-01,   5.00000000e-01,\n",
       "           -6.77033424e-02,  -5.50611531e-01,  -1.73667140e-01,\n",
       "            1.22199044e-01,   2.88675135e-01,   4.76140471e-01,\n",
       "            5.69565953e-02]]))"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigh(nx.to_numpy_matrix(er_graph_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1, 9], 1: [0, 2, 6], 2: [1, 5, 6], 3: [6], 4: [], 5: [2, 6], 6: [1, 2, 3, 5, 7], 7: [8, 6], 8: [7], 9: [0]}\n",
      "[[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 1.  0.  1.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  1.  1.  0.  1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "er_graph_10 = nx.erdos_renyi_graph(10, 0.2, seed=1)\n",
    "print nx.to_dict_of_lists(er_graph_10)\n",
    "print nx.to_numpy_matrix(er_graph_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nx.to_numpy_matrix(er_graph_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
