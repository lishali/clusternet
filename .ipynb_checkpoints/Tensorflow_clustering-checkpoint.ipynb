{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals\n",
    "\n",
    "    -implement spectral clustering\n",
    "    -implement belief propagation\n",
    "    -implement it with power method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla Belief propagation algorithm\n",
    "\n",
    "Input: a stochastic block model (adjaceny matrix)\n",
    "\n",
    "1) for each v, v' adajecnt, randomly draw y^1_vv' from N(0,1)\n",
    "\n",
    "2) find all cycles in G of length r or less.  To do this, we may have to multiply r times, but avoid the backtracking ones.  \n",
    "\n",
    "3) for each 1<t<m and each adjacent v, v' set y^t_vv' = sum of all the y's up to that t....since we seeded it with N(0,1) we will have the value for y^1.  Howver, if (v,v') is part of a cycle of r or less, don't do this.  Instead, \n",
    "4) if your edge is part of a r cycle, then we subtract from the previous sum, the accumulated influence of the other adjacent edge in our cycle, unless the r cycle is the same lenght as the time steps, in which case we just subtract the original randomized N(0,1)\n",
    "\n",
    "5) Let Y be the matrix composed of all y_vv' summed up with edge vertices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first try implementing power method in tensorflow\n",
    "\n",
    "#feed in graphs, as in adjaceny matrices, or just nodes and connected edges?\n",
    "\n",
    "#each layer will feed in a random vector, then multiply our matrix by the random vector\n",
    "#many times.  At the end, we subtract away the orignal vector component\n",
    "\n",
    "#next layer we just randomize another vector...\n",
    "\n",
    "#how many layers.  The depth can be learned by adding identify layers, which is essentially \n",
    "#self multiplication.  \n",
    "\n",
    "#adjaceny matrix to graph laplacian \n",
    "\n",
    "#suppose for simplicity that our graph has the same dimnension\n",
    "\n",
    "#10by10 graph, so feed adjacency matrix\n",
    "dim_graph = 10\n",
    "dim_subspace = 3\n",
    "\n",
    "x = tf.placeholder(\"float\", shape = [dim_graph, dim_graph])\n",
    "y = tf.placeholder(\"float\", shape = [None, dim_graph])\n",
    "#y is our community classification answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize the k random vectors (whcih should be tuned)\n",
    "#that we are feeding to the laplacian operator\n",
    "d = {}\n",
    "for i in range(1,dim_subspace):\n",
    "    d[\"v{}\".format(i)] = tf.Variable(tf.random_normal(shape=[1, dim_graph], \n",
    "                         mean=0.0, \n",
    "                         stddev = 1.0))\n",
    "\n",
    "#may have to define another way...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#laplacian\n",
    "\n",
    "#diffusion:\n",
    "\n",
    "def DiffusionVertex(vertex, graph, vector):\n",
    "    #assume graph is in form of adjacency matrix \n",
    "    neighbour_vector = tf.slice(graph, begin=[vertex,0], size=[1,dim_graph])\n",
    "    prod = tf.mul(vector, neighbour_vector)\n",
    "    diffusion = tf.reduce_sum(prod, 1)\n",
    "    return(diffusion)\n",
    "\n",
    "def GraphLaplacian(graph, vector):\n",
    "    #takes in graph and vector on graph indices, returns new vector\n",
    "    tmp_v = tf.constant(range(dim_graph))\n",
    "    def DiffusionVertex_1(vertex):\n",
    "        return DiffusionVertex(vertex, graph, vector)\n",
    "    diffusion_vector = tf.map_fn(DiffusionVertex_1, tmp_v) \n",
    "    \n",
    "    return tf.reduce_sum(diffusion_vector)\n",
    "\n",
    "def euclidean_norm(tensor): #need to have this for tf to work\n",
    "    square_tensor = tf.square(tensor)\n",
    "    norm_squared = tf.reduce_sum(square_tensor)\n",
    "    euclidean_norm = tf.sqrt(norm_squared)\n",
    "    return euclidean_norm\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,   4.,   9.,  16.,  25.,  36.], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elems = np.array([1, 2, 3, 4, 5, 6], dtype=\"float32\")\n",
    "squares = tf.map_fn(lambda x: x * x, elems)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(squares)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  3.,   8.,  15.],\n",
      "       [  6.,  12.,  20.],\n",
      "       [  9.,  16.,  25.]], dtype=float32), array([[ 3.,  4.,  5.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#test to see if your diffusion operator works\n",
    "\n",
    "x = tf.constant([[1,2,3], [2,3,4], [3,4,5]], dtype=tf.float32)\n",
    "y = tf.Variable(tf.random_normal(shape=[3], \n",
    "                         mean=0.0, \n",
    "                         stddev = 1.0))\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "answer = tf.mul(x,tf.slice(x, [2,0], [1,3])),tf.slice(x, [2,0], [1,3])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print sess.run(answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.58576\n"
     ]
    }
   ],
   "source": [
    "dim_graph = 3\n",
    "dim_subspace = 3\n",
    "\n",
    "x = tf.constant([[1,2,3], [2,3,4], [3,4,5]])\n",
    "x = tf.cast(x, tf.float32)\n",
    "f_x = tf.Variable(tf.random_normal(shape=[3], \n",
    "                         mean=0.0, \n",
    "                         stddev = 1.0))\n",
    "\n",
    "blah = [DiffusionVertex(i, graph=x, vector=f_x) for i in range(dim_graph)]\n",
    "blah = tf.reduce_sum(tf.pack(blah))\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print sess.run(blah)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"div_41:0\", shape=(3, 1), dtype=float32)\n",
      "[array([[ 0.38511941],\n",
      "       [ 0.5595153 ],\n",
      "       [ 0.73391116]], dtype=float32), array([[-0.38507888],\n",
      "       [-0.55950832],\n",
      "       [-0.73393774]], dtype=float32), array([[-0.38455883],\n",
      "       [-0.55941874],\n",
      "       [-0.73427862]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#now let continue with the powermethod from the above:\n",
    "#since the largest k eigenvalues is supposed to come from the adjacney matrix, \n",
    "#we leave the diffusion component for now\n",
    "\n",
    "dim_graph = 3\n",
    "dim_subspace = 3\n",
    "\n",
    "#x = tf.placeholder(tf.float32, shape=(dim_graph, dim_graph))\n",
    "x = tf.cast(x, tf.float32)\n",
    "\n",
    "answer_lst = []\n",
    "\n",
    "lmbda_lst = []\n",
    "\n",
    "f = {}\n",
    "for i in range(1,dim_subspace+1):\n",
    "    f[\"v{}\".format(i)] = tf.Variable(tf.random_normal(shape=[dim_graph, 1], \n",
    "                         mean=0.0, \n",
    "                         stddev = 1.0))\n",
    "    \n",
    "    \n",
    "\n",
    "adjacency_vector = tf.matmul(x, f[\"v1\"])\n",
    "adjacency_vector = adjacency_vector/euclidean_norm(adjacency_vector)\n",
    "\n",
    "adjacency_vector = tf.matmul(x, adjacency_vector)\n",
    "adjacency_vector = adjacency_vector/euclidean_norm(adjacency_vector)\n",
    "\n",
    "adjacency_vector = tf.matmul(x, adjacency_vector)\n",
    "adjacency_vector = adjacency_vector/euclidean_norm(adjacency_vector)\n",
    "print adjacency_vector\n",
    "answer_lst.append(adjacency_vector)\n",
    "\n",
    "#lmbda_lst.append(euclidean_norm(tf.matmul(x, adjacency_vector)) #since it is already normalized\n",
    "\n",
    "                 \n",
    "adjacency_vector = tf.sub(f[\"v2\"], adjacency_vector)\n",
    "adjacency_vector = tf.matmul(x, adjacency_vector)\n",
    "adjacency_vector = adjacency_vector/euclidean_norm(adjacency_vector)\n",
    "\n",
    "adjacency_vector = tf.matmul(x, adjacency_vector)\n",
    "adjacency_vector = adjacency_vector/euclidean_norm(adjacency_vector)\n",
    "\n",
    "adjacency_vector = tf.matmul(x, adjacency_vector)\n",
    "adjacency_vector = adjacency_vector/euclidean_norm(adjacency_vector)\n",
    "\n",
    "answer_lst.append(adjacency_vector)\n",
    "#lmbda_lst.append(euclidean_norm(tf.matmul(x, adjacency_vector)) #since it is already normalized\n",
    "\n",
    "\n",
    "adjacency_vector = tf.sub(tf.sub(f[\"v3\"], adjacency_vector), answer_lst[1])\n",
    "adjacency_vector = tf.matmul(x, adjacency_vector)\n",
    "adjacency_vector = adjacency_vector/euclidean_norm(adjacency_vector)\n",
    "\n",
    "adjacency_vector = tf.matmul(x, adjacency_vector)\n",
    "adjacency_vector = adjacency_vector/euclidean_norm(adjacency_vector)\n",
    "\n",
    "adjacency_vector = tf.matmul(x, adjacency_vector)\n",
    "adjacency_vector = adjacency_vector/euclidean_norm(adjacency_vector)\n",
    "\n",
    "answer_lst.append(adjacency_vector)\n",
    "#lmbda_lst.append(euclidean_norm(tf.matmul(x, adjacency_vector)) #since it is already normalized\n",
    "\n",
    "                 \n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print sess.run(answer_lst, feed_dict = {x: [[1,2,3], [2,3,4], [3,4,5]]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 18.08835174],\n",
       "        [ 26.55926778],\n",
       "        [ 35.03018382]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matrix([[1,2,3], [2,3,4], [3,4,5]])*np.matrix([[ 2.25037885], [2.82363868], [3.39689851]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 18.0883522 ]\n",
      " [ 26.55926895]\n",
      " [ 35.0301857 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = tf.matmul(tf.constant([[1.0,2.0,3.], [2.,3.,4.], [3.,4.,5.]], shape=[3,3]),\n",
    "          tf.constant([ 2.25037885, 2.82363868, 3.39689851], shape=[3,1]))\n",
    "with tf.Session() as sess:\n",
    "    print sess.run(y)\n",
    "    \n",
    "    #ok, they match, so at least that is not wrong....\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.24716772],\n",
      "       [ 0.08627883],\n",
      "       [-0.96512389]], dtype=float32), array([[ 0.5934819 ],\n",
      "       [ 0.2071667 ],\n",
      "       [-0.46347761]], dtype=float32)]\n",
      "[array([[ 0.12172756],\n",
      "       [ 0.04249142],\n",
      "       [-0.99165362]], dtype=float32), array([[ 0.40214682],\n",
      "       [ 0.14037734],\n",
      "       [-0.65521783]], dtype=float32)]\n",
      "[array([[ 0.05911896],\n",
      "       [ 0.02063665],\n",
      "       [-0.99803764]], dtype=float32), array([[ 0.22093283],\n",
      "       [ 0.077121  ],\n",
      "       [-0.74595112]], dtype=float32)]\n",
      "[array([[ 0.02915056],\n",
      "       [ 0.01017559],\n",
      "       [-0.99952322]], dtype=float32), array([[ 0.11268038],\n",
      "       [ 0.03933334],\n",
      "       [-0.77272373]], dtype=float32)]\n",
      "[array([[ 0.01444603],\n",
      "       [ 0.00504267],\n",
      "       [-0.99988294]], dtype=float32), array([[ 0.05631948],\n",
      "       [ 0.01965943],\n",
      "       [-0.77963114]], dtype=float32)]\n",
      "[array([[ 0.00716838],\n",
      "       [ 0.00250227],\n",
      "       [-0.99997115]], dtype=float32), array([[ 0.02800598],\n",
      "       [ 0.00977604],\n",
      "       [-0.78135294]], dtype=float32)]\n",
      "[array([[ 0.00355825],\n",
      "       [ 0.00124208],\n",
      "       [-0.99999297]], dtype=float32), array([[ 0.01390891],\n",
      "       [ 0.00485518],\n",
      "       [-0.78177834]], dtype=float32)]\n",
      "[array([[  1.76638993e-03],\n",
      "       [  6.16593286e-04],\n",
      "       [ -9.99998212e-01]], dtype=float32), array([[ 0.00690557],\n",
      "       [ 0.00241052],\n",
      "       [-0.78188324]], dtype=float32)]\n",
      "[array([[  8.76890670e-04],\n",
      "       [  3.06096161e-04],\n",
      "       [ -9.99999642e-01]], dtype=float32), array([[ 0.00342825],\n",
      "       [ 0.0011967 ],\n",
      "       [-0.78190905]], dtype=float32)]\n",
      "[array([[  4.35317867e-04],\n",
      "       [  1.51956279e-04],\n",
      "       [ -9.99999881e-01]], dtype=float32), array([[  1.70191051e-03],\n",
      "       [  5.94085432e-04],\n",
      "       [ -7.81916142e-01]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#now let try to get the first egenvector right with some backprop\n",
    "dim_graph = 3\n",
    "dim_subspace = 1\n",
    "\n",
    "\n",
    "x = [[1,0,0], [0,1,0], [0,0,5]]\n",
    "y = np.linalg.eig([[1,0,0], [0,1,0], [0,0,5]])[1][0]\n",
    "    \n",
    "x = tf.cast(x, tf.float32)\n",
    "y = tf.cast(y, tf.float32)\n",
    "\n",
    "f = {}\n",
    "for i in range(1,dim_subspace+1):\n",
    "    f[\"v{}\".format(i)] = tf.Variable(tf.random_uniform(shape = [dim_graph,1],\n",
    "                                                       minval=-1,\n",
    "                                                       maxval = 1,\n",
    "                                                       dtype = tf.float32))\n",
    "y = f[\"v1\"]\n",
    "y = y/euclidean_norm(y)\n",
    "    \n",
    "    \n",
    "\n",
    "adjacency_vector = tf.matmul(x, y)\n",
    "adjacency_vector = adjacency_vector/euclidean_norm(adjacency_vector)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(y-adjacency_vector))                \n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "\n",
    "train = optimizer.minimize(loss = cost, var_list = [f[\"v1\"]])\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "for i in xrange(1000):\n",
    "    sess.run(train)\n",
    "    if i%100==0:\n",
    "        print sess.run([adjacency_vector, f[\"v1\"]])\n",
    "#getting stuck in some local min...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999987296\n",
      "(array([  9.62347538e+00,  -6.23475383e-01,   9.06797114e-17]), array([[-0.38508979, -0.82767094,  0.40824829],\n",
      "       [-0.55951021, -0.14241368, -0.81649658],\n",
      "       [-0.73393063,  0.54284358,  0.40824829]]))\n"
     ]
    }
   ],
   "source": [
    "print np.linalg.norm([[  4.35317867e-04],\n",
    "       [  1.51956279e-04],\n",
    "       [ -9.99999881e-01]])\n",
    "print np.linalg.eig([[1,2,3], [2,3,4], [3,4,5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above does not do well with certain vectors, but with the identity it is not totally off....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem with using tf.map_fn below.  Using list instead, however this the step that is parallelizable, hence not sure that writing in terms of for loop is ideal... How will tensorflow handle it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.81568682]\n",
      " [-1.62019897]\n",
      " [-2.42471123]]\n"
     ]
    }
   ],
   "source": [
    "y = tf.matmul(tf.constant([[1.0,2.0,3.], [2.,3.,4.], [3.,4.,5.]], shape=[3,3]),\n",
    "          tf.constant(np.linalg.eig([[1,2,3], [2,3,4], [3,4,5]])[1][0], shape=[3,1], dtype= tf.float32))\n",
    "with tf.Session() as sess:\n",
    "    print sess.run(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.3163\n"
     ]
    }
   ],
   "source": [
    "dim_graph = 3\n",
    "dim_subspace = 3\n",
    "\n",
    "x = tf.constant([[1,2,3], [2,3,4], [3,4,5]])\n",
    "x = tf.cast(x, tf.float32)\n",
    "y = tf.Variable(tf.random_normal(shape=[dim_graph], \n",
    "                         mean=0.0, \n",
    "                         stddev = 1.0))\n",
    "\n",
    "tmp_v = np.array(range(dim_graph), dtype=\"int\")\n",
    "\n",
    "def DiffusionVertex_1(vertex):\n",
    "    return DiffusionVertex(vertex, x, y)\n",
    "\n",
    "diffusion_vector = [DiffusionVertex_1(i) for i in range(dim_graph)]\n",
    "#diffusion_vector = tf.scan(DiffusionVertex_1, tmp_v)\n",
    "diffusion_vector = tf.pack(diffusion_vector)\n",
    "\n",
    "#answer = tf.shape(tmp_v)\n",
    "answer = diffusion_vector\n",
    "\n",
    "#answer = tf.shape(diffusion_vector)\n",
    "answer = tf.reduce_sum(diffusion_vector)\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print sess.run(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
