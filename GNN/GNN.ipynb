{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needs fixing:\n",
    "    \n",
    "    -ineffcieint tf.diag .... we are doing n^2 computations when we could be being only n...figure out how to avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import linalg_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "communities = 2\n",
    "group_size = 10\n",
    "\n",
    "def Diffusion(A, F):\n",
    "    \"\"\"finds the diffusion of F via A\"\"\"\n",
    "    #F can be a batched signal\n",
    "    return tf.batch_matmul(A, F)\n",
    "\n",
    "\n",
    "def Diag(A, F):\n",
    "    \"\"\"multiplies F by diagonal vector\"\"\"\n",
    "    diag_matrix = tf.expand_dims(tf.reduce_sum(Adj, 1), 1)\n",
    "    return tf.mul(diag_matrix, F)\n",
    "\n",
    "def Diffusion_normed(A, F):\n",
    "    \"\"\"D^-1W\"\"\"\n",
    "    return tf.mul(tf.div(1.0, Diag(A, F)), tf.batch_matmul(A, F))\n",
    "\n",
    "def Laplacian(A, F):\n",
    "    \"\"\"find the laplacian of a graph A given signal F\"\"\"\n",
    "    \n",
    "    return tf.sub(tf.transpose(Diffusion(A,F)), Diag(A,F))\n",
    "\n",
    "def Max_norm(F):\n",
    "    \"\"\"Returns the maximum of the signal\"\"\"\n",
    "    return tf.reduce_max(F)\n",
    "\n",
    "def L2_norm(F):\n",
    "    \"\"\"Returns L2 norm of F\"\"\"\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(F)))\n",
    "\n",
    "def balanced_stochastic_blockmodel(communities=2, groupsize=3, p_in=1.0, p_out=0.0):\n",
    "    \"\"\"gives dense adjacency matrix representaiton of randomly generated SBM with balanced community size\"\"\"\n",
    "\n",
    "    G = nx.planted_partition_graph(l=communities, k=groupsize, p_in=p_in, p_out =p_out)\n",
    "    A = nx.adjacency_matrix(G).todense()\n",
    "    \n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_vm(v, m):\n",
    "    shape = tf.shape(v)\n",
    "    rank = shape.get_shape()[0].value\n",
    "    v = tf.expand_dims(v, rank)\n",
    "\n",
    "    vm = tf.mul(v, m)\n",
    "\n",
    "    return tf.reduce_sum(vm, rank-1)\n",
    "\n",
    "def batch_vm2(x, m):\n",
    "    [input_size, output_size] = m.get_shape().as_list()\n",
    "\n",
    "    input_shape = tf.shape(x)\n",
    "    batch_rank = input_shape.get_shape()[0].value - 1\n",
    "    batch_shape = input_shape[:batch_rank]\n",
    "    output_shape = tf.concat(0, [batch_shape, [output_size]])\n",
    "\n",
    "    x = tf.reshape(x, [-1, input_size])\n",
    "    y = tf.matmul(x, m)\n",
    "\n",
    "    y = tf.reshape(y, output_shape)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.10.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_dim = 3\n",
    "communities = 2 #number of communities, chance to \n",
    "group_size = 2\n",
    "Size = 100\n",
    "p_min = 0.5\n",
    "p_max = 0.6\n",
    "\n",
    "\n",
    "#A = balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.6, p_out=0.01)\n",
    "#Adj = tf.cast(A, dtype = tf.float32)\n",
    "DATA = [np.asarray(balanced_stochastic_blockmodel(communities, group_size, p, 0.1*p)).astype(np.double) for p in np.linspace(p_min, p_max, Size)]\n",
    "DATA[1:2]\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[   0.        ,    0.        ],\n",
      "        [   0.        ,    0.        ],\n",
      "        [ 192.90757751,  131.36637878],\n",
      "        [ 202.95181274,  134.9052124 ]],\n",
      "\n",
      "       [[ 201.71510315,  135.57440186],\n",
      "        [ 212.63111877,  139.18081665],\n",
      "        [ 192.90757751,  131.36637878],\n",
      "        [ 202.95181274,  134.9052124 ]],\n",
      "\n",
      "       [[ 201.71510315,  135.57440186],\n",
      "        [ 212.63111877,  139.18081665],\n",
      "        [ 192.90757751,  131.36637878],\n",
      "        [ 202.95181274,  134.9052124 ]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#testing functions defined above\n",
    "\n",
    "\n",
    "signal_dim = 2\n",
    "batch_size = 3\n",
    "communities = 2 #number of communities, chance to \n",
    "group_size = 2\n",
    "dim = communities*group_size\n",
    "Size = 100\n",
    "p_min = 0.8\n",
    "p_max = 0.9\n",
    "Mean = 0.5\n",
    "\n",
    "\n",
    "#A = balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.6, p_out=0.01)\n",
    "#Adj = tf.cast(A, dtype = tf.float32)\n",
    "DATA = [np.asarray(balanced_stochastic_blockmodel(communities, group_size, p, 0.1*p)).astype(np.double) for p in np.linspace(p_min, p_max, Size)]\n",
    "\n",
    "\n",
    "Adj = tf.placeholder(dtype=tf.float32, shape=[None, communities*group_size, communities*group_size])\n",
    "Adj_mod = tf.reshape(tf.transpose(Adj, perm = [1,0,2]), [dim, batch_size*dim])#preparing it to be multiplied by F to broadcast\n",
    "\n",
    "#initialize a 10 dim signal\n",
    "F = tf.transpose(tf.Variable(tf.random_normal([communities*group_size, signal_dim], stddev=1.0, mean=0.0, seed=1)))\n",
    " \n",
    "#first diffusion step without cascading (unnormed version)\n",
    "Diff_1 = tf.reshape(tf.transpose(tf.matmul(F, Adj_mod)), shape=[batch_size, dim, signal_dim]) #shape=[batch_size, signal_dim, dim])\n",
    "\n",
    "diag_inv = tf.div(1.0, tf.reduce_sum(Adj, 2))\n",
    "diag_inv_batch = tf.matrix_diag(diag_inv) #to use in subsequent layers\n",
    "Diag_1 = tf.mul(tf.expand_dims(diag_inv, 1), F)\n",
    "\n",
    "\n",
    "C_a = tf.Variable(tf.random_normal([signal_dim, signal_dim], stddev=1.0, mean=Mean))\n",
    "C_b = tf.Variable(tf.random_normal([signal_dim, signal_dim], stddev=1.0, mean=Mean))\n",
    "\n",
    "#treat this as the new Adj_mod\n",
    "A1 = tf.matmul(C_a, tf.reshape(tf.transpose(Diag_1, perm=[1, 0,2]), [signal_dim, batch_size*dim]))\n",
    "B1 = tf.matmul(C_b, tf.reshape(tf.transpose(Diff_1, perm=[2, 0,1]), [signal_dim, batch_size*dim]))\n",
    "\n",
    "#transform it back into the 3-D tensor it is\n",
    "#Psi_1 = tf.transpose(tf.reshape(A1 + B1, shape = [signal_dim, batch_size, dim]), perm=[1,0,2])\n",
    "#relu also added\n",
    "Psi_1 = tf.transpose(tf.reshape(tf.nn.relu(A1 + B1), shape = [signal_dim, batch_size, dim]), perm=[1,2,0])\n",
    "\n",
    "###################\n",
    "###################\n",
    "Diff_2 = tf.batch_matmul(Adj, Psi_1)\n",
    "Diag_2 = tf.batch_matmul(diag_inv_batch, Psi_1)\n",
    "#we change the constants for now but let's keep these the same for another model\n",
    "C_a_1 = tf.Variable(tf.random_normal([signal_dim, signal_dim], stddev=1.0, mean=Mean))\n",
    "C_b_1 = tf.Variable(tf.random_normal([signal_dim, signal_dim], stddev=1.0, mean=Mean))\n",
    "\n",
    "A2 = tf.matmul(C_a_1, tf.reshape(tf.transpose(Diag_2, perm=[2, 0,1]), [signal_dim, batch_size*dim]))\n",
    "B2 = tf.matmul(C_b_1, tf.reshape(tf.transpose(Diff_2, perm=[2, 0,1]), [signal_dim, batch_size*dim]))\n",
    "\n",
    "Psi_2 = tf.transpose(tf.reshape(tf.nn.relu(A2 + B2), shape = [signal_dim, batch_size, dim]), perm=[1,2,0])\n",
    "\n",
    "##################\n",
    "##################\n",
    "Diff_3 = tf.batch_matmul(Adj, Psi_2)\n",
    "Diag_3 = tf.batch_matmul(diag_inv_batch, Psi_2)\n",
    "\n",
    "C_a_2 = tf.Variable(tf.random_normal([signal_dim, signal_dim], stddev=1.0, mean=Mean))\n",
    "C_b_2 = tf.Variable(tf.random_normal([signal_dim, signal_dim], stddev=1.0, mean=Mean))\n",
    "\n",
    "A3 = tf.matmul(C_a_2, tf.reshape(tf.transpose(Diag_3, perm=[2, 0,1]), [signal_dim, batch_size*dim]))\n",
    "B3 = tf.matmul(C_b_2, tf.reshape(tf.transpose(Diff_3, perm=[2, 0,1]), [signal_dim, batch_size*dim]))\n",
    "\n",
    "Psi_3 = tf.transpose(tf.reshape(tf.nn.relu(A3 + B3), shape = [signal_dim, batch_size, dim]), perm=[1,2,0])\n",
    "\n",
    "##################\n",
    "##################\n",
    "Diff_4 = tf.batch_matmul(Adj, Psi_3)\n",
    "Diag_4 = tf.batch_matmul(diag_inv_batch, Psi_3)\n",
    "\n",
    "C_a_3 = tf.Variable(tf.random_normal([signal_dim, signal_dim], stddev=1.0, mean=Mean))\n",
    "C_b_3 = tf.Variable(tf.random_normal([signal_dim, signal_dim], stddev=1.0, mean=Mean))\n",
    "\n",
    "A4 = tf.matmul(C_a_3, tf.reshape(tf.transpose(Diag_4, perm=[2, 0,1]), [signal_dim, batch_size*dim]))\n",
    "B4 = tf.matmul(C_b_3, tf.reshape(tf.transpose(Diff_4, perm=[2, 0,1]), [signal_dim, batch_size*dim]))\n",
    "\n",
    "Psi_4 = tf.transpose(tf.reshape(tf.nn.relu(A4 + B4), shape = [signal_dim, batch_size, dim]), perm=[1,2,0])\n",
    "\n",
    "\n",
    "##################\n",
    "##################\n",
    "Diff_5 = tf.batch_matmul(Adj, Psi_4)\n",
    "Diag_5 = tf.batch_matmul(diag_inv_batch, Psi_4)\n",
    "\n",
    "C_a_4 = tf.Variable(tf.random_normal([signal_dim, signal_dim], stddev=1.0, mean=Mean))\n",
    "C_b_4 = tf.Variable(tf.random_normal([signal_dim, signal_dim], stddev=1.0, mean=Mean))\n",
    "\n",
    "A5 = tf.matmul(C_a_4, tf.reshape(tf.transpose(Diag_5, perm=[2, 0,1]), [signal_dim, batch_size*dim]))\n",
    "B5 = tf.matmul(C_b_4, tf.reshape(tf.transpose(Diff_5, perm=[2, 0,1]), [signal_dim, batch_size*dim]))\n",
    "\n",
    "Psi_5 = tf.transpose(tf.reshape(tf.nn.relu(A5 + B5), shape = [signal_dim, batch_size, dim]), perm=[1,2,0])\n",
    "\n",
    "\n",
    "##################\n",
    "##################\n",
    "Diff_6 = tf.batch_matmul(Adj, Psi_5)\n",
    "Diag_6 = tf.batch_matmul(diag_inv_batch, Psi_5)\n",
    "\n",
    "C_a_5 = tf.Variable(tf.random_normal([signal_dim, signal_dim], stddev=1.0, mean=Mean))\n",
    "C_b_5 = tf.Variable(tf.random_normal([signal_dim, signal_dim], stddev=1.0, mean=Mean))\n",
    "\n",
    "A6 = tf.matmul(C_a_5, tf.reshape(tf.transpose(Diag_6, perm=[2, 0,1]), [signal_dim, batch_size*dim]))\n",
    "B6 = tf.matmul(C_b_5, tf.reshape(tf.transpose(Diff_6, perm=[2, 0,1]), [signal_dim, batch_size*dim]))\n",
    "\n",
    "Psi_6 = tf.transpose(tf.reshape(tf.nn.relu(A6 + B6), shape = [signal_dim, batch_size, dim]), perm=[1,2,0])\n",
    "\n",
    "##################\n",
    "##################\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in xrange(1):\n",
    "        sess.run(init)\n",
    "        \n",
    "        print sess.run([Psi_6], feed_dict={Adj: DATA[i:i+batch_size]})\n",
    "\n",
    "        #print sess.run([tf.batch_matmul(tf.matrix_diag(diag_inv), Psi_1)], feed_dict={Adj: DATA[i:i+batch_size]})\n",
    "\n",
    "        #print sess.run([tf.transpose(Psi_1, perm=[1, 0, 2])], feed_dict={Adj: DATA[i:i+batch_size]})\n",
    "        #print sess.run([tf.reshape(A1+B1, shape=[2, batch_size, dim])], feed_dict={Adj: DATA[i:i+batch_size]})\n",
    "        #print sess.run([tf.shape(Diag_mod)], feed_dict={Adj: DATA[i:i+batch_size]})\n",
    "        #print sess.run([B1], feed_dict={Adj: DATA[i:i+batch_size]})\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.694709770185618"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.reset_default_graph()\n",
    "np.dot(np.asarray([ 0.07222086,  4.90196609]),np.asarray([-1.18431401,  1.38316786]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
