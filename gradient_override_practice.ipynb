{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Registering two gradient with name 'GuidedRelu' !(Previous registration was in <module> /Users/xiangli/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-318-1e3d1f73b329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GuidedRelu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_GuidedReluGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_relu_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   1663\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[0;34m\"\"\"Registers the function `f` as gradient function for `op_type`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1665\u001b[0;31m     \u001b[0m_gradient_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1666\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/registry.pyc\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, candidate, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m       raise KeyError(\"Registering two %s with name '%s' !\"\n\u001b[1;32m     61\u001b[0m                      \u001b[0;34m\"(Previous registration was in %s %s:%d)\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                      (self._name, name, function_name, filename, line_number))\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Registering %s (%s) in %s.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Registering two gradient with name 'GuidedRelu' !(Previous registration was in <module> /Users/xiangli/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3)\""
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "\n",
    "@ops.RegisterGradient(\"GuidedRelu\")\n",
    "def _GuidedReluGrad(op, grad):\n",
    "    return tf.select(0. < grad, gen_nn_ops._relu_grad(grad, op.outputs[0]), tf.zeros(grad.get_shape()))\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import linalg_ops\n",
    "from tensorflow.python.ops import math_ops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@ops.RegisterGradient(\"blah1\")\n",
    "def _blah(op, grad):\n",
    "    return tf.select(0. < grad, tf.ones(grad.get_shape()), tf.zeros(grad.get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.   2.] [ 10.   2.] 104.0 [ 1.  1.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    g = tf.get_default_graph()\n",
    "    x = tf.constant([10., 2.])\n",
    "    with g.gradient_override_map({'Relu': 'blah1'}):\n",
    "        y = tf.nn.relu(x)\n",
    "        z = tf.reduce_sum(y ** 2)\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    print x.eval(), y.eval(), z.eval(), tf.gradients(z, x)[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.   2.] [ 10.   2.] -104.0 [-20.  -4.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    g = tf.get_default_graph()\n",
    "    x = tf.constant([10., 2.])\n",
    "    \n",
    "    y = tf.nn.relu(x)\n",
    "    z = tf.reduce_sum(-y ** 2)\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    print x.eval(), y.eval(), z.eval(), tf.gradients(z, x)[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "@ops.RegisterGradient(\"gradtest\")\n",
    "def _GradientTest(op, grad_e, grad_v):\n",
    "    \"\"\"Gradient for SelfAdjointEigV2 without dependence on eigenvalues\"\"\"\n",
    "    e = op.outputs[0]\n",
    "    v = op.outputs[1]\n",
    "    # a = op.inputs[0], which satisfies\n",
    "    # a[...,:,:] * v[...,:,i] = e[...,i] * v[...,i]\n",
    "    \n",
    "    # I do not care about e for my function....\n",
    "    with ops.control_dependencies([grad_e.op, grad_v.op]):\n",
    "        if grad_v is not None:\n",
    "            f = array_ops.matrix_set_diag(\n",
    "              math_ops.inv(array_ops.expand_dims(e, -2) - array_ops.expand_dims(e, -1)), array_ops.zeros_like(e))\n",
    "        \n",
    "            grad_a = math_ops.batch_matmul(v,\n",
    "              math_ops.batch_matmul(f * math_ops.batch_matmul(v, grad_v, adj_x=True),\n",
    "              v,adj_y=True))\n",
    "    return grad_a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@ops.RegisterGradient(\"adsfadfad\")\n",
    "def GradientTest2(op, grad_e, grad_v):\n",
    "    \"\"\"Gradient for SelfAdjointEigV2 derived with Joan\"\"\"\n",
    "    e = op.outputs[0]\n",
    "    v = op.outputs[1]\n",
    "    #dim = v.get_shape()\n",
    "    with ops.control_dependencies([grad_e.op, grad_v.op]):\n",
    "        if grad_v is not None:  \n",
    "            E = array_ops.diag(e)\n",
    "            #v_proj = arrary.ops.slice(v, [0,0], [])\n",
    "            grad_grassman = grad_v - math_ops.batch_matmul(math_ops.batch_matmul(v, grad_v), array_ops.transpose(v))\n",
    "            grad_a = math_ops.batch_matmul(E, math_ops.batch_matmul(v, array_ops.transpose(grad_grassman))\n",
    "                                           +math_ops.batch_matmul(grad_grassman, array_ops.transpose(v)))\n",
    "    return grad_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@ops.RegisterGradient(\"adfasdfasdfa\")\n",
    "def GradientTest2(op, grad_e, grad_v):\n",
    "    \"\"\"Gradient for SelfAdjointEigV2 derived with Joan with grad_stiefel instead of grassman\"\"\"\n",
    "    e = op.outputs[0]\n",
    "    v = op.outputs[1]\n",
    "    with ops.control_dependencies([grad_e.op, grad_v.op]):\n",
    "        if grad_v is not None:  \n",
    "            E = array.ops.diag(e)\n",
    "            #v_proj = arrary.ops.slice(v, [0,0], [])\n",
    "            grad_stiefel = grad_v - math_ops.batch_matmul(math_ops.batch_matmul(v, grad_v), array_ops.transpose(v))\n",
    "            grad_a = math_ops.batch_matmul(E, math_ops.batch_matmul(v, array_ops.transpose(grad_stiefel))\n",
    "                                           +math_ops.batch_matmul(grad_stiefel, array_ops.transpose(v)))\n",
    "    return grad_a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@ops.RegisterGradient(\"GradientTest4\")\n",
    "def GradientTest2(op, grad_e, grad_v):\n",
    "    \"\"\"Gradient to test vanishing problem\"\"\"\n",
    "    e = op.outputs[0]\n",
    "    v = op.outputs[1]\n",
    "    with ops.control_dependencies([grad_e.op, grad_v.op]):\n",
    "        if grad_v is not None:  \n",
    "            E = arrary.ops.diag(e)\n",
    "            #v_proj = arrary.ops.slice(v, [0,0], [])\n",
    "            grad_grassman = grad_v - math_ops.batch_matmul(math_ops.batch_matmul(v, grad_v), math_ops.transpose(v))\n",
    "            grad_a = math_ops.batch_matmul(E, math_ops.batch_matmul(v, math_ops.transpose(grad_grassman))\n",
    "                                           +math_ops.batch_matmul(grad_grassman, math_ops.transpose(v)))\n",
    "    return grad_a*10000000000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@ops.RegisterGradient(\"adfasdf\")\n",
    "def _adsfadsf(op, grad_e, grad_v):\n",
    "    \"\"\"Gradient to test vanishing problem\"\"\"\n",
    "    e = op.outputs[0]\n",
    "    v = op.outputs[1]\n",
    "    with ops.control_dependencies([grad_e.op, grad_v.op]):\n",
    "        if grad_v is not None:  \n",
    "            grad_a = grad_v\n",
    "    return grad_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def balanced_stochastic_blockmodel(communities=2, groupsize=3, p_in=1.0, p_out=0.0):\n",
    "    #gives dense adjacency matrix representaiton of randomly generated SBM with balanced community size\n",
    "\n",
    "    G = nx.planted_partition_graph(l=communities, k=groupsize, p_in=p_in, p_out =p_out)\n",
    "    A = nx.adjacency_matrix(G).todense()\n",
    "    \n",
    "    return A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "communities = 2 #number of communities, chance to \n",
    "group_size = 10 #number of nodes in each communitites (balanced so far)\n",
    "dim_graph = communities*group_size\n",
    "\n",
    "A = np.asarray(balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.9, p_out=0.2)).astype(np.double)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.140883104496 0.0 [[ 0.00269307  0.          0.          0.        ]\n",
      " [-0.005119   -0.00124502  0.          0.        ]\n",
      " [ 0.00135188  0.00320817 -0.00144805  0.        ]\n",
      " [ 0.00145645 -0.00086827 -0.00036872  0.        ]] 10.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    A = [[1,0,0,5], [3,0,0, 4], [5,5,7,0], [0,0,0,6]]\n",
    "    #np.asarray(balanced_stochastic_blockmodel(communities=communities,\n",
    "        #                                          groupsize=group_size, p_in=0.9, p_out=0.2)).astype(np.double)\n",
    "    #g = tf.get_default_graph()\n",
    "    A = tf.cast(A, dtype = tf.float64)\n",
    "    r = tf.constant(10.0, dtype = tf.float64)#tf.Variable(tf.random_normal([1], mean=0.0, stddev=10.0, dtype = tf.float64))\n",
    "    BH = (tf.square(r)-1)*A\n",
    "    eigenval, eigenvec = tf.self_adjoint_eig(BH)\n",
    "    eigenvec_proj = tf.slice(eigenvec, [0,0], [communities*group_size, 2])\n",
    "    #with g.gradient_override_map({'SelfAdjointEigV2': 'GradientTest3'}):\n",
    "    z = tf.reduce_sum(eigenvec_proj)     \n",
    "        \n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    print z.eval(), tf.gradients(z, r)[0].eval(), tf.gradients(eigenvec_proj, BH)[0].eval(), r.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.140883104496 -71635.2928372 [[  722.69873403   246.89362202    30.52571667   197.98523214]\n",
      " [  163.8596245   -761.25556195  -235.92879104  -288.01770355]\n",
      " [  -67.1063394    781.47760725  -630.26948522  -454.05651472]\n",
      " [ -909.70732485  1994.00385436  -949.03258805  -632.31125643]] 10.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    A = [[1,0,0,5], [3,0,0, 4], [5,5,7,0], [0,0,0,6]]\n",
    "    #np.asarray(balanced_stochastic_blockmodel(communities=communities,\n",
    "        #                                          groupsize=group_size, p_in=0.9, p_out=0.2)).astype(np.double)\n",
    "    g = tf.get_default_graph()\n",
    "    A = tf.cast(A, dtype = tf.float64)\n",
    "    r = tf.constant(10.0, dtype = tf.float64)#tf.Variable(tf.random_normal([1], mean=0.0, stddev=10.0, dtype = tf.float64))\n",
    "    BH = (tf.square(r)-1)*A\n",
    "    with g.gradient_override_map({'SelfAdjointEigV2': 'adsfadfad'}):\n",
    "        eigenval, eigenvec = tf.self_adjoint_eig(BH)\n",
    "        eigenvec_proj = tf.slice(eigenvec, [0,0], [communities*group_size, 2])\n",
    "        z = tf.reduce_sum(eigenvec_proj)     \n",
    "        \n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    print z.eval(), tf.gradients(z, r)[0].eval(), tf.gradients(eigenvec_proj, BH)[0].eval(), r.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.140883104496"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "No gradient defined for operation 'SelfAdjointEigV2_29' (op type: SelfAdjointEigV2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-326-8d5dd17e3a8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenvec_proj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/xiangli/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gradients.pyc\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\u001b[0m\n\u001b[1;32m    444\u001b[0m               raise LookupError(\n\u001b[1;32m    445\u001b[0m                   \u001b[0;34m\"No gradient defined for operation '%s' (op type: %s)\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                   (op.name, op.type))\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloop_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m           \u001b[0mloop_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnterGradWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: No gradient defined for operation 'SelfAdjointEigV2_29' (op type: SelfAdjointEigV2)"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    A = [[1,0,0,5], [3,0,0, 4], [5,5,7,0], [0,0,0,6]]\n",
    "    #np.asarray(balanced_stochastic_blockmodel(communities=communities,\n",
    "        #                                          groupsize=group_size, p_in=0.9, p_out=0.2)).astype(np.double)\n",
    "    g = tf.get_default_graph()\n",
    "    A = tf.cast(A, dtype = tf.float64)\n",
    "    r = tf.constant(10.0, dtype = tf.float64)#tf.Variable(tf.random_normal([1], mean=0.0, stddev=10.0, dtype = tf.float64))\n",
    "    BH = (tf.square(r)-1)*A\n",
    "    with g.gradient_override_map({'SelfAdjointEigV2': 'adfasdfasdfa'}):\n",
    "        eigenval, eigenvec = tf.self_adjoint_eig(BH)\n",
    "        eigenvec_proj = tf.slice(eigenvec, [0,0], [communities*group_size, 2])\n",
    "        z = tf.reduce_sum(eigenvec_proj)     \n",
    "        \n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    print z.eval(), tf.gradients(z, r)[0].eval(), tf.gradients(eigenvec_proj, BH)[0].eval(), r.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "communities=2\n",
    "group_size=2\n",
    "B = np.asarray(balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.9, p_out=0.1)).astype(np.double)\n",
    "adj = B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Tensor 'Slice_15:0' shape=(20, 5) dtype=float64> cannot be interpreted as a Tensor. (Tensor Tensor(\"Slice_15:0\", shape=(20, 5), dtype=float64) is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-267-c2d9e2115ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_l_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_l_bh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvec_proj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/xiangli/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m     \u001b[0mfetch_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \"\"\"\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \"\"\"\n\u001b[1;32m    287\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m/Users/xiangli/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 225\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    226\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument <tf.Tensor 'Slice_15:0' shape=(20, 5) dtype=float64> cannot be interpreted as a Tensor. (Tensor Tensor(\"Slice_15:0\", shape=(20, 5), dtype=float64) is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "A = tf.placeholder(dtype = tf.float64)\n",
    "B = tf.cast(A, dtype = tf.float64)\n",
    "communities=2\n",
    "group_size=2\n",
    "k = tf.Variable(tf.random_normal([1], mean=0.0, stddev=10.0, dtype = tf.float64))\n",
    "BH = (tf.square(k)-1)*B\n",
    "eigenval, eigenvec = tf.self_adjoint_eig(BH)\n",
    "eigen_proj = tf.slice(eigenvec, [0,0], [communities*group_size, 3])\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({'SelfAdjointEigV2': 'adfasdf'}):\n",
    "        loss = tf.reduce_sum(eigen_proj) \n",
    "         \n",
    "        optimizer = tf.train.GradientDescentOptimizer(1)\n",
    "        train = optimizer.minimize(loss)\n",
    "            \n",
    "        gradient_l_k = tf.gradients(loss, k)\n",
    "        gradient_l_bh = tf.gradients(loss, BH)\n",
    "        #grad_l_eigenvec = tf.gradients(loss, eigenvec_proj)\n",
    "        sess.run(init)\n",
    "        \n",
    "        print sess.run([k, loss, gradient_l_k, gradient_l_bh, eigenvec_proj], feed_dict = {A: adj})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-10.21789988]), 2.9999999999999996, [array([ -3.54504616e-17])], [array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  2.51308517e+14,   2.18909386e-03,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [ -2.51308517e+14,  -2.39451038e-03,  -4.58360424e-03,\n",
      "          0.00000000e+00],\n",
      "       [  7.39833015e-03,   6.77269810e-03,  -6.77269810e-03,\n",
      "          2.39451038e-03]])]]\n",
      "[array([-10.21789988]), 2.9999999999999996, [array([ -3.54504616e-17])], [array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  2.51308517e+14,   2.18909386e-03,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [ -2.51308517e+14,  -2.39451038e-03,  -4.58360424e-03,\n",
      "          0.00000000e+00],\n",
      "       [  7.39833015e-03,   6.77269810e-03,  -6.77269810e-03,\n",
      "          2.39451038e-03]])]]\n",
      "[array([-10.21789988]), 2.9999999999999996, [array([ -3.54504616e-17])], [array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  2.51308517e+14,   2.18909386e-03,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [ -2.51308517e+14,  -2.39451038e-03,  -4.58360424e-03,\n",
      "          0.00000000e+00],\n",
      "       [  7.39833015e-03,   6.77269810e-03,  -6.77269810e-03,\n",
      "          2.39451038e-03]])]]\n",
      "[array([-10.21789988]), 2.9999999999999996, [array([ -3.54504616e-17])], [array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  2.51308517e+14,   2.18909386e-03,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [ -2.51308517e+14,  -2.39451038e-03,  -4.58360424e-03,\n",
      "          0.00000000e+00],\n",
      "       [  7.39833015e-03,   6.77269810e-03,  -6.77269810e-03,\n",
      "          2.39451038e-03]])]]\n",
      "[array([-10.21789988]), 2.9999999999999996, [array([ -3.54504616e-17])], [array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  2.51308517e+14,   2.18909386e-03,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [ -2.51308517e+14,  -2.39451038e-03,  -4.58360424e-03,\n",
      "          0.00000000e+00],\n",
      "       [  7.39833015e-03,   6.77269810e-03,  -6.77269810e-03,\n",
      "          2.39451038e-03]])]]\n",
      "[array([-10.21789988]), 2.9999999999999996, [array([ -3.54504616e-17])], [array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  2.51308517e+14,   2.18909386e-03,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [ -2.51308517e+14,  -2.39451038e-03,  -4.58360424e-03,\n",
      "          0.00000000e+00],\n",
      "       [  7.39833015e-03,   6.77269810e-03,  -6.77269810e-03,\n",
      "          2.39451038e-03]])]]\n",
      "[array([-10.21789988]), 2.9999999999999996, [array([ -3.54504616e-17])], [array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  2.51308517e+14,   2.18909386e-03,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [ -2.51308517e+14,  -2.39451038e-03,  -4.58360424e-03,\n",
      "          0.00000000e+00],\n",
      "       [  7.39833015e-03,   6.77269810e-03,  -6.77269810e-03,\n",
      "          2.39451038e-03]])]]\n",
      "[array([-10.21789988]), 2.9999999999999996, [array([ -3.54504616e-17])], [array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  2.51308517e+14,   2.18909386e-03,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [ -2.51308517e+14,  -2.39451038e-03,  -4.58360424e-03,\n",
      "          0.00000000e+00],\n",
      "       [  7.39833015e-03,   6.77269810e-03,  -6.77269810e-03,\n",
      "          2.39451038e-03]])]]\n",
      "[array([-10.21789988]), 2.9999999999999996, [array([ -3.54504616e-17])], [array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  2.51308517e+14,   2.18909386e-03,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [ -2.51308517e+14,  -2.39451038e-03,  -4.58360424e-03,\n",
      "          0.00000000e+00],\n",
      "       [  7.39833015e-03,   6.77269810e-03,  -6.77269810e-03,\n",
      "          2.39451038e-03]])]]\n",
      "[array([-10.21789988]), 2.9999999999999996, [array([ -3.54504616e-17])], [array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  2.51308517e+14,   2.18909386e-03,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [ -2.51308517e+14,  -2.39451038e-03,  -4.58360424e-03,\n",
      "          0.00000000e+00],\n",
      "       [  7.39833015e-03,   6.77269810e-03,  -6.77269810e-03,\n",
      "          2.39451038e-03]])]]\n"
     ]
    }
   ],
   "source": [
    "B = np.asarray(balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.4, p_out=0.1)).astype(np.double)\n",
    "B = tf.cast(B, dtype = tf.float64)\n",
    "k = tf.Variable(tf.random_normal([1], mean=0.0, stddev=10.0, dtype = tf.float64))\n",
    "BH = (tf.square(k))*B\n",
    "eigenval, eigenvec = tf.self_adjoint_eig(BH)\n",
    "\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    loss = tf.reduce_sum(eigenvec) \n",
    "         \n",
    "    optimizer = tf.train.GradientDescentOptimizer(1)\n",
    "    train = optimizer.minimize(loss)\n",
    "            \n",
    "    gradient_r = tf.gradients(loss, k)\n",
    "    gradient_u = tf.gradients(loss, eigenvec)\n",
    "    sess.run(init)\n",
    "    for i in range(10):\n",
    "        sess.run(train)\n",
    "        print sess.run([k , loss, gradient_r, tf.gradients(eigenvec, BH)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9028712499999998"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1.90287125e-15*1000000000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `tf.gradient_override_map` not found.\n"
     ]
    }
   ],
   "source": [
    "?tf.gradient_override_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
