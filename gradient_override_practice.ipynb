{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Registering two gradient with name 'GuidedRelu' !(Previous registration was in <module> /Users/xiangli/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-318-1e3d1f73b329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GuidedRelu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_GuidedReluGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_relu_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   1663\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[0;34m\"\"\"Registers the function `f` as gradient function for `op_type`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1665\u001b[0;31m     \u001b[0m_gradient_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1666\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiangli/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/registry.pyc\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, candidate, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m       raise KeyError(\"Registering two %s with name '%s' !\"\n\u001b[1;32m     61\u001b[0m                      \u001b[0;34m\"(Previous registration was in %s %s:%d)\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                      (self._name, name, function_name, filename, line_number))\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Registering %s (%s) in %s.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Registering two gradient with name 'GuidedRelu' !(Previous registration was in <module> /Users/xiangli/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3)\""
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import linalg_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "\n",
    "@ops.RegisterGradient(\"GuidedRelu\")\n",
    "def _GuidedReluGrad(op, grad):\n",
    "    return tf.select(0. < grad, gen_nn_ops._relu_grad(grad, op.outputs[0]), tf.zeros(grad.get_shape()))\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@ops.RegisterGradient(\"blah1\")\n",
    "def _blah(op, grad):\n",
    "    return tf.select(0. < grad, tf.ones(grad.get_shape()), tf.zeros(grad.get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.   2.] [ 10.   2.] 104.0 [ 1.  1.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    g = tf.get_default_graph()\n",
    "    x = tf.constant([10., 2.])\n",
    "    with g.gradient_override_map({'Relu': 'blah1'}):\n",
    "        y = tf.nn.relu(x)\n",
    "        z = tf.reduce_sum(y ** 2)\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    print x.eval(), y.eval(), z.eval(), tf.gradients(z, x)[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.   2.] [ 10.   2.] -104.0 [-20.  -4.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    g = tf.get_default_graph()\n",
    "    x = tf.constant([10., 2.])\n",
    "    \n",
    "    y = tf.nn.relu(x)\n",
    "    z = tf.reduce_sum(-y ** 2)\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    print x.eval(), y.eval(), z.eval(), tf.gradients(z, x)[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "@ops.RegisterGradient(\"gradtest\")\n",
    "def _GradientTest(op, grad_e, grad_v):\n",
    "    \"\"\"Gradient for SelfAdjointEigV2 without dependence on eigenvalues\"\"\"\n",
    "    e = op.outputs[0]\n",
    "    v = op.outputs[1]\n",
    "    # a = op.inputs[0], which satisfies\n",
    "    # a[...,:,:] * v[...,:,i] = e[...,i] * v[...,i]\n",
    "    \n",
    "    # I do not care about e for my function....\n",
    "    with ops.control_dependencies([grad_e.op, grad_v.op]):\n",
    "        if grad_v is not None:\n",
    "            f = array_ops.matrix_set_diag(\n",
    "              math_ops.inv(array_ops.expand_dims(e, -2) - array_ops.expand_dims(e, -1)), array_ops.zeros_like(e))\n",
    "        \n",
    "            grad_a = math_ops.batch_matmul(v,\n",
    "              math_ops.batch_matmul(f * math_ops.batch_matmul(v, grad_v, adj_x=True),\n",
    "              v,adj_y=True))\n",
    "    return grad_a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@ops.RegisterGradient(\"adsfadfad\")\n",
    "def GradientTest2(op, grad_e, grad_v):\n",
    "    \"\"\"Gradient for SelfAdjointEigV2 derived with Joan\"\"\"\n",
    "    e = op.outputs[0]\n",
    "    v = op.outputs[1]\n",
    "    #dim = v.get_shape()\n",
    "    with ops.control_dependencies([grad_e.op, grad_v.op]):\n",
    "        if grad_v is not None:  \n",
    "            E = array_ops.diag(e)\n",
    "            #v_proj = arrary.ops.slice(v, [0,0], [])\n",
    "            grad_grassman = grad_v - math_ops.batch_matmul(math_ops.batch_matmul(v, grad_v), array_ops.transpose(v))\n",
    "            grad_a = math_ops.batch_matmul(E, math_ops.batch_matmul(v, array_ops.transpose(grad_grassman))\n",
    "                                           +math_ops.batch_matmul(grad_grassman, array_ops.transpose(v)))\n",
    "    return grad_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@ops.RegisterGradient(\"aj\")\n",
    "def GradientTest2(op, grad_e, grad_v):\n",
    "    \"\"\"Gradient for SelfAdjointEigV2 derived with Joan with grad_stiefel instead of grassman\"\"\"\n",
    "    e = op.outputs[0]\n",
    "    v = op.outputs[1]\n",
    "    with ops.control_dependencies([grad_e.op, grad_v.op]):\n",
    "        if grad_v is not None:  \n",
    "            E = array_ops.diag(e)\n",
    "            #v_proj = arrary.ops.slice(v, [0,0], [])\n",
    "            grad_stiefel = grad_v - math_ops.batch_matmul(math_ops.batch_matmul(v, grad_v), array_ops.transpose(v))\n",
    "            grad_a = math_ops.batch_matmul(E, math_ops.batch_matmul(v, array_ops.transpose(grad_stiefel))\n",
    "                                           +math_ops.batch_matmul(grad_stiefel, array_ops.transpose(v)))\n",
    "    return grad_a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@ops.RegisterGradient(\"GradientTest4\")\n",
    "def GradientTest2(op, grad_e, grad_v):\n",
    "    \"\"\"Gradient to test vanishing problem\"\"\"\n",
    "    e = op.outputs[0]\n",
    "    v = op.outputs[1]\n",
    "    with ops.control_dependencies([grad_e.op, grad_v.op]):\n",
    "        if grad_v is not None:  \n",
    "            E = arrary.ops.diag(e)\n",
    "            #v_proj = arrary.ops.slice(v, [0,0], [])\n",
    "            grad_grassman = grad_v - math_ops.batch_matmul(math_ops.batch_matmul(v, grad_v), math_ops.transpose(v))\n",
    "            grad_a = math_ops.batch_matmul(E, math_ops.batch_matmul(v, math_ops.transpose(grad_grassman))\n",
    "                                           +math_ops.batch_matmul(grad_grassman, math_ops.transpose(v)))\n",
    "    return grad_a*10000000000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@ops.RegisterGradient(\"adfasdf\")\n",
    "def _adsfadsf(op, grad_e, grad_v):\n",
    "    \"\"\"Gradient to test vanishing problem\"\"\"\n",
    "    e = op.outputs[0]\n",
    "    v = op.outputs[1]\n",
    "    with ops.control_dependencies([grad_e.op, grad_v.op]):\n",
    "        if grad_v is not None:  \n",
    "            grad_a = grad_v\n",
    "    return grad_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@ops.RegisterGradient(\"eigenadlfjkaldjflad\")\n",
    "def _adsfadsf(op, grad_e, grad_v):\n",
    "    \"\"\"Gradient to test vanishing problem\"\"\"\n",
    "    e = op.outputs[0]\n",
    "    v = op.outputs[1]\n",
    "    with ops.control_dependencies([grad_e.op, grad_v.op]):\n",
    "        if grad_v is not None:  \n",
    "            grad_a = array_ops.diag(grad_e)\n",
    "    return grad_a  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def balanced_stochastic_blockmodel(communities=2, groupsize=3, p_in=1.0, p_out=0.0):\n",
    "    #gives dense adjacency matrix representaiton of randomly generated SBM with balanced community size\n",
    "\n",
    "    G = nx.planted_partition_graph(l=communities, k=groupsize, p_in=p_in, p_out =p_out)\n",
    "    A = nx.adjacency_matrix(G).todense()\n",
    "    \n",
    "    return A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "communities = 2 #number of communities, chance to \n",
    "group_size = 10 #number of nodes in each communitites (balanced so far)\n",
    "dim_graph = communities*group_size\n",
    "\n",
    "A = np.asarray(balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.9, p_out=0.2)).astype(np.double)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2654.09850662 536.181516488 [[ 0.00269307  0.          0.          0.        ]\n",
      " [-0.005119   -0.00124502  0.          0.        ]\n",
      " [ 0.00135188  0.00320817 -0.00144805  0.        ]\n",
      " [ 0.00145645 -0.00086827 -0.00036872  0.        ]] 10.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    A = [[1,0,0,5], [3,0,0, 4], [5,5,7,0], [0,0,0,6]]\n",
    "    #np.asarray(balanced_stochastic_blockmodel(communities=communities,\n",
    "        #                                          groupsize=group_size, p_in=0.9, p_out=0.2)).astype(np.double)\n",
    "    #g = tf.get_default_graph()\n",
    "    A = tf.cast(A, dtype = tf.float64)\n",
    "    r = tf.constant(10.0, dtype = tf.float64)#tf.Variable(tf.random_normal([1], mean=0.0, stddev=10.0, dtype = tf.float64))\n",
    "    BH = (tf.square(r)-1)*A\n",
    "    eigenval, eigenvec = tf.self_adjoint_eig(BH)\n",
    "    eigenvec_proj = tf.slice(eigenvec, [0,0], [communities*group_size, 2])\n",
    "    #with g.gradient_override_map({'SelfAdjointEigV2': 'GradientTest3'}):\n",
    "    z = tf.reduce_sum(eigenvec*eigenval)     \n",
    "        \n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    print z.eval(), tf.gradients(z, r)[0].eval(), tf.gradients(eigenvec_proj, BH)[0].eval(), r.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.140883104496 -71635.2928372 [[  722.69873403   246.89362202    30.52571667   197.98523214]\n",
      " [  163.8596245   -761.25556195  -235.92879104  -288.01770355]\n",
      " [  -67.1063394    781.47760725  -630.26948522  -454.05651472]\n",
      " [ -909.70732485  1994.00385436  -949.03258805  -632.31125643]] 10.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    A = [[1,0,0,5], [3,0,0, 4], [5,5,7,0], [0,0,0,6]]\n",
    "    #np.asarray(balanced_stochastic_blockmodel(communities=communities,\n",
    "        #                                          groupsize=group_size, p_in=0.9, p_out=0.2)).astype(np.double)\n",
    "    g = tf.get_default_graph()\n",
    "    A = tf.cast(A, dtype = tf.float64)\n",
    "    r = tf.constant(10.0, dtype = tf.float64)#tf.Variable(tf.random_normal([1], mean=0.0, stddev=10.0, dtype = tf.float64))\n",
    "    BH = (tf.square(r)-1)*A\n",
    "    with g.gradient_override_map({'SelfAdjointEigV2': 'adsfadfad'}):\n",
    "        eigenval, eigenvec = tf.self_adjoint_eig(BH)\n",
    "        eigenvec_proj = tf.slice(eigenvec, [0,0], [communities*group_size, 2])\n",
    "        z = tf.reduce_sum(eigenvec_proj)     \n",
    "        \n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    print z.eval(), tf.gradients(z, r)[0].eval(), tf.gradients(eigenvec_proj, BH)[0].eval(), r.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.707106781187 -6060.10714012 [[-140.00714267 -303.00535701 -317.50357134    6.00535701]\n",
      " [   0.            0.            0.            0.        ]\n",
      " [   0.            0.            0.            0.        ]\n",
      " [  -6.00535701    0.          105.00535701 -160.51071401]] 10.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    #A = #[[1,0,0,5], [3,0,0, 4], [5,5,7,0], [0,0,0,6]]\n",
    "    A = np.asarray(balanced_stochastic_blockmodel(communities=communities,\n",
    "                                                  groupsize=group_size, p_in=0.9, p_out=0.2)).astype(np.double)\n",
    "    g = tf.get_default_graph()\n",
    "    A = tf.cast(A, dtype = tf.float64)\n",
    "    r = tf.constant(10.0, dtype = tf.float64)#tf.Variable(tf.random_normal([1], mean=0.0, stddev=10.0, dtype = tf.float64))\n",
    "    BH = (tf.square(r)-1)*A\n",
    "    with g.gradient_override_map({'SelfAdjointEigV2': 'aj'}):\n",
    "        eigenval, eigenvec = tf.self_adjoint_eig(BH)\n",
    "        eigenvec_proj = tf.slice(eigenvec, [0,0], [communities*group_size, 2])\n",
    "        z = tf.reduce_sum(eigenvec_proj)     \n",
    "        \n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    print z.eval(), tf.gradients(z, r)[0].eval(), tf.gradients(eigenvec_proj, BH)[0].eval(), r.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "communities=2\n",
    "group_size=2\n",
    "B = np.asarray(balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.9, p_out=0.1)).astype(np.double)\n",
    "adj = B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-2.53836831]), 1.4142135623730949, [array([-234.48455593])], [array([[  7.69800804,  11.54701205,   3.84900402,   7.69800804],\n",
      "       [ 11.54701205,   0.        ,  -7.69800804,  -3.84900402],\n",
      "       [ -3.84900402,   7.69800804,   0.        ,  11.54701205],\n",
      "       [ -7.69800804,   3.84900402,  11.54701205,   7.69800804]])], array([[ 0.70710678,  0.        ],\n",
      "       [-0.5       ,  0.        ],\n",
      "       [ 0.        ,  1.        ],\n",
      "       [-0.5       ,  0.        ]])]\n"
     ]
    }
   ],
   "source": [
    "A = tf.placeholder(dtype = tf.float64)\n",
    "B = tf.cast(A, dtype = tf.float64)\n",
    "communities=2\n",
    "group_size=2\n",
    "k = tf.Variable(tf.random_normal([1], mean=0.0, stddev=10.0, dtype = tf.float64))\n",
    "BH = (tf.square(k)-1)*B\n",
    "\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({'SelfAdjointEigV2': 'aj'}):\n",
    "        eigenval, eigenvec = tf.self_adjoint_eig(BH)\n",
    "        eigen_proj = tf.slice(eigenvec, [0,0], [communities*group_size, 3])\n",
    "        loss = tf.reduce_sum(eigen_proj) \n",
    "         \n",
    "        optimizer = tf.train.GradientDescentOptimizer(1)\n",
    "        train = optimizer.minimize(loss)\n",
    "            \n",
    "        gradient_l_k = tf.gradients(loss, k)\n",
    "        gradient_l_bh = tf.gradients(loss, BH)\n",
    "        #grad_l_eigenvec = tf.gradients(loss, eigenvec_proj)\n",
    "        sess.run(init)\n",
    "        \n",
    "        print sess.run([k, loss, gradient_l_k, gradient_l_bh, eigenvec_proj], feed_dict = {A: adj})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, array([ 0.69562506]), 0.46830724457294121]\n",
      "[None, array([ 0.69562506]), 0.46830724457294121]\n",
      "[None, array([ 0.69562506]), 0.46830724457294121]\n",
      "[None, array([ 0.69562506]), 0.46830724457294121]\n",
      "[None, array([ 0.69562506]), 0.46830724457294121]\n",
      "[None, array([ 0.69562506]), 0.46830724457294121]\n",
      "[None, array([ 0.69562506]), 0.46830724457294121]\n",
      "[None, array([ 0.69562506]), 0.46830724457294121]\n",
      "[None, array([ 0.69562506]), 0.46830724457294121]\n",
      "[None, array([ 0.69562506]), 0.46830724457294121]\n"
     ]
    }
   ],
   "source": [
    "B = np.asarray(balanced_stochastic_blockmodel(communities=communities, groupsize=group_size, p_in=0.5, p_out=0.1)).astype(np.double)\n",
    "B = tf.cast(B, dtype = tf.float64)\n",
    "k = tf.Variable(tf.random_normal([1], mean=0.0, stddev=1.0, dtype = tf.float64))\n",
    "\n",
    "Diag = tf.diag(tf.reduce_sum(B,0))\n",
    "Diag = tf.cast(Diag, tf.float64)\n",
    "\n",
    "r =  tf.Variable(tf.random_normal(shape=[1], mean=0.0,\n",
    "                                 stddev=2.0, dtype=tf.float64,\n",
    "                                 seed=None, name=None))\n",
    "\n",
    "\n",
    "\n",
    "BH = tf.square(k)*B#(tf.square(r)-1)*tf.diag(tf.ones(shape=[communities*group_size], dtype=tf.float64))-tf.mul(r, B)+Diag \n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    g = tf.get_default_graph()\n",
    "    sess.run(init)\n",
    "    with g.gradient_override_map({'SelfAdjointEigV2': 'aj'}):\n",
    "        eigenval, eigenvec = tf.self_adjoint_eig(BH)\n",
    "        \n",
    "        eigenval = tf.expand_dims(eigenval, 0)\n",
    "        loss = tf.reduce_sum(tf.square(eigenval)) \n",
    "         \n",
    "        optimizer = tf.train.GradientDescentOptimizer(1)\n",
    "        train = optimizer.minimize(loss, var_list=[k])\n",
    "            \n",
    "        #gradient_r = tf.gradients(loss, k)\n",
    "        #gradient_u = tf.gradients(loss, eigenvec)\n",
    "        \n",
    "        for i in range(10):\n",
    "            \n",
    "            print sess.run([train, k, loss]) #tf.gradients(eigenvec, BH)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?tf.diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9028712499999998"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1.90287125e-15*1000000000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `tf.gradient_override_map` not found.\n"
     ]
    }
   ],
   "source": [
    "?tf.gradient_override_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?tf.train.GradientDescentOptimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
